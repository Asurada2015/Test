import tensorflow as tf
from tensorflow.python.framework import ops

# 超参数
MIN_AFTER_DEQUEUE = 1000
# 数据输入
NUM_EPOCHS = 50  # 批次轮数
NUM_THREADS = 3  # 线程数
TRAIN_FILE = 'a_train.csv'
TEST_FILE = 'a_test.csv'
BATCH_SIZE = 20  # 批处理数量  128 test use 3


# 读取数据
def read_data(file_queue):
    reader = tf.TextLineReader(skip_header_lines=1)
    key, value = reader.read(file_queue)
    defaults = [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.],
                [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.],
                [0.], [0.], [0.]]
    C, MN, SI, P, S, CU, AL, ALS, NI, CR, TI, MO, V, NB, N, B, Furnace, RoughMill, FinishMill, DownCoil, Tensile, Yeild, Elongation \
        = tf.decode_csv(value, defaults)
    vertor_example = tf.stack(
        [C, MN, SI, P, S, CU, AL, ALS, NI, CR, TI, MO, V, NB, N, B, Furnace, RoughMill, FinishMill,
         DownCoil])
    # 将(21)维度的数据添加维度成为(1,21)的向量

    example_2D = tf.expand_dims(vertor_example, 0)
    trans_example_2D = tf.transpose(example_2D)
    example = tf.expand_dims(tf.matmul(trans_example_2D, example_2D), 2)
    vertor_label = tf.stack([Tensile])
    return example, vertor_label


# 创建输入管道
def create_pipeline(filename, batch_size, num_threads, num_epochs=None):
    file_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)  # 设置文件名队列
    example, label = read_data(file_queue)  # 读取数据和标签

    min_after_dequeue = MIN_AFTER_DEQUEUE
    # capacity = min_after_dequeue + batch_size
    capacity = min_after_dequeue + (num_threads + 3*batch_size)
    example_batch, label_batch = tf.train.shuffle_batch(
        [example, label], batch_size=batch_size, num_threads=num_threads, capacity=capacity,
        min_after_dequeue=min_after_dequeue)
    return example_batch, label_batch


# 获取数据
print('Now getting and transforming Data')
train_images, train_targets = create_pipeline(TRAIN_FILE, batch_size=BATCH_SIZE, num_threads=NUM_THREADS,
                                              num_epochs=NUM_EPOCHS)

test_images, test_targets = create_pipeline(TEST_FILE, batch_size=BATCH_SIZE, num_threads=NUM_THREADS,
                                            num_epochs=NUM_EPOCHS)
# 初始化变量和队列
sess = tf.Session()
print('Initializing the Variables.')
init_op = tf.global_variables_initializer()
local_init_op = tf.local_variables_initializer()
sess.run([init_op, local_init_op])
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(coord=coord, sess=sess)
print(sess.run(train_targets))
# 关闭线程和Session
coord.request_stop()
coord.join(threads)
sess.close()
