C:\ProgramData\Anaconda3\envs\py35gpu\python.exe "D:/CODE/Git/Test/Prediction based on convolutional neural network/code/NewModels1/Tensile_BNL2.py"
2018-05-11 22:18:00.565289: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-05-11 22:18:00.794206: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 750 Ti major: 5 minor: 0 memoryClockRate(GHz): 1.0845
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.35GiB
2018-05-11 22:18:00.794743: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0)
Now getting and transforming Data
Creating the CNN model.
Declare Loss Function.
Create the Train Operation
Initializing the Variables.
Starting Training
  0%|          | 149/50002 [01:38<8:54:22,  1.55it/s]Generation 150: train Loss = 0.01606
  0%|          | 150/50002 [01:41<16:29:51,  1.19s/it]Generation 150: test Loss = 0.01509
  0%|          | 199/50002 [02:12<8:53:06,  1.56it/s]Generation 200: train Loss = 0.01438
  0%|          | 200/50002 [02:15<16:35:45,  1.20s/it]Generation 200: test Loss = 0.01303
  0%|          | 249/50002 [02:46<8:50:08,  1.56it/s]Generation 250: train Loss = 0.01384
  0%|          | 250/50002 [02:49<16:13:37,  1.17s/it]Generation 250: test Loss = 0.01323
  1%|          | 299/50002 [03:20<8:48:50,  1.57it/s]Generation 300: train Loss = 0.01166
Generation 300: test Loss = 0.01156
  1%|          | 349/50002 [03:54<8:57:54,  1.54it/s]Generation 350: train Loss = 0.01092
  1%|          | 350/50002 [03:57<16:40:22,  1.21s/it]Generation 350: test Loss = 0.01129
  1%|          | 399/50002 [04:28<8:50:17,  1.56it/s]Generation 400: train Loss = 0.01010
  1%|          | 400/50002 [04:30<16:21:26,  1.19s/it]Generation 400: test Loss = 0.00926
  1%|          | 449/50002 [05:02<8:51:25,  1.55it/s]Generation 450: train Loss = 0.00896
Generation 450: test Loss = 0.00979
  1%|          | 499/50002 [05:36<8:50:30,  1.56it/s]Generation 500: train Loss = 0.00834
Generation 500: test Loss = 0.00973
训练集上一个批次数据的前10个数据
 [[ 0.47698745]
 [ 0.55230123]
 [ 0.46861926]
 [ 0.50627613]
 [ 0.41841003]
 [ 0.43514645]
 [ 0.33472803]
 [ 0.45606694]
 [ 0.47280335]
 [ 0.60251045]]
测试集上一个批次数据的前10个数据
 [[ 0.53974897]
 [ 0.43514645]
 [ 0.46443516]
 [ 0.44351465]
 [ 0.53138077]
 [ 0.48117155]
 [ 0.52301258]
 [ 0.52719665]
 [ 0.45606694]
 [ 0.65690374]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]]
测试集上一个批次数据中通过inference后的前10个输出结果
  1%|          | 500/50002 [05:40<24:45:15,  1.80s/it] [[ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]
 [ 0.4915323]]
  1%|          | 549/50002 [06:12<8:53:20,  1.55it/s]Generation 550: train Loss = 0.00788
Generation 550: test Loss = 0.00801
  1%|          | 599/50002 [06:46<8:52:59,  1.54it/s]Generation 600: train Loss = 0.00818
Generation 600: test Loss = 0.00802
  1%|         | 649/50002 [07:20<8:49:55,  1.55it/s]Generation 650: train Loss = 0.00821
Generation 650: test Loss = 0.00684
  1%|         | 699/50002 [07:54<8:45:28,  1.56it/s]Generation 700: train Loss = 0.00826
  1%|         | 700/50002 [07:56<16:39:34,  1.22s/it]Generation 700: test Loss = 0.00742
  1%|         | 749/50002 [08:28<8:48:47,  1.55it/s]Generation 750: train Loss = 0.00784
Generation 750: test Loss = 0.00690
  2%|         | 799/50002 [09:02<8:48:42,  1.55it/s]Generation 800: train Loss = 0.00738
Generation 800: test Loss = 0.00649
  2%|         | 849/50002 [09:36<8:43:10,  1.57it/s]Generation 850: train Loss = 0.00683
Generation 850: test Loss = 0.00629
  2%|         | 899/50002 [10:10<8:41:40,  1.57it/s]Generation 900: train Loss = 0.00724
Generation 900: test Loss = 0.00674
  2%|         | 949/50002 [10:44<8:43:18,  1.56it/s]Generation 950: train Loss = 0.00748
  2%|         | 950/50002 [10:46<16:34:50,  1.22s/it]Generation 950: test Loss = 0.00549
  2%|         | 999/50002 [11:17<8:37:49,  1.58it/s]Generation 1000: train Loss = 0.00697
Generation 1000: test Loss = 0.00614
训练集上一个批次数据的前10个数据
 [[ 0.51882845]
 [ 0.46861926]
 [ 0.49372384]
 [ 0.33472803]
 [ 0.45188284]
 [ 0.38075313]
 [ 0.40167364]
 [ 0.41841003]
 [ 0.48953974]
 [ 0.45606694]]
测试集上一个批次数据的前10个数据
 [[ 0.58577406]
 [ 0.50209206]
 [ 0.44351465]
 [ 0.43096235]
 [ 0.50627613]
 [ 0.49790794]
 [ 0.53556484]
 [ 0.37238494]
 [ 0.52301258]
 [ 0.44351465]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]]
  2%|         | 1000/50002 [11:22<22:34:06,  1.66s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]
 [ 0.49055436]]
  2%|         | 1049/50002 [11:53<8:46:03,  1.55it/s]Generation 1050: train Loss = 0.00668
  2%|         | 1050/50002 [11:56<17:32:52,  1.29s/it]Generation 1050: test Loss = 0.00666
  2%|         | 1099/50002 [12:27<8:44:01,  1.56it/s]Generation 1100: train Loss = 0.00685
  2%|         | 1100/50002 [12:29<16:56:21,  1.25s/it]Generation 1100: test Loss = 0.00727
  2%|         | 1149/50002 [13:01<8:40:52,  1.56it/s]Generation 1150: train Loss = 0.00560
  2%|         | 1150/50002 [13:03<16:42:02,  1.23s/it]Generation 1150: test Loss = 0.00574
  2%|         | 1199/50002 [13:35<8:39:43,  1.57it/s]Generation 1200: train Loss = 0.00738
Generation 1200: test Loss = 0.00584
  2%|         | 1249/50002 [14:08<8:38:35,  1.57it/s]Generation 1250: train Loss = 0.00673
  2%|         | 1250/50002 [14:11<16:50:33,  1.24s/it]Generation 1250: test Loss = 0.00606
  3%|         | 1299/50002 [14:42<8:41:04,  1.56it/s]Generation 1300: train Loss = 0.00525
  3%|         | 1300/50002 [14:45<16:59:14,  1.26s/it]Generation 1300: test Loss = 0.00601
  3%|         | 1349/50002 [15:16<8:38:21,  1.56it/s]Generation 1350: train Loss = 0.00789
  3%|         | 1350/50002 [15:19<16:52:52,  1.25s/it]Generation 1350: test Loss = 0.00510
  3%|         | 1399/50002 [15:50<8:37:27,  1.57it/s]Generation 1400: train Loss = 0.00528
Generation 1400: test Loss = 0.00619
  3%|         | 1449/50002 [16:24<8:34:34,  1.57it/s]Generation 1450: train Loss = 0.00581
Generation 1450: test Loss = 0.00537
  3%|         | 1499/50002 [16:58<8:35:43,  1.57it/s]Generation 1500: train Loss = 0.00480
Generation 1500: test Loss = 0.00541
训练集上一个批次数据的前10个数据
 [[ 0.50209206]
 [ 0.56903768]
 [ 0.49790794]
 [ 0.58158994]
 [ 0.53556484]
 [ 0.55230123]
 [ 0.49372384]
 [ 0.47280335]
 [ 0.38912135]
 [ 0.27196652]]
测试集上一个批次数据的前10个数据
 [[ 0.47698745]
 [ 0.29288703]
 [ 0.50209206]
 [ 0.42259413]
 [ 0.38493723]
 [ 0.48535565]
 [ 0.40585774]
 [ 0.49790794]
 [ 0.54393303]
 [ 0.56066948]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]
 [ 0.48919326]]
  3%|         | 1549/50002 [17:33<8:40:44,  1.55it/s]Generation 1550: train Loss = 0.00523
  3%|         | 1550/50002 [17:37<18:22:43,  1.37s/it]Generation 1550: test Loss = 0.00561
  3%|         | 1599/50002 [18:08<8:35:14,  1.57it/s]Generation 1600: train Loss = 0.00684
  3%|         | 1600/50002 [18:11<17:17:36,  1.29s/it]Generation 1600: test Loss = 0.00482
  3%|         | 1649/50002 [18:42<8:30:30,  1.58it/s]Generation 1650: train Loss = 0.00473
  3%|         | 1650/50002 [18:45<17:17:22,  1.29s/it]Generation 1650: test Loss = 0.00580
  3%|         | 1699/50002 [19:16<8:36:09,  1.56it/s]Generation 1700: train Loss = 0.00468
Generation 1700: test Loss = 0.00540
  3%|         | 1749/50002 [19:50<8:31:51,  1.57it/s]Generation 1750: train Loss = 0.00617
  3%|         | 1750/50002 [19:53<17:13:08,  1.28s/it]Generation 1750: test Loss = 0.00500
  4%|         | 1799/50002 [20:24<8:35:03,  1.56it/s]Generation 1800: train Loss = 0.00762
  4%|         | 1800/50002 [20:27<17:22:12,  1.30s/it]Generation 1800: test Loss = 0.00435
  4%|         | 1849/50002 [20:58<8:34:15,  1.56it/s]Generation 1850: train Loss = 0.00695
  4%|         | 1850/50002 [21:01<17:24:42,  1.30s/it]Generation 1850: test Loss = 0.00517
  4%|         | 1899/50002 [21:32<8:30:37,  1.57it/s]Generation 1900: train Loss = 0.00557
  4%|         | 1900/50002 [21:35<17:28:58,  1.31s/it]Generation 1900: test Loss = 0.00441
  4%|         | 1949/50002 [22:07<8:28:26,  1.58it/s]Generation 1950: train Loss = 0.00571
Generation 1950: test Loss = 0.00487
  4%|         | 1999/50002 [22:41<8:27:28,  1.58it/s]Generation 2000: train Loss = 0.00510
Generation 2000: test Loss = 0.00389
训练集上一个批次数据的前10个数据
 [[ 0.43514645]
 [ 0.51046026]
 [ 0.55648535]
 [ 0.46861926]
 [ 0.53556484]
 [ 0.48953974]
 [ 0.44769874]
 [ 0.33054394]
 [ 0.58577406]
 [ 0.48953974]]
测试集上一个批次数据的前10个数据
 [[ 0.41422594]
 [ 0.46861926]
 [ 0.60669458]
 [ 0.45606694]
 [ 0.53974897]
 [ 0.49790794]
 [ 0.47698745]
 [ 0.55648535]
 [ 0.60251045]
 [ 0.45606694]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]
 [ 0.4888297]]
  4%|         | 2049/50002 [23:16<8:29:51,  1.57it/s]Generation 2050: train Loss = 0.00564
  4%|         | 2050/50002 [23:19<18:11:14,  1.37s/it]Generation 2050: test Loss = 0.00408
  4%|         | 2099/50002 [23:50<8:30:38,  1.56it/s]Generation 2100: train Loss = 0.00486
Generation 2100: test Loss = 0.00560
  4%|         | 2149/50002 [24:25<8:28:12,  1.57it/s]Generation 2150: train Loss = 0.00517
Generation 2150: test Loss = 0.00420
  4%|         | 2199/50002 [24:59<8:25:18,  1.58it/s]Generation 2200: train Loss = 0.00521
  4%|         | 2200/50002 [25:02<17:50:48,  1.34s/it]Generation 2200: test Loss = 0.00489
  4%|         | 2249/50002 [25:33<8:28:52,  1.56it/s]Generation 2250: train Loss = 0.00587
  4%|         | 2250/50002 [25:36<17:48:49,  1.34s/it]Generation 2250: test Loss = 0.00642
  5%|         | 2299/50002 [26:07<8:27:07,  1.57it/s]Generation 2300: train Loss = 0.00521
  5%|         | 2300/50002 [26:10<17:50:35,  1.35s/it]Generation 2300: test Loss = 0.00556
  5%|         | 2349/50002 [26:42<8:33:10,  1.55it/s]Generation 2350: train Loss = 0.00518
Generation 2350: test Loss = 0.00584
  5%|         | 2399/50002 [27:16<8:27:27,  1.56it/s]Generation 2400: train Loss = 0.00542
Generation 2400: test Loss = 0.00596
  5%|         | 2449/50002 [27:50<8:27:27,  1.56it/s]Generation 2450: train Loss = 0.00616
Generation 2450: test Loss = 0.00459
  5%|         | 2499/50002 [28:25<8:23:32,  1.57it/s]Generation 2500: train Loss = 0.00490
Generation 2500: test Loss = 0.00337
训练集上一个批次数据的前10个数据
 [[ 0.37656903]
 [ 0.48535565]
 [ 0.45188284]
 [ 0.34309623]
 [ 0.54393303]
 [ 0.48117155]
 [ 0.55648535]
 [ 0.56485355]
 [ 0.44769874]
 [ 0.47698745]]
测试集上一个批次数据的前10个数据
 [[ 0.34728032]
 [ 0.39748955]
 [ 0.48953974]
 [ 0.48117155]
 [ 0.48953974]
 [ 0.48953974]
 [ 0.54393303]
 [ 0.52301258]
 [ 0.52719665]
 [ 0.45188284]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]
 [ 0.4929699]]
  5%|         | 2549/50002 [29:00<8:22:07,  1.58it/s]Generation 2550: train Loss = 0.00499
  5%|         | 2550/50002 [29:03<18:35:14,  1.41s/it]Generation 2550: test Loss = 0.00508
  5%|         | 2599/50002 [29:35<8:23:19,  1.57it/s]Generation 2600: train Loss = 0.00432
Generation 2600: test Loss = 0.00553
  5%|         | 2649/50002 [30:09<8:21:13,  1.57it/s]Generation 2650: train Loss = 0.00523
  5%|         | 2650/50002 [30:12<17:59:42,  1.37s/it]Generation 2650: test Loss = 0.00502
  5%|         | 2699/50002 [30:43<8:21:08,  1.57it/s]Generation 2700: train Loss = 0.00580
Generation 2700: test Loss = 0.00406
  5%|         | 2749/50002 [31:18<8:19:22,  1.58it/s]Generation 2750: train Loss = 0.00479
  5%|         | 2750/50002 [31:21<18:15:19,  1.39s/it]Generation 2750: test Loss = 0.00520
  6%|         | 2799/50002 [31:52<8:21:56,  1.57it/s]Generation 2800: train Loss = 0.00534
Generation 2800: test Loss = 0.00622
  6%|         | 2849/50002 [32:27<8:24:17,  1.56it/s]Generation 2850: train Loss = 0.00586
  6%|         | 2850/50002 [32:30<18:13:30,  1.39s/it]Generation 2850: test Loss = 0.00398
  6%|         | 2899/50002 [33:01<8:21:18,  1.57it/s]Generation 2900: train Loss = 0.00520
  6%|         | 2900/50002 [33:04<18:14:19,  1.39s/it]Generation 2900: test Loss = 0.00348
  6%|         | 2949/50002 [33:35<8:20:01,  1.57it/s]Generation 2950: train Loss = 0.00620
Generation 2950: test Loss = 0.00526
  6%|         | 2999/50002 [34:10<8:21:15,  1.56it/s]Generation 3000: train Loss = 0.00592
Generation 3000: test Loss = 0.00490
训练集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.46861926]
 [ 0.40585774]
 [ 0.44769874]
 [ 0.50209206]
 [ 0.45188284]
 [ 0.41422594]
 [ 0.49790794]
 [ 0.56066948]
 [ 0.36820084]]
测试集上一个批次数据的前10个数据
 [[ 0.48953974]
 [ 0.48953974]
 [ 0.62343097]
 [ 0.58995813]
 [ 0.44351465]
 [ 0.56485355]
 [ 0.52719665]
 [ 0.48535565]
 [ 0.42677826]
 [ 0.57740587]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]]
  6%|         | 3000/50002 [34:14<23:50:33,  1.83s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]
 [ 0.50990868]]
  6%|         | 3049/50002 [34:46<8:21:24,  1.56it/s]Generation 3050: train Loss = 0.00449
  6%|         | 3050/50002 [34:49<18:52:22,  1.45s/it]Generation 3050: test Loss = 0.00475
  6%|         | 3099/50002 [35:20<8:13:33,  1.58it/s]Generation 3100: train Loss = 0.00594
  6%|         | 3100/50002 [35:23<18:35:03,  1.43s/it]Generation 3100: test Loss = 0.00415
  6%|         | 3149/50002 [35:55<8:14:40,  1.58it/s]Generation 3150: train Loss = 0.00530
  6%|         | 3150/50002 [35:58<18:16:42,  1.40s/it]Generation 3150: test Loss = 0.00520
  6%|         | 3199/50002 [36:29<8:18:51,  1.56it/s]Generation 3200: train Loss = 0.00543
Generation 3200: test Loss = 0.00432
  6%|         | 3249/50002 [37:04<8:13:22,  1.58it/s]Generation 3250: train Loss = 0.00444
Generation 3250: test Loss = 0.00478
  7%|         | 3299/50002 [37:38<8:23:20,  1.55it/s]Generation 3300: train Loss = 0.00405
Generation 3300: test Loss = 0.00497
  7%|         | 3349/50002 [38:13<8:14:15,  1.57it/s]Generation 3350: train Loss = 0.00459
  7%|         | 3350/50002 [38:16<18:35:05,  1.43s/it]Generation 3350: test Loss = 0.00391
  7%|         | 3399/50002 [38:47<8:14:20,  1.57it/s]Generation 3400: train Loss = 0.00679
Generation 3400: test Loss = 0.00459
  7%|         | 3449/50002 [39:22<8:15:18,  1.57it/s]Generation 3450: train Loss = 0.00485
Generation 3450: test Loss = 0.00360
  7%|         | 3499/50002 [39:56<8:15:31,  1.56it/s]Generation 3500: train Loss = 0.00425
Generation 3500: test Loss = 0.00454
训练集上一个批次数据的前10个数据
 [[ 0.48117155]
 [ 0.39748955]
 [ 0.46025103]
 [ 0.41004184]
 [ 0.53556484]
 [ 0.52301258]
 [ 0.25941423]
 [ 0.55230123]
 [ 0.57322174]
 [ 0.48535565]]
测试集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.53556484]
 [ 0.50627613]
 [ 0.54811716]
 [ 0.54393303]
 [ 0.46443516]
 [ 0.51882845]
 [ 0.48117155]
 [ 0.29707113]
 [ 0.42677826]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]]
  7%|         | 3500/50002 [40:01<24:04:08,  1.86s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]
 [ 0.48505738]]
  7%|         | 3549/50002 [40:32<8:16:17,  1.56it/s]Generation 3550: train Loss = 0.00489
  7%|         | 3550/50002 [40:36<19:16:45,  1.49s/it]Generation 3550: test Loss = 0.00621
  7%|         | 3599/50002 [41:07<8:15:13,  1.56it/s]Generation 3600: train Loss = 0.00479
  7%|         | 3600/50002 [41:10<19:00:39,  1.47s/it]Generation 3600: test Loss = 0.00477
  7%|         | 3649/50002 [41:42<8:14:18,  1.56it/s]Generation 3650: train Loss = 0.00552
Generation 3650: test Loss = 0.00414
  7%|         | 3699/50002 [42:16<8:08:52,  1.58it/s]Generation 3700: train Loss = 0.00431
Generation 3700: test Loss = 0.00431
  7%|         | 3749/50002 [42:51<8:12:40,  1.56it/s]Generation 3750: train Loss = 0.00440
Generation 3750: test Loss = 0.00583
  8%|         | 3799/50002 [43:26<8:13:13,  1.56it/s]Generation 3800: train Loss = 0.00413
  8%|         | 3800/50002 [43:29<18:44:59,  1.46s/it]Generation 3800: test Loss = 0.00384
  8%|         | 3849/50002 [44:00<8:11:47,  1.56it/s]Generation 3850: train Loss = 0.00455
  8%|         | 3850/50002 [44:04<18:57:34,  1.48s/it]Generation 3850: test Loss = 0.00451
  8%|         | 3899/50002 [44:35<8:12:46,  1.56it/s]Generation 3900: train Loss = 0.00464
Generation 3900: test Loss = 0.00530
  8%|         | 3949/50002 [45:09<8:06:53,  1.58it/s]Generation 3950: train Loss = 0.00418
  8%|         | 3950/50002 [45:13<18:56:00,  1.48s/it]Generation 3950: test Loss = 0.00445
  8%|         | 3999/50002 [45:44<8:12:40,  1.56it/s]Generation 4000: train Loss = 0.00485
Generation 4000: test Loss = 0.00416
训练集上一个批次数据的前10个数据
 [[ 0.46025103]
 [ 0.41841003]
 [ 0.53556484]
 [ 0.57740587]
 [ 0.54393303]
 [ 0.51464432]
 [ 0.55648535]
 [ 0.44769874]
 [ 0.57740587]
 [ 0.43514645]]
测试集上一个批次数据的前10个数据
 [[ 0.55648535]
 [ 0.53974897]
 [ 0.32635984]
 [ 0.56485355]
 [ 0.42677826]
 [ 0.53138077]
 [ 0.49790794]
 [ 0.40585774]
 [ 0.39330545]
 [ 0.56903768]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]]
  8%|         | 4000/50002 [45:49<24:37:04,  1.93s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]
 [ 0.50466615]]
  8%|         | 4049/50002 [46:20<8:09:23,  1.56it/s]Generation 4050: train Loss = 0.00654
Generation 4050: test Loss = 0.00502
  8%|         | 4099/50002 [46:55<8:13:51,  1.55it/s]Generation 4100: train Loss = 0.00473
Generation 4100: test Loss = 0.00442
  8%|         | 4149/50002 [47:30<8:04:17,  1.58it/s]Generation 4150: train Loss = 0.00472
  8%|         | 4150/50002 [47:33<18:57:54,  1.49s/it]Generation 4150: test Loss = 0.00396
  8%|         | 4199/50002 [48:05<8:03:16,  1.58it/s]Generation 4200: train Loss = 0.00508
  8%|         | 4200/50002 [48:08<19:03:28,  1.50s/it]Generation 4200: test Loss = 0.00473
  8%|         | 4249/50002 [48:39<8:08:38,  1.56it/s]Generation 4250: train Loss = 0.00636
  8%|         | 4250/50002 [48:43<19:52:50,  1.56s/it]Generation 4250: test Loss = 0.00413
  9%|         | 4299/50002 [49:14<8:05:17,  1.57it/s]Generation 4300: train Loss = 0.00414
Generation 4300: test Loss = 0.00470
  9%|         | 4349/50002 [49:49<8:04:14,  1.57it/s]Generation 4350: train Loss = 0.00446
  9%|         | 4350/50002 [49:53<19:22:55,  1.53s/it]Generation 4350: test Loss = 0.00466
  9%|         | 4399/50002 [50:24<8:01:24,  1.58it/s]Generation 4400: train Loss = 0.00660
Generation 4400: test Loss = 0.00342
  9%|         | 4449/50002 [50:59<8:04:34,  1.57it/s]Generation 4450: train Loss = 0.00439
  9%|         | 4450/50002 [51:02<19:07:07,  1.51s/it]Generation 4450: test Loss = 0.00520
  9%|         | 4499/50002 [51:34<8:03:03,  1.57it/s]Generation 4500: train Loss = 0.00732
Generation 4500: test Loss = 0.00487
训练集上一个批次数据的前10个数据
 [[ 0.53556484]
 [ 0.55648535]
 [ 0.63179916]
 [ 0.47280335]
 [ 0.45606694]
 [ 0.54393303]
 [ 0.43933055]
 [ 0.48117155]
 [ 0.49372384]
 [ 0.55648535]]
测试集上一个批次数据的前10个数据
 [[ 0.40167364]
 [ 0.53974897]
 [ 0.45188284]
 [ 0.52301258]
 [ 0.47280335]
 [ 0.51464432]
 [ 0.58158994]
 [ 0.57322174]
 [ 0.41422594]
 [ 0.38075313]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]
 [ 0.49862841]]
  9%|         | 4549/50002 [52:10<7:59:24,  1.58it/s]Generation 4550: train Loss = 0.00474
Generation 4550: test Loss = 0.00443
  9%|         | 4599/50002 [52:45<8:00:11,  1.58it/s]Generation 4600: train Loss = 0.00477
Generation 4600: test Loss = 0.00377
  9%|         | 4649/50002 [53:20<8:01:13,  1.57it/s]Generation 4650: train Loss = 0.00569
  9%|         | 4650/50002 [53:23<19:18:56,  1.53s/it]Generation 4650: test Loss = 0.00479
  9%|         | 4699/50002 [53:55<8:00:13,  1.57it/s]Generation 4700: train Loss = 0.00521
Generation 4700: test Loss = 0.00393
  9%|         | 4749/50002 [54:29<7:53:15,  1.59it/s]Generation 4750: train Loss = 0.00534
Generation 4750: test Loss = 0.00545
 10%|         | 4799/50002 [55:04<8:02:30,  1.56it/s]Generation 4800: train Loss = 0.00539
 10%|         | 4800/50002 [55:08<19:24:11,  1.55s/it]Generation 4800: test Loss = 0.00555
 10%|         | 4849/50002 [55:39<7:57:58,  1.57it/s]Generation 4850: train Loss = 0.00522
 10%|         | 4850/50002 [55:43<19:34:12,  1.56s/it]Generation 4850: test Loss = 0.00553
 10%|         | 4899/50002 [56:14<7:55:43,  1.58it/s]Generation 4900: train Loss = 0.00396
 10%|         | 4900/50002 [56:18<19:28:10,  1.55s/it]Generation 4900: test Loss = 0.00371
 10%|         | 4949/50002 [56:49<8:00:08,  1.56it/s]Generation 4950: train Loss = 0.00513
 10%|         | 4950/50002 [56:53<19:33:52,  1.56s/it]Generation 4950: test Loss = 0.00494
 10%|         | 4999/50002 [57:24<7:55:53,  1.58it/s]Generation 5000: train Loss = 0.00418
Generation 5000: test Loss = 0.00532
训练集上一个批次数据的前10个数据
 [[ 0.48953974]
 [ 0.61087865]
 [ 0.52301258]
 [ 0.39748955]
 [ 0.59832639]
 [ 0.29707113]
 [ 0.51046026]
 [ 0.48535565]
 [ 0.59414226]
 [ 0.53974897]]
测试集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.45188284]
 [ 0.63179916]
 [ 0.48117155]
 [ 0.47698745]
 [ 0.53138077]
 [ 0.53974897]
 [ 0.35564855]
 [ 0.46861926]
 [ 0.55230123]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]
 [ 0.4802939]]
 10%|         | 5049/50002 [58:00<8:00:34,  1.56it/s]Generation 5050: train Loss = 0.00573
Generation 5050: test Loss = 0.00522
 10%|         | 5099/50002 [58:36<8:02:05,  1.55it/s]Generation 5100: train Loss = 0.00486
 10%|         | 5100/50002 [58:39<19:57:00,  1.60s/it]Generation 5100: test Loss = 0.00347
 10%|         | 5149/50002 [59:11<7:54:48,  1.57it/s]Generation 5150: train Loss = 0.00492
Generation 5150: test Loss = 0.00371
 10%|         | 5199/50002 [59:46<7:52:56,  1.58it/s]Generation 5200: train Loss = 0.00607
 10%|         | 5200/50002 [59:49<19:34:40,  1.57s/it]Generation 5200: test Loss = 0.00447
 10%|         | 5249/50002 [1:00:21<7:56:46,  1.56it/s]Generation 5250: train Loss = 0.00473
Generation 5250: test Loss = 0.00322
 11%|         | 5299/50002 [1:00:56<7:59:39,  1.55it/s]Generation 5300: train Loss = 0.00501
Generation 5300: test Loss = 0.00417
 11%|         | 5349/50002 [1:01:31<7:53:04,  1.57it/s]Generation 5350: train Loss = 0.00497
 11%|         | 5350/50002 [1:01:35<19:42:24,  1.59s/it]Generation 5350: test Loss = 0.00647
 11%|         | 5399/50002 [1:02:06<7:52:23,  1.57it/s]Generation 5400: train Loss = 0.00454
 11%|         | 5400/50002 [1:02:10<19:47:57,  1.60s/it]Generation 5400: test Loss = 0.00596
 11%|         | 5449/50002 [1:02:41<7:55:20,  1.56it/s]Generation 5450: train Loss = 0.00483
 11%|         | 5450/50002 [1:02:45<19:45:34,  1.60s/it]Generation 5450: test Loss = 0.00567
 11%|         | 5499/50002 [1:03:16<7:55:18,  1.56it/s]Generation 5500: train Loss = 0.00811
Generation 5500: test Loss = 0.00583
训练集上一个批次数据的前10个数据
 [[ 0.46443516]
 [ 0.42677826]
 [ 0.43096235]
 [ 0.47698745]
 [ 0.46861926]
 [ 0.35983264]
 [ 0.52301258]
 [ 0.41841003]
 [ 0.47280335]
 [ 0.56066948]]
测试集上一个批次数据的前10个数据
 [[ 0.54811716]
 [ 0.54811716]
 [ 0.38075313]
 [ 0.51882845]
 [ 0.40585774]
 [ 0.53974897]
 [ 0.53974897]
 [ 0.46025103]
 [ 0.57322174]
 [ 0.47280335]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]
 [ 0.46900657]]
 11%|         | 5549/50002 [1:03:53<7:50:55,  1.57it/s]Generation 5550: train Loss = 0.00443
Generation 5550: test Loss = 0.00567
 11%|         | 5599/50002 [1:04:28<7:51:45,  1.57it/s]Generation 5600: train Loss = 0.00529
 11%|         | 5600/50002 [1:04:32<20:21:49,  1.65s/it]Generation 5600: test Loss = 0.00344
 11%|        | 5649/50002 [1:05:03<7:51:55,  1.57it/s]Generation 5650: train Loss = 0.00549
 11%|        | 5650/50002 [1:05:07<19:46:16,  1.60s/it]Generation 5650: test Loss = 0.00438
 11%|        | 5699/50002 [1:05:38<7:58:33,  1.54it/s]Generation 5700: train Loss = 0.00445
 11%|        | 5700/50002 [1:05:42<19:56:53,  1.62s/it]Generation 5700: test Loss = 0.00536
 11%|        | 5749/50002 [1:06:14<7:48:36,  1.57it/s]Generation 5750: train Loss = 0.00621
Generation 5750: test Loss = 0.00408
 12%|        | 5799/50002 [1:06:49<7:50:32,  1.57it/s]Generation 5800: train Loss = 0.00655
Generation 5800: test Loss = 0.00535
 12%|        | 5849/50002 [1:07:24<7:52:57,  1.56it/s]Generation 5850: train Loss = 0.00483
Generation 5850: test Loss = 0.00518
 12%|        | 5899/50002 [1:07:59<7:46:42,  1.57it/s]Generation 5900: train Loss = 0.00583
Generation 5900: test Loss = 0.00502
 12%|        | 5949/50002 [1:08:35<7:46:16,  1.57it/s]Generation 5950: train Loss = 0.00669
 12%|        | 5950/50002 [1:08:39<20:04:04,  1.64s/it]Generation 5950: test Loss = 0.00567
 12%|        | 5999/50002 [1:09:10<7:47:17,  1.57it/s]Generation 6000: train Loss = 0.00493
Generation 6000: test Loss = 0.00498
训练集上一个批次数据的前10个数据
 [[ 0.48117155]
 [ 0.44351465]
 [ 0.48535565]
 [ 0.47280335]
 [ 0.44351465]
 [ 0.60251045]
 [ 0.41004184]
 [ 0.50627613]
 [ 0.49372384]
 [ 0.46443516]]
测试集上一个批次数据的前10个数据
 [[ 0.46025103]
 [ 0.54393303]
 [ 0.49372384]
 [ 0.41422594]
 [ 0.51464432]
 [ 0.48117155]
 [ 0.53556484]
 [ 0.54811716]
 [ 0.51046026]
 [ 0.48117155]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]]
 12%|        | 6000/50002 [1:09:15<25:20:05,  2.07s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]
 [ 0.48238873]]
 12%|        | 6049/50002 [1:09:46<7:45:43,  1.57it/s]Generation 6050: train Loss = 0.00457
Generation 6050: test Loss = 0.00512
 12%|        | 6099/50002 [1:10:22<7:46:20,  1.57it/s]Generation 6100: train Loss = 0.00517
 12%|        | 6100/50002 [1:10:26<20:18:17,  1.67s/it]Generation 6100: test Loss = 0.00451
 12%|        | 6149/50002 [1:10:57<7:44:00,  1.58it/s]Generation 6150: train Loss = 0.00519
 12%|        | 6150/50002 [1:11:01<20:01:56,  1.64s/it]Generation 6150: test Loss = 0.00497
 12%|        | 6199/50002 [1:11:32<7:46:05,  1.57it/s]Generation 6200: train Loss = 0.00482
Generation 6200: test Loss = 0.00492
 12%|        | 6249/50002 [1:12:07<7:44:22,  1.57it/s]Generation 6250: train Loss = 0.00445
 12%|        | 6250/50002 [1:12:11<20:13:51,  1.66s/it]Generation 6250: test Loss = 0.00418
 13%|        | 6299/50002 [1:12:43<7:44:44,  1.57it/s]Generation 6300: train Loss = 0.00497
 13%|        | 6300/50002 [1:12:47<20:06:16,  1.66s/it]Generation 6300: test Loss = 0.00474
 13%|        | 6349/50002 [1:13:18<7:45:04,  1.56it/s]Generation 6350: train Loss = 0.00749
 13%|        | 6350/50002 [1:13:22<20:12:19,  1.67s/it]Generation 6350: test Loss = 0.00519
 13%|        | 6399/50002 [1:13:53<7:43:52,  1.57it/s]Generation 6400: train Loss = 0.00382
 13%|        | 6400/50002 [1:13:57<20:13:52,  1.67s/it]Generation 6400: test Loss = 0.00451
 13%|        | 6449/50002 [1:14:29<7:41:55,  1.57it/s]Generation 6450: train Loss = 0.00540
Generation 6450: test Loss = 0.00474
 13%|        | 6499/50002 [1:15:04<7:42:05,  1.57it/s]Generation 6500: train Loss = 0.00511
Generation 6500: test Loss = 0.00545
训练集上一个批次数据的前10个数据
 [[ 0.37656903]
 [ 0.52301258]
 [ 0.38912135]
 [ 0.37656903]
 [ 0.57322174]
 [ 0.51046026]
 [ 0.41841003]
 [ 0.53974897]
 [ 0.50627613]
 [ 0.59414226]]
测试集上一个批次数据的前10个数据
 [[ 0.61087865]
 [ 0.40167364]
 [ 0.57740587]
 [ 0.52301258]
 [ 0.53974897]
 [ 0.57322174]
 [ 0.42259413]
 [ 0.53556484]
 [ 0.50209206]
 [ 0.54811716]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]]
 13%|        | 6500/50002 [1:15:09<25:36:53,  2.12s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]
 [ 0.4653202]]
 13%|        | 6549/50002 [1:15:41<7:43:22,  1.56it/s]Generation 6550: train Loss = 0.00655
Generation 6550: test Loss = 0.00318
 13%|        | 6599/50002 [1:16:16<7:41:38,  1.57it/s]Generation 6600: train Loss = 0.00606
 13%|        | 6600/50002 [1:16:20<20:25:10,  1.69s/it]Generation 6600: test Loss = 0.00500
 13%|        | 6649/50002 [1:16:51<7:41:25,  1.57it/s]Generation 6650: train Loss = 0.00529
 13%|        | 6650/50002 [1:16:56<20:20:36,  1.69s/it]Generation 6650: test Loss = 0.00373
 13%|        | 6699/50002 [1:17:27<7:41:56,  1.56it/s]Generation 6700: train Loss = 0.00546
 13%|        | 6700/50002 [1:17:31<20:19:55,  1.69s/it]Generation 6700: test Loss = 0.00427
 13%|        | 6749/50002 [1:18:02<7:40:41,  1.56it/s]Generation 6750: train Loss = 0.00524
Generation 6750: test Loss = 0.00638
 14%|        | 6799/50002 [1:18:38<7:36:15,  1.58it/s]Generation 6800: train Loss = 0.00473
Generation 6800: test Loss = 0.00393
 14%|        | 6849/50002 [1:19:13<7:39:36,  1.56it/s]Generation 6850: train Loss = 0.00550
 14%|        | 6850/50002 [1:19:17<20:25:18,  1.70s/it]Generation 6850: test Loss = 0.00326
 14%|        | 6899/50002 [1:19:49<7:39:08,  1.56it/s]Generation 6900: train Loss = 0.00559
 14%|        | 6900/50002 [1:19:53<20:20:34,  1.70s/it]Generation 6900: test Loss = 0.00471
 14%|        | 6949/50002 [1:20:24<7:34:57,  1.58it/s]Generation 6950: train Loss = 0.00504
Generation 6950: test Loss = 0.00421
 14%|        | 6999/50002 [1:20:59<7:35:42,  1.57it/s]Generation 7000: train Loss = 0.00568
Generation 7000: test Loss = 0.00518
训练集上一个批次数据的前10个数据
 [[ 0.41422594]
 [ 0.38075313]
 [ 0.51464432]
 [ 0.42677826]
 [ 0.43514645]
 [ 0.44769874]
 [ 0.43096235]
 [ 0.48535565]
 [ 0.44769874]
 [ 0.60669458]]
测试集上一个批次数据的前10个数据
 [[ 0.35146442]
 [ 0.52719665]
 [ 0.53556484]
 [ 0.48117155]
 [ 0.52719665]
 [ 0.48117155]
 [ 0.52719665]
 [ 0.38912135]
 [ 0.52301258]
 [ 0.53556484]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]]
测试集上一个批次数据中通过inference后的前10个输出结果
 14%|        | 7000/50002 [1:21:05<26:49:11,  2.25s/it][[ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]
 [ 0.50459838]]
 14%|        | 7049/50002 [1:21:37<7:37:43,  1.56it/s]Generation 7050: train Loss = 0.00494
Generation 7050: test Loss = 0.00483
 14%|        | 7099/50002 [1:22:12<7:39:10,  1.56it/s]Generation 7100: train Loss = 0.00369
Generation 7100: test Loss = 0.00528
 14%|        | 7149/50002 [1:22:48<7:36:19,  1.57it/s]Generation 7150: train Loss = 0.00526
Generation 7150: test Loss = 0.00448
 14%|        | 7199/50002 [1:23:23<7:36:53,  1.56it/s]Generation 7200: train Loss = 0.00480
 14%|        | 7200/50002 [1:23:28<20:39:29,  1.74s/it]Generation 7200: test Loss = 0.00471
 14%|        | 7249/50002 [1:23:59<7:33:42,  1.57it/s]Generation 7250: train Loss = 0.00508
 14%|        | 7250/50002 [1:24:03<20:39:31,  1.74s/it]Generation 7250: test Loss = 0.00463
 15%|        | 7299/50002 [1:24:34<7:35:45,  1.56it/s]Generation 7300: train Loss = 0.00475
 15%|        | 7300/50002 [1:24:39<20:39:53,  1.74s/it]Generation 7300: test Loss = 0.00357
 15%|        | 7349/50002 [1:25:10<7:37:04,  1.56it/s]Generation 7350: train Loss = 0.00452
 15%|        | 7350/50002 [1:25:14<20:43:03,  1.75s/it]Generation 7350: test Loss = 0.00375
 15%|        | 7399/50002 [1:25:46<7:31:03,  1.57it/s]Generation 7400: train Loss = 0.00437
 15%|        | 7400/50002 [1:25:50<20:37:46,  1.74s/it]Generation 7400: test Loss = 0.00423
 15%|        | 7449/50002 [1:26:21<7:27:05,  1.59it/s]Generation 7450: train Loss = 0.00477
 15%|        | 7450/50002 [1:26:26<20:43:52,  1.75s/it]Generation 7450: test Loss = 0.00425
 15%|        | 7499/50002 [1:26:57<7:30:39,  1.57it/s]Generation 7500: train Loss = 0.00476
Generation 7500: test Loss = 0.00321
训练集上一个批次数据的前10个数据
 [[ 0.41004184]
 [ 0.40167364]
 [ 0.49372384]
 [ 0.48535565]
 [ 0.56066948]
 [ 0.36820084]
 [ 0.44351465]
 [ 0.52719665]
 [ 0.48535565]
 [ 0.45606694]]
测试集上一个批次数据的前10个数据
 [[ 0.41422594]
 [ 0.45606694]
 [ 0.57322174]
 [ 0.45188284]
 [ 0.47698745]
 [ 0.48535565]
 [ 0.44769874]
 [ 0.48953974]
 [ 0.48117155]
 [ 0.54811716]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]]
 15%|        | 7500/50002 [1:27:03<25:54:07,  2.19s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]
 [ 0.49593249]]
 15%|        | 7549/50002 [1:27:34<7:29:32,  1.57it/s]Generation 7550: train Loss = 0.00564
 15%|        | 7550/50002 [1:27:38<21:29:50,  1.82s/it]Generation 7550: test Loss = 0.00415
 15%|        | 7599/50002 [1:28:10<7:30:12,  1.57it/s]Generation 7600: train Loss = 0.00484
Generation 7600: test Loss = 0.00530
 15%|        | 7649/50002 [1:28:45<7:30:34,  1.57it/s]Generation 7650: train Loss = 0.00560
Generation 7650: test Loss = 0.00495
 15%|        | 7699/50002 [1:29:21<7:29:49,  1.57it/s]Generation 7700: train Loss = 0.00549
Generation 7700: test Loss = 0.00525
 15%|        | 7749/50002 [1:29:57<7:27:40,  1.57it/s]Generation 7750: train Loss = 0.00474
Generation 7750: test Loss = 0.00398
 16%|        | 7799/50002 [1:30:32<7:31:19,  1.56it/s]Generation 7800: train Loss = 0.00635
 16%|        | 7800/50002 [1:30:37<20:55:40,  1.79s/it]Generation 7800: test Loss = 0.00357
 16%|        | 7849/50002 [1:31:08<7:28:14,  1.57it/s]Generation 7850: train Loss = 0.00495
 16%|        | 7850/50002 [1:31:12<20:49:06,  1.78s/it]Generation 7850: test Loss = 0.00546
 16%|        | 7899/50002 [1:31:44<7:28:58,  1.56it/s]Generation 7900: train Loss = 0.00496
 16%|        | 7900/50002 [1:31:48<20:51:48,  1.78s/it]Generation 7900: test Loss = 0.00527
 16%|        | 7949/50002 [1:32:19<7:28:23,  1.56it/s]Generation 7950: train Loss = 0.00456
 16%|        | 7950/50002 [1:32:24<20:53:34,  1.79s/it]Generation 7950: test Loss = 0.00439
 16%|        | 7999/50002 [1:32:55<7:27:37,  1.56it/s]Generation 8000: train Loss = 0.00525
Generation 8000: test Loss = 0.00468
训练集上一个批次数据的前10个数据
 [[ 0.45606694]
 [ 0.50209206]
 [ 0.40167364]
 [ 0.51464432]
 [ 0.50627613]
 [ 0.48535565]
 [ 0.54393303]
 [ 0.41841003]
 [ 0.47280335]
 [ 0.49790794]]
测试集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.53138077]
 [ 0.31380752]
 [ 0.51464432]
 [ 0.53974897]
 [ 0.52719665]
 [ 0.49372384]
 [ 0.46443516]
 [ 0.46443516]
 [ 0.42677826]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]]
测试集上一个批次数据中通过inference后的前10个输出结果
 16%|        | 8000/50002 [1:33:01<26:13:31,  2.25s/it] [[ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]
 [ 0.49982047]]
 16%|        | 8049/50002 [1:33:32<7:26:36,  1.57it/s]Generation 8050: train Loss = 0.00378
 16%|        | 8050/50002 [1:33:37<21:32:41,  1.85s/it]Generation 8050: test Loss = 0.00478
 16%|        | 8099/50002 [1:34:08<7:30:09,  1.55it/s]Generation 8100: train Loss = 0.00410
 16%|        | 8100/50002 [1:34:13<21:11:05,  1.82s/it]Generation 8100: test Loss = 0.00545
 16%|        | 8149/50002 [1:34:44<7:22:18,  1.58it/s]Generation 8150: train Loss = 0.00428
 16%|        | 8150/50002 [1:34:49<20:54:39,  1.80s/it]Generation 8150: test Loss = 0.00527
 16%|        | 8199/50002 [1:35:20<7:22:31,  1.57it/s]Generation 8200: train Loss = 0.00443
Generation 8200: test Loss = 0.00485
 16%|        | 8249/50002 [1:35:56<7:20:07,  1.58it/s]Generation 8250: train Loss = 0.00432
 16%|        | 8250/50002 [1:36:00<21:00:39,  1.81s/it]Generation 8250: test Loss = 0.00634
 17%|        | 8299/50002 [1:36:32<7:20:38,  1.58it/s]Generation 8300: train Loss = 0.00449
 17%|        | 8300/50002 [1:36:36<21:06:23,  1.82s/it]Generation 8300: test Loss = 0.00467
 17%|        | 8349/50002 [1:37:07<7:22:55,  1.57it/s]Generation 8350: train Loss = 0.00592
Generation 8350: test Loss = 0.00406
 17%|        | 8399/50002 [1:37:43<7:19:56,  1.58it/s]Generation 8400: train Loss = 0.00441
 17%|        | 8400/50002 [1:37:48<21:16:35,  1.84s/it]Generation 8400: test Loss = 0.00454
 17%|        | 8449/50002 [1:38:19<7:22:10,  1.57it/s]Generation 8450: train Loss = 0.00457
Generation 8450: test Loss = 0.00379
 17%|        | 8499/50002 [1:38:55<7:18:28,  1.58it/s]Generation 8500: train Loss = 0.00571
Generation 8500: test Loss = 0.00433
训练集上一个批次数据的前10个数据
 [[ 0.46025103]
 [ 0.38493723]
 [ 0.41841003]
 [ 0.48535565]
 [ 0.48535565]
 [ 0.51046026]
 [ 0.53556484]
 [ 0.55648535]
 [ 0.52719665]
 [ 0.48117155]]
测试集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.46861926]
 [ 0.48535565]
 [ 0.51046026]
 [ 0.49790794]
 [ 0.50627613]
 [ 0.54811716]
 [ 0.41004184]
 [ 0.45188284]
 [ 0.58577406]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]]
测试集上一个批次数据中通过inference后的前10个输出结果
 17%|        | 8500/50002 [1:39:01<26:14:48,  2.28s/it] [[ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]
 [ 0.4958331]]
 17%|        | 8549/50002 [1:39:32<7:18:03,  1.58it/s]Generation 8550: train Loss = 0.00399
Generation 8550: test Loss = 0.00452
 17%|        | 8599/50002 [1:40:08<7:18:06,  1.58it/s]Generation 8600: train Loss = 0.00382
Generation 8600: test Loss = 0.00496
 17%|        | 8649/50002 [1:40:44<7:17:26,  1.58it/s]Generation 8650: train Loss = 0.00597
Generation 8650: test Loss = 0.00494
 17%|        | 8699/50002 [1:41:20<7:20:16,  1.56it/s]Generation 8700: train Loss = 0.00405
 17%|        | 8700/50002 [1:41:25<21:25:58,  1.87s/it]Generation 8700: test Loss = 0.00449
 17%|        | 8749/50002 [1:41:56<7:15:42,  1.58it/s]Generation 8750: train Loss = 0.00414
 17%|        | 8750/50002 [1:42:01<21:31:16,  1.88s/it]Generation 8750: test Loss = 0.00413
 18%|        | 8799/50002 [1:42:32<7:20:23,  1.56it/s]Generation 8800: train Loss = 0.00492
 18%|        | 8800/50002 [1:42:37<22:37:44,  1.98s/it]Generation 8800: test Loss = 0.00456
 18%|        | 8849/50002 [1:43:09<7:16:07,  1.57it/s]Generation 8850: train Loss = 0.00472
Generation 8850: test Loss = 0.00340
 18%|        | 8899/50002 [1:43:45<7:14:17,  1.58it/s]Generation 8900: train Loss = 0.00548
Generation 8900: test Loss = 0.00556
 18%|        | 8949/50002 [1:44:21<7:15:57,  1.57it/s]Generation 8950: train Loss = 0.00504
Generation 8950: test Loss = 0.00495
 18%|        | 8999/50002 [1:44:57<7:15:31,  1.57it/s]Generation 9000: train Loss = 0.00616
Generation 9000: test Loss = 0.00455
训练集上一个批次数据的前10个数据
 [[ 0.54393303]
 [ 0.56485355]
 [ 0.51046026]
 [ 0.48953974]
 [ 0.55648535]
 [ 0.46443516]
 [ 0.51046026]
 [ 0.58995813]
 [ 0.41841003]
 [ 0.36401674]]
测试集上一个批次数据的前10个数据
 [[ 0.54393303]
 [ 0.43096235]
 [ 0.57740587]
 [ 0.48117155]
 [ 0.50209206]
 [ 0.43933055]
 [ 0.53556484]
 [ 0.59832639]
 [ 0.49790794]
 [ 0.52719665]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]]
 18%|        | 9000/50002 [1:45:03<26:39:07,  2.34s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]
 [ 0.48620552]]
 18%|        | 9049/50002 [1:45:34<7:10:25,  1.59it/s]Generation 9050: train Loss = 0.00533
 18%|        | 9050/50002 [1:45:39<22:21:11,  1.97s/it]Generation 9050: test Loss = 0.00437
 18%|        | 9099/50002 [1:46:11<7:09:24,  1.59it/s]Generation 9100: train Loss = 0.00425
 18%|        | 9100/50002 [1:46:16<21:53:38,  1.93s/it]Generation 9100: test Loss = 0.00464
 18%|        | 9149/50002 [1:46:47<7:12:52,  1.57it/s]Generation 9150: train Loss = 0.00508
 18%|        | 9150/50002 [1:46:52<21:38:52,  1.91s/it]Generation 9150: test Loss = 0.00480
 18%|        | 9199/50002 [1:47:23<7:13:29,  1.57it/s]Generation 9200: train Loss = 0.00490
 18%|        | 9200/50002 [1:47:28<21:31:42,  1.90s/it]Generation 9200: test Loss = 0.00461
 18%|        | 9249/50002 [1:47:59<7:14:23,  1.56it/s]Generation 9250: train Loss = 0.00566
Generation 9250: test Loss = 0.00440
 19%|        | 9299/50002 [1:48:35<7:14:07,  1.56it/s]Generation 9300: train Loss = 0.00457
 19%|        | 9300/50002 [1:48:40<21:39:16,  1.92s/it]Generation 9300: test Loss = 0.00375
 19%|        | 9349/50002 [1:49:11<7:10:16,  1.57it/s]Generation 9350: train Loss = 0.00378
Generation 9350: test Loss = 0.00372
 19%|        | 9399/50002 [1:49:47<7:12:43,  1.56it/s]Generation 9400: train Loss = 0.00465
Generation 9400: test Loss = 0.00402
 19%|        | 9449/50002 [1:50:24<7:12:15,  1.56it/s]Generation 9450: train Loss = 0.00559
Generation 9450: test Loss = 0.00464
 19%|        | 9499/50002 [1:51:00<7:10:08,  1.57it/s]Generation 9500: train Loss = 0.00663
Generation 9500: test Loss = 0.00363
训练集上一个批次数据的前10个数据
 [[ 0.45606694]
 [ 0.54393303]
 [ 0.50627613]
 [ 0.49372384]
 [ 0.51882845]
 [ 0.49790794]
 [ 0.43514645]
 [ 0.57740587]
 [ 0.48117155]
 [ 0.50209206]]
测试集上一个批次数据的前10个数据
 [[ 0.53556484]
 [ 0.53974897]
 [ 0.45188284]
 [ 0.49372384]
 [ 0.58158994]
 [ 0.53556484]
 [ 0.44351465]
 [ 0.46443516]
 [ 0.47280335]
 [ 0.52301258]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]]
 19%|        | 9500/50002 [1:51:06<26:35:24,  2.36s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]
 [ 0.49156216]]
 19%|        | 9549/50002 [1:51:37<7:07:56,  1.58it/s]Generation 9550: train Loss = 0.00423
Generation 9550: test Loss = 0.00441
 19%|        | 9599/50002 [1:52:13<7:09:10,  1.57it/s]Generation 9600: train Loss = 0.00514
 19%|        | 9600/50002 [1:52:18<22:00:02,  1.96s/it]Generation 9600: test Loss = 0.00377
 19%|        | 9649/50002 [1:52:50<7:06:50,  1.58it/s]Generation 9650: train Loss = 0.00533
 19%|        | 9650/50002 [1:52:55<21:47:41,  1.94s/it]Generation 9650: test Loss = 0.00540
 19%|        | 9699/50002 [1:53:26<7:08:50,  1.57it/s]Generation 9700: train Loss = 0.00529
Generation 9700: test Loss = 0.00444
 19%|        | 9749/50002 [1:54:02<7:08:36,  1.57it/s]Generation 9750: train Loss = 0.00518
Generation 9750: test Loss = 0.00596
 20%|        | 9799/50002 [1:54:38<7:07:21,  1.57it/s]Generation 9800: train Loss = 0.00450
 20%|        | 9800/50002 [1:54:43<21:41:09,  1.94s/it]Generation 9800: test Loss = 0.00390
 20%|        | 9849/50002 [1:55:15<7:07:57,  1.56it/s]Generation 9850: train Loss = 0.00462
 20%|        | 9850/50002 [1:55:20<21:43:28,  1.95s/it]Generation 9850: test Loss = 0.00388
 20%|        | 9899/50002 [1:55:51<7:07:30,  1.56it/s]Generation 9900: train Loss = 0.00447
 20%|        | 9900/50002 [1:55:56<21:48:10,  1.96s/it]Generation 9900: test Loss = 0.00510
 20%|        | 9949/50002 [1:56:27<7:03:48,  1.58it/s]Generation 9950: train Loss = 0.00504
 20%|        | 9950/50002 [1:56:32<21:44:19,  1.95s/it]Generation 9950: test Loss = 0.00526
 20%|        | 9999/50002 [1:57:04<7:06:00,  1.57it/s]Generation 10000: train Loss = 0.00474
Generation 10000: test Loss = 0.00457
训练集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.54811716]
 [ 0.71966529]
 [ 0.38493723]
 [ 0.48953974]
 [ 0.53138077]
 [ 0.55230123]
 [ 0.50627613]
 [ 0.53556484]
 [ 0.41004184]]
测试集上一个批次数据的前10个数据
 [[ 0.40167364]
 [ 0.58577406]
 [ 0.51046026]
 [ 0.42677826]
 [ 0.51464432]
 [ 0.44769874]
 [ 0.46443516]
 [ 0.36401674]
 [ 0.55230123]
 [ 0.36820084]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]]
 20%|        | 10000/50002 [1:57:10<26:50:54,  2.42s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]
 [ 0.48796263]]
 20%|        | 10049/50002 [1:58:16<7:04:31,  1.57it/s]Generation 10050: train Loss = 0.00404
 20%|        | 10050/50002 [1:58:21<22:22:53,  2.02s/it]Generation 10050: test Loss = 0.00411
 20%|        | 10099/50002 [1:58:53<7:05:36,  1.56it/s]Generation 10100: train Loss = 0.00393
Generation 10100: test Loss = 0.00331
 20%|        | 10149/50002 [1:59:29<7:07:51,  1.55it/s]Generation 10150: train Loss = 0.00528
Generation 10150: test Loss = 0.00542
 20%|        | 10199/50002 [2:00:05<7:06:51,  1.55it/s]Generation 10200: train Loss = 0.00594
Generation 10200: test Loss = 0.00637
 20%|        | 10249/50002 [2:00:42<7:01:12,  1.57it/s]Generation 10250: train Loss = 0.00703
Generation 10250: test Loss = 0.00456
 21%|        | 10299/50002 [2:01:18<7:04:33,  1.56it/s]Generation 10300: train Loss = 0.00513
 21%|        | 10300/50002 [2:01:23<21:54:39,  1.99s/it]Generation 10300: test Loss = 0.00468
 21%|        | 10349/50002 [2:01:55<7:01:44,  1.57it/s]Generation 10350: train Loss = 0.00359
 21%|        | 10350/50002 [2:02:00<21:51:24,  1.98s/it]Generation 10350: test Loss = 0.00464
 21%|        | 10399/50002 [2:02:31<7:03:46,  1.56it/s]Generation 10400: train Loss = 0.00723
Generation 10400: test Loss = 0.00435
 21%|        | 10449/50002 [2:03:08<6:59:07,  1.57it/s]Generation 10450: train Loss = 0.00443
 21%|        | 10450/50002 [2:03:13<21:53:11,  1.99s/it]Generation 10450: test Loss = 0.00524
 21%|        | 10499/50002 [2:03:44<6:59:48,  1.57it/s]Generation 10500: train Loss = 0.00606
Generation 10500: test Loss = 0.00445
训练集上一个批次数据的前10个数据
 [[ 0.36820084]
 [ 0.46025103]
 [ 0.58995813]
 [ 0.52719665]
 [ 0.50209206]
 [ 0.44769874]
 [ 0.50627613]
 [ 0.55230123]
 [ 0.43096235]
 [ 0.45606694]]
测试集上一个批次数据的前10个数据
 [[ 0.56485355]
 [ 0.51882845]
 [ 0.41422594]
 [ 0.48953974]
 [ 0.48535565]
 [ 0.48117155]
 [ 0.49790794]
 [ 0.46861926]
 [ 0.43514645]
 [ 0.48535565]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]]
 21%|        | 10500/50002 [2:03:51<27:07:11,  2.47s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]
 [ 0.47972023]]
 21%|        | 10549/50002 [2:04:22<7:00:12,  1.56it/s]Generation 10550: train Loss = 0.00573
Generation 10550: test Loss = 0.00444
 21%|        | 10599/50002 [2:04:59<6:58:12,  1.57it/s]Generation 10600: train Loss = 0.00541
Generation 10600: test Loss = 0.00487
 21%|       | 10649/50002 [2:05:35<6:58:54,  1.57it/s]Generation 10650: train Loss = 0.00591
Generation 10650: test Loss = 0.00512
 21%|       | 10699/50002 [2:06:12<6:56:14,  1.57it/s]Generation 10700: train Loss = 0.00468
 21%|       | 10700/50002 [2:06:17<22:09:17,  2.03s/it]Generation 10700: test Loss = 0.00515
 21%|       | 10749/50002 [2:06:48<6:57:56,  1.57it/s]Generation 10750: train Loss = 0.00465
 21%|       | 10750/50002 [2:06:53<21:59:57,  2.02s/it]Generation 10750: test Loss = 0.00454
 22%|       | 10799/50002 [2:07:25<6:55:58,  1.57it/s]Generation 10800: train Loss = 0.00534
 22%|       | 10800/50002 [2:07:30<22:03:23,  2.03s/it]Generation 10800: test Loss = 0.00449
 22%|       | 10849/50002 [2:08:01<6:58:59,  1.56it/s]Generation 10850: train Loss = 0.00609
 22%|       | 10850/50002 [2:08:07<22:07:15,  2.03s/it]Generation 10850: test Loss = 0.00369
 22%|       | 10899/50002 [2:08:38<6:56:56,  1.56it/s]Generation 10900: train Loss = 0.00533
 22%|       | 10900/50002 [2:08:43<22:19:46,  2.06s/it]Generation 10900: test Loss = 0.00535
 22%|       | 10949/50002 [2:09:15<6:54:56,  1.57it/s]Generation 10950: train Loss = 0.00498
 22%|       | 10950/50002 [2:09:20<22:07:52,  2.04s/it]Generation 10950: test Loss = 0.00449
 22%|       | 10999/50002 [2:09:51<6:55:28,  1.56it/s]Generation 11000: train Loss = 0.00478
Generation 11000: test Loss = 0.00410
训练集上一个批次数据的前10个数据
 [[ 0.49790794]
 [ 0.51882845]
 [ 0.53138077]
 [ 0.58995813]
 [ 0.48535565]
 [ 0.59414226]
 [ 0.50209206]
 [ 0.53556484]
 [ 0.53138077]
 [ 0.47280335]]
测试集上一个批次数据的前10个数据
 [[ 0.53556484]
 [ 0.51464432]
 [ 0.54811716]
 [ 0.53974897]
 [ 0.58995813]
 [ 0.48117155]
 [ 0.42677826]
 [ 0.49790794]
 [ 0.63598329]
 [ 0.51882845]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]
 [ 0.49653262]]
 22%|       | 11049/50002 [2:10:29<6:54:35,  1.57it/s]Generation 11050: train Loss = 0.00460
 22%|       | 11050/50002 [2:10:34<22:32:22,  2.08s/it]Generation 11050: test Loss = 0.00411
 22%|       | 11099/50002 [2:11:06<6:50:54,  1.58it/s]Generation 11100: train Loss = 0.00730
Generation 11100: test Loss = 0.00401
 22%|       | 11149/50002 [2:11:42<6:52:06,  1.57it/s]Generation 11150: train Loss = 0.00647
 22%|       | 11150/50002 [2:11:48<22:03:37,  2.04s/it]Generation 11150: test Loss = 0.00385
 22%|       | 11199/50002 [2:12:19<6:50:45,  1.57it/s]Generation 11200: train Loss = 0.00511
 22%|       | 11200/50002 [2:12:24<22:25:35,  2.08s/it]Generation 11200: test Loss = 0.00433
 22%|       | 11249/50002 [2:12:56<6:49:58,  1.58it/s]Generation 11250: train Loss = 0.00500
Generation 11250: test Loss = 0.00374
 23%|       | 11299/50002 [2:13:32<6:51:41,  1.57it/s]Generation 11300: train Loss = 0.00518
Generation 11300: test Loss = 0.00366
 23%|       | 11349/50002 [2:14:09<6:49:00,  1.58it/s]Generation 11350: train Loss = 0.00584
 23%|       | 11350/50002 [2:14:14<22:11:13,  2.07s/it]Generation 11350: test Loss = 0.00561
 23%|       | 11399/50002 [2:14:45<6:49:59,  1.57it/s]Generation 11400: train Loss = 0.00418
Generation 11400: test Loss = 0.00525
 23%|       | 11449/50002 [2:15:22<6:49:36,  1.57it/s]Generation 11450: train Loss = 0.00507
Generation 11450: test Loss = 0.00579
 23%|       | 11499/50002 [2:15:59<6:52:48,  1.55it/s]Generation 11500: train Loss = 0.00346
Generation 11500: test Loss = 0.00510
训练集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.63598329]
 [ 0.56485355]
 [ 0.49372384]
 [ 0.40167364]
 [ 0.56903768]
 [ 0.47280335]
 [ 0.51046026]
 [ 0.57322174]
 [ 0.60669458]]
测试集上一个批次数据的前10个数据
 [[ 0.38912135]
 [ 0.47280335]
 [ 0.46861926]
 [ 0.54393303]
 [ 0.52719665]
 [ 0.56485355]
 [ 0.37656903]
 [ 0.38912135]
 [ 0.55230123]
 [ 0.43096235]]
 23%|       | 11500/50002 [2:16:06<27:04:38,  2.53s/it]训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]
 [ 0.49397543]]
 23%|       | 11549/50002 [2:16:37<6:50:15,  1.56it/s]Generation 11550: train Loss = 0.00554
Generation 11550: test Loss = 0.00435
 23%|       | 11599/50002 [2:17:14<6:47:14,  1.57it/s]Generation 11600: train Loss = 0.00647
 23%|       | 11600/50002 [2:17:19<22:27:13,  2.10s/it]Generation 11600: test Loss = 0.00522
 23%|       | 11649/50002 [2:17:51<6:50:31,  1.56it/s]Generation 11650: train Loss = 0.00515
 23%|       | 11650/50002 [2:17:56<22:19:09,  2.10s/it]Generation 11650: test Loss = 0.00509
 23%|       | 11699/50002 [2:18:27<6:48:37,  1.56it/s]Generation 11700: train Loss = 0.00468
 23%|       | 11700/50002 [2:18:33<22:16:26,  2.09s/it]Generation 11700: test Loss = 0.00560
 23%|       | 11749/50002 [2:19:04<6:47:07,  1.57it/s]Generation 11750: train Loss = 0.00763
 23%|       | 11750/50002 [2:19:10<22:17:01,  2.10s/it]Generation 11750: test Loss = 0.00412
 24%|       | 11799/50002 [2:19:41<6:48:28,  1.56it/s]Generation 11800: train Loss = 0.00526
Generation 11800: test Loss = 0.00531
 24%|       | 11849/50002 [2:20:18<6:44:30,  1.57it/s]Generation 11850: train Loss = 0.00490
Generation 11850: test Loss = 0.00483
 24%|       | 11899/50002 [2:20:54<6:50:46,  1.55it/s]Generation 11900: train Loss = 0.00522
Generation 11900: test Loss = 0.00382
 24%|       | 11949/50002 [2:21:31<6:43:52,  1.57it/s]Generation 11950: train Loss = 0.00512
Generation 11950: test Loss = 0.00444
 24%|       | 11999/50002 [2:22:08<6:44:07,  1.57it/s]Generation 12000: train Loss = 0.00549
Generation 12000: test Loss = 0.00501
训练集上一个批次数据的前10个数据
 [[ 0.53138077]
 [ 0.49790794]
 [ 0.42677826]
 [ 0.48953974]
 [ 0.46025103]
 [ 0.58158994]
 [ 0.53556484]
 [ 0.50209206]
 [ 0.41841003]
 [ 0.51464432]]
测试集上一个批次数据的前10个数据
 [[ 0.53974897]
 [ 0.45606694]
 [ 0.59832639]
 [ 0.43514645]
 [ 0.48117155]
 [ 0.52719665]
 [ 0.50209206]
 [ 0.44769874]
 [ 0.59832639]
 [ 0.53556484]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]]
 24%|       | 12000/50002 [2:22:15<27:16:50,  2.58s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]
 [ 0.49722949]]
 24%|       | 12049/50002 [2:22:46<6:44:28,  1.56it/s]Generation 12050: train Loss = 0.00717
Generation 12050: test Loss = 0.00767
 24%|       | 12099/50002 [2:23:23<6:41:08,  1.57it/s]Generation 12100: train Loss = 0.00705
 24%|       | 12100/50002 [2:23:29<22:26:54,  2.13s/it]Generation 12100: test Loss = 0.00414
 24%|       | 12149/50002 [2:24:00<6:43:02,  1.57it/s]Generation 12150: train Loss = 0.00613
Generation 12150: test Loss = 0.00427
 24%|       | 12199/50002 [2:24:37<6:44:16,  1.56it/s]Generation 12200: train Loss = 0.00626
Generation 12200: test Loss = 0.00372
 24%|       | 12249/50002 [2:25:14<6:42:44,  1.56it/s]Generation 12250: train Loss = 0.00430
 24%|       | 12250/50002 [2:25:19<22:23:48,  2.14s/it]Generation 12250: test Loss = 0.00417
 25%|       | 12299/50002 [2:25:51<6:41:07,  1.57it/s]Generation 12300: train Loss = 0.00536
Generation 12300: test Loss = 0.00426
 25%|       | 12349/50002 [2:26:28<6:38:18,  1.58it/s]Generation 12350: train Loss = 0.00626
 25%|       | 12350/50002 [2:26:33<22:26:42,  2.15s/it]Generation 12350: test Loss = 0.00465
 25%|       | 12399/50002 [2:27:05<6:40:08,  1.57it/s]Generation 12400: train Loss = 0.00642
Generation 12400: test Loss = 0.00651
 25%|       | 12449/50002 [2:27:42<6:41:47,  1.56it/s]Generation 12450: train Loss = 0.00429
Generation 12450: test Loss = 0.00425
 25%|       | 12499/50002 [2:28:19<6:38:59,  1.57it/s]Generation 12500: train Loss = 0.00489
Generation 12500: test Loss = 0.00478
训练集上一个批次数据的前10个数据
 [[ 0.39748955]
 [ 0.55230123]
 [ 0.49372384]
 [ 0.53138077]
 [ 0.53556484]
 [ 0.49372384]
 [ 0.56485355]
 [ 0.56903768]
 [ 0.41004184]
 [ 0.49790794]]
测试集上一个批次数据的前10个数据
 [[ 0.63598329]
 [ 0.54811716]
 [ 0.48535565]
 [ 0.44351465]
 [ 0.38912135]
 [ 0.48535565]
 [ 0.39748955]
 [ 0.54811716]
 [ 0.58158994]
 [ 0.57740587]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]]
 25%|       | 12500/50002 [2:28:26<27:10:05,  2.61s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]
 [ 0.473344]]
 25%|       | 12549/50002 [2:28:57<6:37:53,  1.57it/s]Generation 12550: train Loss = 0.00444
 25%|       | 12550/50002 [2:29:03<22:50:00,  2.19s/it]Generation 12550: test Loss = 0.00473
 25%|       | 12599/50002 [2:29:34<6:36:35,  1.57it/s]Generation 12600: train Loss = 0.00352
Generation 12600: test Loss = 0.00486
 25%|       | 12649/50002 [2:30:11<6:38:29,  1.56it/s]Generation 12650: train Loss = 0.00410
Generation 12650: test Loss = 0.00423
 25%|       | 12699/50002 [2:30:48<6:33:45,  1.58it/s]Generation 12700: train Loss = 0.00579
 25%|       | 12700/50002 [2:30:54<22:25:15,  2.16s/it]Generation 12700: test Loss = 0.00492
 25%|       | 12749/50002 [2:31:25<6:38:25,  1.56it/s]Generation 12750: train Loss = 0.00594
Generation 12750: test Loss = 0.00480
 26%|       | 12799/50002 [2:32:02<6:32:43,  1.58it/s]Generation 12800: train Loss = 0.00422
 26%|       | 12800/50002 [2:32:08<22:36:12,  2.19s/it]Generation 12800: test Loss = 0.00448
 26%|       | 12849/50002 [2:32:39<6:38:34,  1.55it/s]Generation 12850: train Loss = 0.00505
 26%|       | 12850/50002 [2:32:45<22:30:08,  2.18s/it]Generation 12850: test Loss = 0.00454
 26%|       | 12899/50002 [2:33:16<6:33:40,  1.57it/s]Generation 12900: train Loss = 0.00392
Generation 12900: test Loss = 0.00549
 26%|       | 12949/50002 [2:33:53<6:37:04,  1.56it/s]Generation 12950: train Loss = 0.00486
 26%|       | 12950/50002 [2:33:59<22:26:12,  2.18s/it]Generation 12950: test Loss = 0.00491
 26%|       | 12999/50002 [2:34:30<6:34:11,  1.56it/s]Generation 13000: train Loss = 0.00450
Generation 13000: test Loss = 0.00434
训练集上一个批次数据的前10个数据
 [[ 0.35983264]
 [ 0.49790794]
 [ 0.39330545]
 [ 0.57322174]
 [ 0.39330545]
 [ 0.51464432]
 [ 0.49790794]
 [ 0.70711297]
 [ 0.50627613]
 [ 0.44351465]]
测试集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.50209206]
 [ 0.49790794]
 [ 0.63598329]
 [ 0.49790794]
 [ 0.38075313]
 [ 0.51464432]
 [ 0.54393303]
 [ 0.58995813]
 [ 0.50209206]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]
 [ 0.52605063]]
 26%|       | 13049/50002 [2:35:08<6:34:36,  1.56it/s]Generation 13050: train Loss = 0.00524
 26%|       | 13050/50002 [2:35:14<22:59:07,  2.24s/it]Generation 13050: test Loss = 0.00519
 26%|       | 13099/50002 [2:35:46<6:33:10,  1.56it/s]Generation 13100: train Loss = 0.00534
Generation 13100: test Loss = 0.00501
 26%|       | 13149/50002 [2:36:23<6:30:50,  1.57it/s]Generation 13150: train Loss = 0.00489
 26%|       | 13150/50002 [2:36:29<22:30:28,  2.20s/it]Generation 13150: test Loss = 0.00375
 26%|       | 13199/50002 [2:37:00<6:28:56,  1.58it/s]Generation 13200: train Loss = 0.00482
Generation 13200: test Loss = 0.00481
 26%|       | 13249/50002 [2:37:37<6:31:06,  1.57it/s]Generation 13250: train Loss = 0.00409
 26%|       | 13250/50002 [2:37:43<22:27:44,  2.20s/it]Generation 13250: test Loss = 0.00387
 27%|       | 13299/50002 [2:38:14<6:30:19,  1.57it/s]Generation 13300: train Loss = 0.00512
Generation 13300: test Loss = 0.00528
 27%|       | 13349/50002 [2:38:51<6:28:39,  1.57it/s]Generation 13350: train Loss = 0.00441
Generation 13350: test Loss = 0.00521
 27%|       | 13399/50002 [2:39:29<6:26:52,  1.58it/s]Generation 13400: train Loss = 0.00580
Generation 13400: test Loss = 0.00455
 27%|       | 13449/50002 [2:40:06<6:29:08,  1.57it/s]Generation 13450: train Loss = 0.00485
 27%|       | 13450/50002 [2:40:12<22:34:47,  2.22s/it]Generation 13450: test Loss = 0.00399
 27%|       | 13499/50002 [2:40:43<6:28:12,  1.57it/s]Generation 13500: train Loss = 0.00591
Generation 13500: test Loss = 0.00393
训练集上一个批次数据的前10个数据
 [[ 0.53556484]
 [ 0.54393303]
 [ 0.49372384]
 [ 0.51046026]
 [ 0.48535565]
 [ 0.49790794]
 [ 0.58577406]
 [ 0.58577406]
 [ 0.50627613]
 [ 0.51046026]]
测试集上一个批次数据的前10个数据
 [[ 0.54811716]
 [ 0.51882845]
 [ 0.45606694]
 [ 0.58577406]
 [ 0.42677826]
 [ 0.46025103]
 [ 0.45188284]
 [ 0.40167364]
 [ 0.54811716]
 [ 0.49790794]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]]
 27%|       | 13500/50002 [2:40:50<27:15:00,  2.69s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]
 [ 0.49910393]]
 27%|       | 13549/50002 [2:41:21<6:29:13,  1.56it/s]Generation 13550: train Loss = 0.00531
 27%|       | 13550/50002 [2:41:27<23:08:54,  2.29s/it]Generation 13550: test Loss = 0.00412
 27%|       | 13599/50002 [2:41:59<6:28:59,  1.56it/s]Generation 13600: train Loss = 0.00391
Generation 13600: test Loss = 0.00483
 27%|       | 13649/50002 [2:42:36<6:27:22,  1.56it/s]Generation 13650: train Loss = 0.00455
Generation 13650: test Loss = 0.00403
 27%|       | 13699/50002 [2:43:13<6:26:29,  1.57it/s]Generation 13700: train Loss = 0.00450
 27%|       | 13700/50002 [2:43:19<22:42:33,  2.25s/it]Generation 13700: test Loss = 0.00506
 27%|       | 13749/50002 [2:43:51<6:26:22,  1.56it/s]Generation 13750: train Loss = 0.00466
 27%|       | 13750/50002 [2:43:57<22:35:18,  2.24s/it]Generation 13750: test Loss = 0.00494
 28%|       | 13799/50002 [2:44:28<6:26:40,  1.56it/s]Generation 13800: train Loss = 0.00447
Generation 13800: test Loss = 0.00460
 28%|       | 13849/50002 [2:45:05<6:24:53,  1.57it/s]Generation 13850: train Loss = 0.00448
 28%|       | 13850/50002 [2:45:11<22:42:33,  2.26s/it]Generation 13850: test Loss = 0.00416
 28%|       | 13899/50002 [2:45:43<6:25:29,  1.56it/s]Generation 13900: train Loss = 0.00589
 28%|       | 13900/50002 [2:45:49<22:38:39,  2.26s/it]Generation 13900: test Loss = 0.00459
 28%|       | 13949/50002 [2:46:20<6:20:31,  1.58it/s]Generation 13950: train Loss = 0.00475
Generation 13950: test Loss = 0.00469
 28%|       | 13999/50002 [2:46:57<6:21:01,  1.57it/s]Generation 14000: train Loss = 0.00425
Generation 14000: test Loss = 0.00423
训练集上一个批次数据的前10个数据
 [[ 0.42677826]
 [ 0.56903768]
 [ 0.45188284]
 [ 0.50627613]
 [ 0.38075313]
 [ 0.39330545]
 [ 0.48953974]
 [ 0.57740587]
 [ 0.48535565]
 [ 0.49790794]]
测试集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.63179916]
 [ 0.33472803]
 [ 0.42677826]
 [ 0.63598329]
 [ 0.46025103]
 [ 0.48953974]
 [ 0.53556484]
 [ 0.55230123]
 [ 0.45606694]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]
 [ 0.49083868]]
 28%|       | 14049/50002 [2:47:36<6:25:17,  1.56it/s]Generation 14050: train Loss = 0.00440
Generation 14050: test Loss = 0.00461
 28%|       | 14099/50002 [2:48:14<6:19:26,  1.58it/s]Generation 14100: train Loss = 0.00415
 28%|       | 14100/50002 [2:48:20<22:45:13,  2.28s/it]Generation 14100: test Loss = 0.00405
 28%|       | 14149/50002 [2:48:51<6:22:59,  1.56it/s]Generation 14150: train Loss = 0.00532
Generation 14150: test Loss = 0.00438
 28%|       | 14199/50002 [2:49:28<6:20:04,  1.57it/s]Generation 14200: train Loss = 0.00449
Generation 14200: test Loss = 0.00494
 28%|       | 14249/50002 [2:50:06<6:20:12,  1.57it/s]Generation 14250: train Loss = 0.00395
Generation 14250: test Loss = 0.00407
 29%|       | 14299/50002 [2:50:43<6:20:30,  1.56it/s]Generation 14300: train Loss = 0.00635
 29%|       | 14300/50002 [2:50:49<22:39:50,  2.29s/it]Generation 14300: test Loss = 0.00470
 29%|       | 14349/50002 [2:51:21<6:17:47,  1.57it/s]Generation 14350: train Loss = 0.00508
 29%|       | 14350/50002 [2:51:27<22:41:58,  2.29s/it]Generation 14350: test Loss = 0.00609
 29%|       | 14399/50002 [2:51:58<6:17:56,  1.57it/s]Generation 14400: train Loss = 0.00447
 29%|       | 14400/50002 [2:52:04<22:43:19,  2.30s/it]Generation 14400: test Loss = 0.00533
 29%|       | 14449/50002 [2:52:36<6:19:40,  1.56it/s]Generation 14450: train Loss = 0.00525
 29%|       | 14450/50002 [2:52:42<22:42:59,  2.30s/it]Generation 14450: test Loss = 0.00437
 29%|       | 14499/50002 [2:53:13<6:15:04,  1.58it/s]Generation 14500: train Loss = 0.00386
Generation 14500: test Loss = 0.00500
训练集上一个批次数据的前10个数据
 [[ 0.42677826]
 [ 0.43933055]
 [ 0.37238494]
 [ 0.53974897]
 [ 0.45188284]
 [ 0.39748955]
 [ 0.42259413]
 [ 0.41841003]
 [ 0.45606694]
 [ 0.54811716]]
测试集上一个批次数据的前10个数据
 [[ 0.52719665]
 [ 0.58995813]
 [ 0.54393303]
 [ 0.37656903]
 [ 0.55648535]
 [ 0.48535565]
 [ 0.62343097]
 [ 0.33054394]
 [ 0.36820084]
 [ 0.55230123]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]]
 29%|       | 14500/50002 [2:53:21<29:06:34,  2.95s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]
 [ 0.47580343]]
 29%|       | 14549/50002 [2:53:52<6:21:04,  1.55it/s]Generation 14550: train Loss = 0.00724
Generation 14550: test Loss = 0.00483
 29%|       | 14599/50002 [2:54:30<6:16:27,  1.57it/s]Generation 14600: train Loss = 0.00637
 29%|       | 14600/50002 [2:54:37<23:39:44,  2.41s/it]Generation 14600: test Loss = 0.00440
 29%|       | 14649/50002 [2:55:08<6:17:53,  1.56it/s]Generation 14650: train Loss = 0.00442
Generation 14650: test Loss = 0.00397
 29%|       | 14699/50002 [2:55:46<6:18:30,  1.55it/s]Generation 14700: train Loss = 0.00470
 29%|       | 14700/50002 [2:55:52<22:48:15,  2.33s/it]Generation 14700: test Loss = 0.00391
 29%|       | 14749/50002 [2:56:23<6:13:26,  1.57it/s]Generation 14750: train Loss = 0.00452
Generation 14750: test Loss = 0.00464
 30%|       | 14799/50002 [2:57:01<6:13:57,  1.57it/s]Generation 14800: train Loss = 0.00453
 30%|       | 14800/50002 [2:57:07<22:52:57,  2.34s/it]Generation 14800: test Loss = 0.00414
 30%|       | 14849/50002 [2:57:38<6:13:22,  1.57it/s]Generation 14850: train Loss = 0.00475
 30%|       | 14850/50002 [2:57:45<22:50:57,  2.34s/it]Generation 14850: test Loss = 0.00458
 30%|       | 14899/50002 [2:58:16<6:15:34,  1.56it/s]Generation 14900: train Loss = 0.00392
Generation 14900: test Loss = 0.00482
 30%|       | 14949/50002 [2:58:53<6:12:39,  1.57it/s]Generation 14950: train Loss = 0.00569
Generation 14950: test Loss = 0.00464
 30%|       | 14999/50002 [2:59:31<6:13:24,  1.56it/s]Generation 15000: train Loss = 0.00573
Generation 15000: test Loss = 0.00562
训练集上一个批次数据的前10个数据
 [[ 0.45188284]
 [ 0.51046026]
 [ 0.61087865]
 [ 0.43514645]
 [ 0.48117155]
 [ 0.49790794]
 [ 0.56903768]
 [ 0.64016736]
 [ 0.49372384]
 [ 0.47698745]]
测试集上一个批次数据的前10个数据
 [[ 0.53974897]
 [ 0.41841003]
 [ 0.45606694]
 [ 0.51464432]
 [ 0.53556484]
 [ 0.51046026]
 [ 0.58995813]
 [ 0.55648535]
 [ 0.56485355]
 [ 0.44351465]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]]
 30%|       | 15000/50002 [2:59:39<27:41:36,  2.85s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]
 [ 0.48396993]]
 30%|       | 15049/50002 [3:00:10<6:11:02,  1.57it/s]Generation 15050: train Loss = 0.00556
 30%|       | 15050/50002 [3:00:17<24:26:46,  2.52s/it]Generation 15050: test Loss = 0.00419
 30%|       | 15099/50002 [3:00:49<6:11:41,  1.57it/s]Generation 15100: train Loss = 0.00459
Generation 15100: test Loss = 0.00432
 30%|       | 15149/50002 [3:01:26<6:10:32,  1.57it/s]Generation 15150: train Loss = 0.00575
 30%|       | 15150/50002 [3:01:33<22:53:07,  2.36s/it]Generation 15150: test Loss = 0.00479
 30%|       | 15199/50002 [3:02:04<6:10:20,  1.57it/s]Generation 15200: train Loss = 0.00488
 30%|       | 15200/50002 [3:02:10<22:54:06,  2.37s/it]Generation 15200: test Loss = 0.00521
 30%|       | 15249/50002 [3:02:42<6:09:38,  1.57it/s]Generation 15250: train Loss = 0.00486
 30%|       | 15250/50002 [3:02:48<22:49:17,  2.36s/it]Generation 15250: test Loss = 0.00465
 31%|       | 15299/50002 [3:03:19<6:07:31,  1.57it/s]Generation 15300: train Loss = 0.00347
Generation 15300: test Loss = 0.00589
 31%|       | 15349/50002 [3:03:57<6:06:27,  1.58it/s]Generation 15350: train Loss = 0.00462
 31%|       | 15350/50002 [3:04:03<22:46:34,  2.37s/it]Generation 15350: test Loss = 0.00497
 31%|       | 15399/50002 [3:04:35<6:07:57,  1.57it/s]Generation 15400: train Loss = 0.00666
Generation 15400: test Loss = 0.00611
 31%|       | 15449/50002 [3:05:12<6:08:52,  1.56it/s]Generation 15450: train Loss = 0.00464
 31%|       | 15450/50002 [3:05:19<22:55:51,  2.39s/it]Generation 15450: test Loss = 0.00500
 31%|       | 15499/50002 [3:05:50<6:03:44,  1.58it/s]Generation 15500: train Loss = 0.00722
Generation 15500: test Loss = 0.00386
训练集上一个批次数据的前10个数据
 [[ 0.50627613]
 [ 0.42259413]
 [ 0.47698745]
 [ 0.54811716]
 [ 0.46443516]
 [ 0.52719665]
 [ 0.54393303]
 [ 0.56066948]
 [ 0.53556484]
 [ 0.44351465]]
测试集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.48117155]
 [ 0.51046026]
 [ 0.62761503]
 [ 0.38075313]
 [ 0.53138077]
 [ 0.46025103]
 [ 0.42259413]
 [ 0.39748955]
 [ 0.46443516]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]]
 31%|       | 15500/50002 [3:05:58<27:28:19,  2.87s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]
 [ 0.48718199]]
 31%|       | 15549/50002 [3:06:29<6:06:54,  1.57it/s]Generation 15550: train Loss = 0.00477
 31%|       | 15550/50002 [3:06:36<23:18:10,  2.43s/it]Generation 15550: test Loss = 0.00450
 31%|       | 15599/50002 [3:07:07<6:02:15,  1.58it/s]Generation 15600: train Loss = 0.00488
 31%|       | 15600/50002 [3:07:14<22:54:26,  2.40s/it]
 31%|      | 15649/50002 [3:07:45<6:06:50,  1.56it/s]Generation 15650: train Loss = 0.00570
Generation 15650: test Loss = 0.00367
 31%|      | 15699/50002 [3:08:23<6:05:23,  1.56it/s]Generation 15700: train Loss = 0.00504
 31%|      | 15700/50002 [3:08:29<22:56:04,  2.41s/it]Generation 15700: test Loss = 0.00385
 31%|      | 15749/50002 [3:09:00<6:03:27,  1.57it/s]Generation 15750: train Loss = 0.00432
Generation 15750: test Loss = 0.00357
 32%|      | 15799/50002 [3:09:38<6:03:01,  1.57it/s]Generation 15800: train Loss = 0.00576
Generation 15800: test Loss = 0.00520
 32%|      | 15849/50002 [3:10:16<6:00:55,  1.58it/s]Generation 15850: train Loss = 0.00540
 32%|      | 15850/50002 [3:10:23<22:48:02,  2.40s/it]Generation 15850: test Loss = 0.00398
 32%|      | 15899/50002 [3:10:54<6:01:04,  1.57it/s]Generation 15900: train Loss = 0.00446
Generation 15900: test Loss = 0.00523
 32%|      | 15949/50002 [3:11:32<6:04:45,  1.56it/s]Generation 15950: train Loss = 0.00432
Generation 15950: test Loss = 0.00420
 32%|      | 15999/50002 [3:12:10<5:59:27,  1.58it/s]Generation 16000: train Loss = 0.00659
Generation 16000: test Loss = 0.00416
训练集上一个批次数据的前10个数据
 [[ 0.55648535]
 [ 0.58995813]
 [ 0.51882845]
 [ 0.42259413]
 [ 0.53556484]
 [ 0.55648535]
 [ 0.56485355]
 [ 0.56903768]
 [ 0.58158994]
 [ 0.46025103]]
测试集上一个批次数据的前10个数据
 [[ 0.58158994]
 [ 0.45188284]
 [ 0.60251045]
 [ 0.33472803]
 [ 0.51046026]
 [ 0.47280335]
 [ 0.47698745]
 [ 0.53556484]
 [ 0.30962342]
 [ 0.45188284]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]]
 32%|      | 16000/50002 [3:12:18<27:21:03,  2.90s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]
 [ 0.4984104]]
 32%|      | 16049/50002 [3:12:49<6:02:00,  1.56it/s]Generation 16050: train Loss = 0.00532
 32%|      | 16050/50002 [3:12:56<23:16:45,  2.47s/it]Generation 16050: test Loss = 0.00654
 32%|      | 16099/50002 [3:13:27<6:04:11,  1.55it/s]Generation 16100: train Loss = 0.00498
Generation 16100: test Loss = 0.00452
 32%|      | 16149/50002 [3:14:05<6:01:09,  1.56it/s]Generation 16150: train Loss = 0.00560
 32%|      | 16150/50002 [3:14:11<22:48:58,  2.43s/it]Generation 16150: test Loss = 0.00452
 32%|      | 16199/50002 [3:14:43<5:58:50,  1.57it/s]Generation 16200: train Loss = 0.00395
 32%|      | 16200/50002 [3:14:49<22:53:38,  2.44s/it]Generation 16200: test Loss = 0.00376
 32%|      | 16249/50002 [3:15:21<6:07:25,  1.53it/s]Generation 16250: train Loss = 0.00414
Generation 16250: test Loss = 0.00430
 33%|      | 16299/50002 [3:15:59<5:56:11,  1.58it/s]Generation 16300: train Loss = 0.00421
 33%|      | 16300/50002 [3:16:05<22:56:21,  2.45s/it]Generation 16300: test Loss = 0.00471
 33%|      | 16349/50002 [3:16:37<5:57:18,  1.57it/s]Generation 16350: train Loss = 0.00526
Generation 16350: test Loss = 0.00518
 33%|      | 16399/50002 [3:17:15<5:57:45,  1.57it/s]Generation 16400: train Loss = 0.00485
Generation 16400: test Loss = 0.00469
 33%|      | 16449/50002 [3:17:53<5:55:37,  1.57it/s]Generation 16450: train Loss = 0.00568
Generation 16450: test Loss = 0.00430
 33%|      | 16499/50002 [3:18:31<5:54:27,  1.58it/s]Generation 16500: train Loss = 0.00475
Generation 16500: test Loss = 0.00442
训练集上一个批次数据的前10个数据
 [[ 0.56903768]
 [ 0.49372384]
 [ 0.47280335]
 [ 0.53556484]
 [ 0.33054394]
 [ 0.41422594]
 [ 0.48117155]
 [ 0.53556484]
 [ 0.53974897]
 [ 0.48117155]]
测试集上一个批次数据的前10个数据
 [[ 0.61924684]
 [ 0.51464432]
 [ 0.56903768]
 [ 0.48117155]
 [ 0.48535565]
 [ 0.49372384]
 [ 0.51464432]
 [ 0.53556484]
 [ 0.42259413]
 [ 0.58577406]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]]
 33%|      | 16500/50002 [3:18:39<27:31:09,  2.96s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]
 [ 0.50018567]]
 33%|      | 16549/50002 [3:19:10<5:58:39,  1.55it/s]Generation 16550: train Loss = 0.00706
 33%|      | 16550/50002 [3:19:17<23:23:41,  2.52s/it]Generation 16550: test Loss = 0.00403
 33%|      | 16599/50002 [3:19:48<5:56:03,  1.56it/s]Generation 16600: train Loss = 0.00520
 33%|      | 16600/50002 [3:19:55<22:54:03,  2.47s/it]Generation 16600: test Loss = 0.00512
 33%|      | 16649/50002 [3:20:26<5:53:03,  1.57it/s]Generation 16650: train Loss = 0.00576
 33%|      | 16650/50002 [3:20:33<23:39:47,  2.55s/it]Generation 16650: test Loss = 0.00447
 33%|      | 16699/50002 [3:21:05<5:53:26,  1.57it/s]Generation 16700: train Loss = 0.00586
 33%|      | 16700/50002 [3:21:11<23:01:52,  2.49s/it]Generation 16700: test Loss = 0.00433
 33%|      | 16749/50002 [3:21:43<5:52:59,  1.57it/s]Generation 16750: train Loss = 0.00496
 33%|      | 16750/50002 [3:21:49<22:54:39,  2.48s/it]Generation 16750: test Loss = 0.00551
 34%|      | 16799/50002 [3:22:21<5:55:14,  1.56it/s]Generation 16800: train Loss = 0.00576
Generation 16800: test Loss = 0.00420
 34%|      | 16849/50002 [3:22:59<5:53:28,  1.56it/s]Generation 16850: train Loss = 0.00542
Generation 16850: test Loss = 0.00400
 34%|      | 16899/50002 [3:23:37<5:51:17,  1.57it/s]Generation 16900: train Loss = 0.00445
 34%|      | 16900/50002 [3:23:44<22:58:43,  2.50s/it]Generation 16900: test Loss = 0.00417
 34%|      | 16949/50002 [3:24:15<5:51:06,  1.57it/s]Generation 16950: train Loss = 0.00466
 34%|      | 16950/50002 [3:24:22<22:54:18,  2.49s/it]Generation 16950: test Loss = 0.00485
 34%|      | 16999/50002 [3:24:53<5:51:40,  1.56it/s]Generation 17000: train Loss = 0.00531
Generation 17000: test Loss = 0.00441
训练集上一个批次数据的前10个数据
 [[ 0.60251045]
 [ 0.47280335]
 [ 0.47280335]
 [ 0.44351465]
 [ 0.40585774]
 [ 0.51464432]
 [ 0.56066948]
 [ 0.34728032]
 [ 0.41422594]
 [ 0.51464432]]
测试集上一个批次数据的前10个数据
 [[ 0.48953974]
 [ 0.43933055]
 [ 0.54811716]
 [ 0.53138077]
 [ 0.51882845]
 [ 0.44351465]
 [ 0.41841003]
 [ 0.46443516]
 [ 0.41841003]
 [ 0.34728032]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]
 [ 0.50045866]]
 34%|      | 17049/50002 [3:25:32<5:49:44,  1.57it/s]Generation 17050: train Loss = 0.00491
Generation 17050: test Loss = 0.00378
 34%|      | 17099/50002 [3:26:11<5:51:29,  1.56it/s]Generation 17100: train Loss = 0.00638
 34%|      | 17100/50002 [3:26:18<23:10:01,  2.53s/it]Generation 17100: test Loss = 0.00485
 34%|      | 17149/50002 [3:26:49<5:47:53,  1.57it/s]Generation 17150: train Loss = 0.00408
Generation 17150: test Loss = 0.00454
 34%|      | 17199/50002 [3:27:27<5:49:59,  1.56it/s]Generation 17200: train Loss = 0.00483
 34%|      | 17200/50002 [3:27:34<22:50:07,  2.51s/it]Generation 17200: test Loss = 0.00466
 34%|      | 17249/50002 [3:28:05<5:48:55,  1.56it/s]Generation 17250: train Loss = 0.00605
 34%|      | 17250/50002 [3:28:12<22:52:45,  2.51s/it]Generation 17250: test Loss = 0.00460
 35%|      | 17299/50002 [3:28:44<5:47:46,  1.57it/s]Generation 17300: train Loss = 0.00476
 35%|      | 17300/50002 [3:28:50<22:55:20,  2.52s/it]Generation 17300: test Loss = 0.00531
 35%|      | 17349/50002 [3:29:22<5:48:35,  1.56it/s]Generation 17350: train Loss = 0.00438
Generation 17350: test Loss = 0.00470
 35%|      | 17399/50002 [3:30:00<5:47:03,  1.57it/s]Generation 17400: train Loss = 0.00455
Generation 17400: test Loss = 0.00534
 35%|      | 17449/50002 [3:30:39<5:47:30,  1.56it/s]Generation 17450: train Loss = 0.00478
 35%|      | 17450/50002 [3:30:46<23:20:29,  2.58s/it]Generation 17450: test Loss = 0.00506
 35%|      | 17499/50002 [3:31:17<5:43:54,  1.58it/s]Generation 17500: train Loss = 0.00614
Generation 17500: test Loss = 0.00428
训练集上一个批次数据的前10个数据
 [[ 0.45188284]
 [ 0.38912135]
 [ 0.46025103]
 [ 0.43514645]
 [ 0.51046026]
 [ 0.56903768]
 [ 0.55230123]
 [ 0.47280335]
 [ 0.53974897]
 [ 0.64853555]]
测试集上一个批次数据的前10个数据
 [[ 0.39748955]
 [ 0.54393303]
 [ 0.57322174]
 [ 0.38075313]
 [ 0.56066948]
 [ 0.55648535]
 [ 0.58995813]
 [ 0.43096235]
 [ 0.44769874]
 [ 0.59414226]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]
 [ 0.48418242]]
 35%|      | 17549/50002 [3:31:57<5:43:37,  1.57it/s]Generation 17550: train Loss = 0.00581
Generation 17550: test Loss = 0.00477
 35%|      | 17599/50002 [3:32:35<5:46:25,  1.56it/s]Generation 17600: train Loss = 0.00617
 35%|      | 17600/50002 [3:32:43<23:37:11,  2.62s/it]Generation 17600: test Loss = 0.00555
 35%|      | 17649/50002 [3:33:14<5:45:14,  1.56it/s]Generation 17650: train Loss = 0.00528
Generation 17650: test Loss = 0.00476
 35%|      | 17699/50002 [3:33:52<5:44:55,  1.56it/s]Generation 17700: train Loss = 0.00593
Generation 17700: test Loss = 0.00510
 35%|      | 17749/50002 [3:34:31<5:43:02,  1.57it/s]Generation 17750: train Loss = 0.00519
Generation 17750: test Loss = 0.00406
 36%|      | 17799/50002 [3:35:10<5:42:04,  1.57it/s]Generation 17800: train Loss = 0.00710
Generation 17800: test Loss = 0.00452
 36%|      | 17849/50002 [3:35:48<5:44:31,  1.56it/s]Generation 17850: train Loss = 0.00439
Generation 17850: test Loss = 0.00449
 36%|      | 17899/50002 [3:36:27<5:38:56,  1.58it/s]Generation 17900: train Loss = 0.00421
Generation 17900: test Loss = 0.00349
 36%|      | 17949/50002 [3:37:05<5:40:21,  1.57it/s]Generation 17950: train Loss = 0.00503
Generation 17950: test Loss = 0.00391
 36%|      | 17999/50002 [3:37:44<5:39:28,  1.57it/s]Generation 18000: train Loss = 0.00581
Generation 18000: test Loss = 0.00601
训练集上一个批次数据的前10个数据
 [[ 0.45606694]
 [ 0.51464432]
 [ 0.51464432]
 [ 0.56066948]
 [ 0.56485355]
 [ 0.58158994]
 [ 0.42259413]
 [ 0.52301258]
 [ 0.52719665]
 [ 0.58995813]]
测试集上一个批次数据的前10个数据
 [[ 0.42677826]
 [ 0.44769874]
 [ 0.48953974]
 [ 0.44769874]
 [ 0.53138077]
 [ 0.56485355]
 [ 0.49372384]
 [ 0.46025103]
 [ 0.60251045]
 [ 0.61924684]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]]
 36%|      | 18000/50002 [3:37:53<27:32:52,  3.10s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]
 [ 0.49097052]]
 36%|      | 18049/50002 [3:38:24<5:42:49,  1.55it/s]Generation 18050: train Loss = 0.00403
 36%|      | 18050/50002 [3:38:31<23:45:48,  2.68s/it]Generation 18050: test Loss = 0.00356
 36%|      | 18099/50002 [3:39:02<5:40:46,  1.56it/s]Generation 18100: train Loss = 0.00527
Generation 18100: test Loss = 0.00413
 36%|      | 18149/50002 [3:39:41<5:39:21,  1.56it/s]Generation 18150: train Loss = 0.00501
Generation 18150: test Loss = 0.00434
 36%|      | 18199/50002 [3:40:20<5:37:51,  1.57it/s]Generation 18200: train Loss = 0.00582
Generation 18200: test Loss = 0.00408
 36%|      | 18249/50002 [3:40:58<5:38:04,  1.57it/s]Generation 18250: train Loss = 0.00428
 36%|      | 18250/50002 [3:41:06<23:15:13,  2.64s/it]Generation 18250: test Loss = 0.00359
 37%|      | 18299/50002 [3:41:37<5:35:47,  1.57it/s]Generation 18300: train Loss = 0.00402
 37%|      | 18300/50002 [3:41:44<23:16:45,  2.64s/it]Generation 18300: test Loss = 0.00595
 37%|      | 18349/50002 [3:42:16<5:36:12,  1.57it/s]Generation 18350: train Loss = 0.00560
 37%|      | 18350/50002 [3:42:23<23:15:12,  2.64s/it]Generation 18350: test Loss = 0.00425
 37%|      | 18399/50002 [3:42:54<5:36:46,  1.56it/s]Generation 18400: train Loss = 0.00417
 37%|      | 18400/50002 [3:43:02<23:16:14,  2.65s/it]Generation 18400: test Loss = 0.00402
 37%|      | 18449/50002 [3:43:33<5:32:52,  1.58it/s]Generation 18450: train Loss = 0.00402
 37%|      | 18450/50002 [3:43:40<23:19:04,  2.66s/it]Generation 18450: test Loss = 0.00531
 37%|      | 18499/50002 [3:44:11<5:37:01,  1.56it/s]Generation 18500: train Loss = 0.00419
Generation 18500: test Loss = 0.00441
训练集上一个批次数据的前10个数据
 [[ 0.36820084]
 [ 0.47280335]
 [ 0.47698745]
 [ 0.41841003]
 [ 0.53556484]
 [ 0.52301258]
 [ 0.47698745]
 [ 0.49372384]
 [ 0.55648535]
 [ 0.49372384]]
测试集上一个批次数据的前10个数据
 [[ 0.48117155]
 [ 0.54393303]
 [ 0.49372384]
 [ 0.49372384]
 [ 0.50627613]
 [ 0.53138077]
 [ 0.56066948]
 [ 0.57322174]
 [ 0.52719665]
 [ 0.47698745]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]
 [ 0.48299131]]
 37%|      | 18549/50002 [3:44:52<5:36:35,  1.56it/s]Generation 18550: train Loss = 0.00500
Generation 18550: test Loss = 0.00352
 37%|      | 18599/50002 [3:45:31<5:33:14,  1.57it/s]Generation 18600: train Loss = 0.00551
Generation 18600: test Loss = 0.00638
 37%|      | 18649/50002 [3:46:10<5:37:07,  1.55it/s]Generation 18650: train Loss = 0.00678
 37%|      | 18650/50002 [3:46:17<23:17:06,  2.67s/it]Generation 18650: test Loss = 0.00548
 37%|      | 18699/50002 [3:46:48<5:30:46,  1.58it/s]Generation 18700: train Loss = 0.00518
 37%|      | 18700/50002 [3:46:56<23:15:42,  2.68s/it]Generation 18700: test Loss = 0.00495
 37%|      | 18749/50002 [3:47:27<5:31:52,  1.57it/s]Generation 18750: train Loss = 0.00423
Generation 18750: test Loss = 0.00525
 38%|      | 18799/50002 [3:48:06<5:29:52,  1.58it/s]Generation 18800: train Loss = 0.00566
 38%|      | 18800/50002 [3:48:13<23:21:06,  2.69s/it]Generation 18800: test Loss = 0.00419
 38%|      | 18849/50002 [3:48:45<5:29:49,  1.57it/s]Generation 18850: train Loss = 0.00445
Generation 18850: test Loss = 0.00427
 38%|      | 18899/50002 [3:49:23<5:32:06,  1.56it/s]Generation 18900: train Loss = 0.00361
 38%|      | 18900/50002 [3:49:31<23:14:03,  2.69s/it]Generation 18900: test Loss = 0.00533
 38%|      | 18949/50002 [3:50:02<5:31:05,  1.56it/s]Generation 18950: train Loss = 0.00468
 38%|      | 18950/50002 [3:50:10<23:16:20,  2.70s/it]Generation 18950: test Loss = 0.00525
 38%|      | 18999/50002 [3:50:41<5:30:41,  1.56it/s]Generation 19000: train Loss = 0.00583
Generation 19000: test Loss = 0.00468
训练集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.56903768]
 [ 0.45606694]
 [ 0.44769874]
 [ 0.39330545]
 [ 0.53556484]
 [ 0.46861926]
 [ 0.48953974]
 [ 0.44351465]
 [ 0.46025103]]
测试集上一个批次数据的前10个数据
 [[ 0.50627613]
 [ 0.55230123]
 [ 0.53556484]
 [ 0.54811716]
 [ 0.39330545]
 [ 0.48117155]
 [ 0.48117155]
 [ 0.56066948]
 [ 0.47280335]
 [ 0.52301258]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]]
 38%|      | 19000/50002 [3:50:50<27:18:49,  3.17s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]
 [ 0.48017767]]
 38%|      | 19049/50002 [3:51:21<5:29:37,  1.57it/s]Generation 19050: train Loss = 0.00486
 38%|      | 19050/50002 [3:51:29<23:47:49,  2.77s/it]Generation 19050: test Loss = 0.00492
 38%|      | 19099/50002 [3:52:00<5:29:53,  1.56it/s]Generation 19100: train Loss = 0.00582
 38%|      | 19100/50002 [3:52:08<23:24:21,  2.73s/it]Generation 19100: test Loss = 0.00457
 38%|      | 19149/50002 [3:52:39<5:29:20,  1.56it/s]Generation 19150: train Loss = 0.00497
 38%|      | 19150/50002 [3:52:47<23:14:50,  2.71s/it]Generation 19150: test Loss = 0.00386
 38%|      | 19199/50002 [3:53:18<5:28:52,  1.56it/s]Generation 19200: train Loss = 0.00346
 38%|      | 19200/50002 [3:53:26<23:15:01,  2.72s/it]Generation 19200: test Loss = 0.00467
 38%|      | 19249/50002 [3:53:57<5:27:27,  1.57it/s]Generation 19250: train Loss = 0.00478
 38%|      | 19250/50002 [3:54:04<23:14:33,  2.72s/it]Generation 19250: test Loss = 0.00522
 39%|      | 19299/50002 [3:54:36<5:28:15,  1.56it/s]Generation 19300: train Loss = 0.00459
Generation 19300: test Loss = 0.00435
 39%|      | 19349/50002 [3:55:15<5:26:25,  1.57it/s]Generation 19350: train Loss = 0.00417
 39%|      | 19350/50002 [3:55:22<23:14:49,  2.73s/it]Generation 19350: test Loss = 0.00377
 39%|      | 19399/50002 [3:55:54<5:25:59,  1.56it/s]Generation 19400: train Loss = 0.00468
Generation 19400: test Loss = 0.00521
 39%|      | 19449/50002 [3:56:33<5:26:31,  1.56it/s]Generation 19450: train Loss = 0.00423
Generation 19450: test Loss = 0.00398
 39%|      | 19499/50002 [3:57:11<5:22:10,  1.58it/s]Generation 19500: train Loss = 0.00698
Generation 19500: test Loss = 0.00494
训练集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.48535565]
 [ 0.51464432]
 [ 0.62343097]
 [ 0.61506277]
 [ 0.46861926]
 [ 0.58577406]
 [ 0.51882845]
 [ 0.48535565]
 [ 0.39330545]]
测试集上一个批次数据的前10个数据
 [[ 0.58158994]
 [ 0.57322174]
 [ 0.50209206]
 [ 0.48117155]
 [ 0.56066948]
 [ 0.49372384]
 [ 0.38075313]
 [ 0.59832639]
 [ 0.55648535]
 [ 0.49790794]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]]
 39%|      | 19500/50002 [3:57:21<27:18:45,  3.22s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]
 [ 0.52159119]]
 39%|      | 19549/50002 [3:57:52<5:23:14,  1.57it/s]Generation 19550: train Loss = 0.00475
Generation 19550: test Loss = 0.00507
 39%|      | 19599/50002 [3:58:31<5:23:33,  1.57it/s]Generation 19600: train Loss = 0.00463
Generation 19600: test Loss = 0.00476
 39%|      | 19649/50002 [3:59:10<5:24:15,  1.56it/s]Generation 19650: train Loss = 0.00451
 39%|      | 19650/50002 [3:59:18<23:11:22,  2.75s/it]Generation 19650: test Loss = 0.00504
 39%|      | 19699/50002 [3:59:49<5:24:14,  1.56it/s]Generation 19700: train Loss = 0.00495
 39%|      | 19700/50002 [3:59:57<23:09:26,  2.75s/it]Generation 19700: test Loss = 0.00321
 39%|      | 19749/50002 [4:00:28<5:23:18,  1.56it/s]Generation 19750: train Loss = 0.00507
Generation 19750: test Loss = 0.00535
 40%|      | 19799/50002 [4:01:07<5:21:57,  1.56it/s]Generation 19800: train Loss = 0.00468
Generation 19800: test Loss = 0.00399
 40%|      | 19849/50002 [4:01:46<5:20:17,  1.57it/s]Generation 19850: train Loss = 0.00447
Generation 19850: test Loss = 0.00463
 40%|      | 19899/50002 [4:02:25<5:23:29,  1.55it/s]Generation 19900: train Loss = 0.00512
Generation 19900: test Loss = 0.00480
 40%|      | 19949/50002 [4:03:04<5:17:53,  1.58it/s]Generation 19950: train Loss = 0.00580
Generation 19950: test Loss = 0.00486
 40%|      | 19999/50002 [4:03:43<5:18:18,  1.57it/s]Generation 20000: train Loss = 0.00380
Generation 20000: test Loss = 0.00426
训练集上一个批次数据的前10个数据
 [[ 1.        ]
 [ 0.46443516]
 [ 0.46443516]
 [ 0.43096235]
 [ 0.55230123]
 [ 0.56903768]
 [ 0.48953974]
 [ 0.46861926]
 [ 0.48953974]
 [ 0.48953974]]
测试集上一个批次数据的前10个数据
 [[ 0.51464432]
 [ 0.51882845]
 [ 0.51046026]
 [ 0.51464432]
 [ 0.46443516]
 [ 0.51046026]
 [ 0.46861926]
 [ 0.61924684]
 [ 0.40167364]
 [ 0.42259413]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]
 [ 0.49836475]]
 40%|      | 20049/50002 [4:05:08<5:22:32,  1.55it/s]Generation 20050: train Loss = 0.00452
 40%|      | 20050/50002 [4:05:16<23:43:58,  2.85s/it]Generation 20050: test Loss = 0.00461
 40%|      | 20099/50002 [4:05:47<5:16:38,  1.57it/s]Generation 20100: train Loss = 0.00411
 40%|      | 20100/50002 [4:05:56<24:26:54,  2.94s/it]Generation 20100: test Loss = 0.00377
 40%|      | 20149/50002 [4:06:27<5:17:58,  1.56it/s]Generation 20150: train Loss = 0.00458
 40%|      | 20150/50002 [4:06:35<23:15:47,  2.81s/it]Generation 20150: test Loss = 0.00477
 40%|      | 20199/50002 [4:07:06<5:17:10,  1.57it/s]Generation 20200: train Loss = 0.00458
 40%|      | 20200/50002 [4:07:14<23:13:15,  2.81s/it]Generation 20200: test Loss = 0.00474
 40%|      | 20249/50002 [4:07:45<5:19:21,  1.55it/s]Generation 20250: train Loss = 0.00452
Generation 20250: test Loss = 0.00581
 41%|      | 20299/50002 [4:08:24<5:13:29,  1.58it/s]Generation 20300: train Loss = 0.00442
Generation 20300: test Loss = 0.00429
 41%|      | 20349/50002 [4:09:03<5:14:07,  1.57it/s]Generation 20350: train Loss = 0.00594
Generation 20350: test Loss = 0.00425
 41%|      | 20399/50002 [4:09:43<5:16:07,  1.56it/s]Generation 20400: train Loss = 0.00461
Generation 20400: test Loss = 0.00451
 41%|      | 20449/50002 [4:10:22<5:12:12,  1.58it/s]Generation 20450: train Loss = 0.00577
 41%|      | 20450/50002 [4:10:30<23:11:30,  2.83s/it]Generation 20450: test Loss = 0.00417
 41%|      | 20499/50002 [4:11:01<5:12:15,  1.57it/s]Generation 20500: train Loss = 0.00520
Generation 20500: test Loss = 0.00452
训练集上一个批次数据的前10个数据
 [[ 0.50627613]
 [ 0.53974897]
 [ 0.51464432]
 [ 0.40585774]
 [ 0.52719665]
 [ 0.48953974]
 [ 0.53138077]
 [ 0.49790794]
 [ 0.47280335]
 [ 0.42677826]]
测试集上一个批次数据的前10个数据
 [[ 0.52301258]
 [ 0.45606694]
 [ 0.53138077]
 [ 0.33054394]
 [ 0.45606694]
 [ 0.51464432]
 [ 0.49372384]
 [ 0.38912135]
 [ 0.44351465]
 [ 0.53556484]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]]
 41%|      | 20500/50002 [4:11:11<27:34:38,  3.37s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]
 [ 0.50418687]]
 41%|      | 20549/50002 [4:11:42<5:13:15,  1.57it/s]Generation 20550: train Loss = 0.00522
 41%|      | 20550/50002 [4:11:50<23:31:17,  2.88s/it]Generation 20550: test Loss = 0.00579
 41%|      | 20599/50002 [4:12:21<5:14:30,  1.56it/s]Generation 20600: train Loss = 0.00466
Generation 20600: test Loss = 0.00454
 41%|     | 20649/50002 [4:13:01<5:13:36,  1.56it/s]Generation 20650: train Loss = 0.00541
 41%|     | 20650/50002 [4:13:08<23:06:50,  2.83s/it]Generation 20650: test Loss = 0.00537
 41%|     | 20699/50002 [4:13:40<5:12:02,  1.57it/s]Generation 20700: train Loss = 0.00506
 41%|     | 20700/50002 [4:13:48<23:08:20,  2.84s/it]Generation 20700: test Loss = 0.00427
 41%|     | 20749/50002 [4:14:19<5:10:02,  1.57it/s]Generation 20750: train Loss = 0.00555
Generation 20750: test Loss = 0.00527
 42%|     | 20799/50002 [4:14:58<5:14:15,  1.55it/s]Generation 20800: train Loss = 0.00511
 42%|     | 20800/50002 [4:15:06<23:46:57,  2.93s/it]Generation 20800: test Loss = 0.00484
 42%|     | 20849/50002 [4:15:38<5:11:53,  1.56it/s]Generation 20850: train Loss = 0.00526
Generation 20850: test Loss = 0.00517
 42%|     | 20899/50002 [4:16:17<5:06:41,  1.58it/s]Generation 20900: train Loss = 0.00832
Generation 20900: test Loss = 0.00383
 42%|     | 20949/50002 [4:16:56<5:11:29,  1.55it/s]Generation 20950: train Loss = 0.00490
 42%|     | 20950/50002 [4:17:04<22:57:58,  2.85s/it]Generation 20950: test Loss = 0.00339
 42%|     | 20999/50002 [4:17:36<5:06:37,  1.58it/s]Generation 21000: train Loss = 0.00492
Generation 21000: test Loss = 0.00458
训练集上一个批次数据的前10个数据
 [[ 0.58158994]
 [ 0.34728032]
 [ 0.45606694]
 [ 0.57740587]
 [ 0.44769874]
 [ 0.59832639]
 [ 0.51882845]
 [ 0.51882845]
 [ 0.58577406]
 [ 0.41841003]]
测试集上一个批次数据的前10个数据
 [[ 0.52719665]
 [ 0.48535565]
 [ 0.52301258]
 [ 0.51046026]
 [ 0.44351465]
 [ 0.49790794]
 [ 0.51882845]
 [ 0.52719665]
 [ 0.57322174]
 [ 0.50627613]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]]
 42%|     | 21000/50002 [4:17:45<26:57:17,  3.35s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]
 [ 0.48415062]]
 42%|     | 21049/50002 [4:18:16<5:07:43,  1.57it/s]Generation 21050: train Loss = 0.00480
Generation 21050: test Loss = 0.00577
 42%|     | 21099/50002 [4:18:56<5:06:18,  1.57it/s]Generation 21100: train Loss = 0.00418
Generation 21100: test Loss = 0.00652
 42%|     | 21149/50002 [4:19:35<5:07:01,  1.57it/s]Generation 21150: train Loss = 0.00413
Generation 21150: test Loss = 0.00501
 42%|     | 21199/50002 [4:20:15<5:05:43,  1.57it/s]Generation 21200: train Loss = 0.00533
 42%|     | 21200/50002 [4:20:23<22:59:42,  2.87s/it]Generation 21200: test Loss = 0.00498
 42%|     | 21249/50002 [4:20:54<5:03:44,  1.58it/s]Generation 21250: train Loss = 0.00504
 42%|     | 21250/50002 [4:21:02<23:00:46,  2.88s/it]Generation 21250: test Loss = 0.00561
 43%|     | 21299/50002 [4:21:33<5:05:06,  1.57it/s]Generation 21300: train Loss = 0.00446
Generation 21300: test Loss = 0.00341
 43%|     | 21349/50002 [4:22:13<5:06:51,  1.56it/s]Generation 21350: train Loss = 0.00491
 43%|     | 21350/50002 [4:22:21<22:58:54,  2.89s/it]Generation 21350: test Loss = 0.00438
 43%|     | 21399/50002 [4:22:52<5:02:57,  1.57it/s]Generation 21400: train Loss = 0.00455
 43%|     | 21400/50002 [4:23:01<22:58:36,  2.89s/it]Generation 21400: test Loss = 0.00396
 43%|     | 21449/50002 [4:23:32<5:01:49,  1.58it/s]Generation 21450: train Loss = 0.00459
 43%|     | 21450/50002 [4:23:40<23:04:42,  2.91s/it]Generation 21450: test Loss = 0.00523
 43%|     | 21499/50002 [4:24:11<5:02:57,  1.57it/s]Generation 21500: train Loss = 0.00692
Generation 21500: test Loss = 0.00491
训练集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.48535565]
 [ 0.56485355]
 [ 0.54811716]
 [ 0.48535565]
 [ 0.58577406]
 [ 0.52719665]
 [ 0.53556484]
 [ 0.43933055]
 [ 0.48535565]]
测试集上一个批次数据的前10个数据
 [[ 0.50209206]
 [ 0.55230123]
 [ 0.38912135]
 [ 0.51464432]
 [ 0.49790794]
 [ 0.40585774]
 [ 0.48535565]
 [ 0.51464432]
 [ 0.50209206]
 [ 0.55648535]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]]
 43%|     | 21500/50002 [4:24:21<26:48:21,  3.39s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]
 [ 0.50527477]]
 43%|     | 21549/50002 [4:24:52<5:03:59,  1.56it/s]Generation 21550: train Loss = 0.00429
Generation 21550: test Loss = 0.00354
 43%|     | 21599/50002 [4:25:32<5:00:09,  1.58it/s]Generation 21600: train Loss = 0.00406
Generation 21600: test Loss = 0.00513
 43%|     | 21649/50002 [4:26:11<4:59:35,  1.58it/s]Generation 21650: train Loss = 0.00463
 43%|     | 21650/50002 [4:26:19<22:50:29,  2.90s/it]Generation 21650: test Loss = 0.00473
 43%|     | 21699/50002 [4:26:51<5:01:24,  1.57it/s]Generation 21700: train Loss = 0.00452
 43%|     | 21700/50002 [4:26:59<22:58:33,  2.92s/it]Generation 21700: test Loss = 0.00524
 43%|     | 21749/50002 [4:27:30<5:01:23,  1.56it/s]Generation 21750: train Loss = 0.00496
 43%|     | 21750/50002 [4:27:39<23:03:06,  2.94s/it]Generation 21750: test Loss = 0.00410
 44%|     | 21799/50002 [4:28:10<4:57:39,  1.58it/s]Generation 21800: train Loss = 0.00385
 44%|     | 21800/50002 [4:28:18<22:47:24,  2.91s/it]Generation 21800: test Loss = 0.00482
 44%|     | 21849/50002 [4:28:49<4:58:40,  1.57it/s]Generation 21850: train Loss = 0.00465
 44%|     | 21850/50002 [4:28:58<22:48:15,  2.92s/it]Generation 21850: test Loss = 0.00577
 44%|     | 21899/50002 [4:29:29<4:58:56,  1.57it/s]Generation 21900: train Loss = 0.00532
 44%|     | 21900/50002 [4:29:37<22:46:23,  2.92s/it]Generation 21900: test Loss = 0.00497
 44%|     | 21949/50002 [4:30:08<4:59:57,  1.56it/s]Generation 21950: train Loss = 0.00654
 44%|     | 21950/50002 [4:30:17<22:56:00,  2.94s/it]Generation 21950: test Loss = 0.00455
 44%|     | 21999/50002 [4:30:48<4:59:31,  1.56it/s]Generation 22000: train Loss = 0.00505
Generation 22000: test Loss = 0.00422
训练集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.58995813]
 [ 0.48535565]
 [ 0.48117155]
 [ 0.43096235]
 [ 0.48953974]
 [ 0.40585774]
 [ 0.54811716]
 [ 0.59414226]
 [ 0.44351465]]
测试集上一个批次数据的前10个数据
 [[ 0.46025103]
 [ 0.53974897]
 [ 0.55230123]
 [ 0.47698745]
 [ 0.43096235]
 [ 0.56066948]
 [ 0.38912135]
 [ 0.39748955]
 [ 0.56485355]
 [ 0.47698745]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]
 [ 0.49243289]]
 44%|     | 22049/50002 [4:31:29<4:57:24,  1.57it/s]Generation 22050: train Loss = 0.00593
Generation 22050: test Loss = 0.00368
 44%|     | 22099/50002 [4:32:09<4:57:17,  1.56it/s]Generation 22100: train Loss = 0.00528
 44%|     | 22100/50002 [4:32:17<22:45:42,  2.94s/it]Generation 22100: test Loss = 0.00546
 44%|     | 22149/50002 [4:32:48<4:55:31,  1.57it/s]Generation 22150: train Loss = 0.00510
 44%|     | 22150/50002 [4:32:57<22:53:16,  2.96s/it]Generation 22150: test Loss = 0.00374
 44%|     | 22199/50002 [4:33:28<4:57:03,  1.56it/s]Generation 22200: train Loss = 0.00534
 44%|     | 22200/50002 [4:33:36<22:47:55,  2.95s/it]Generation 22200: test Loss = 0.00400
 44%|     | 22249/50002 [4:34:08<4:53:02,  1.58it/s]Generation 22250: train Loss = 0.00731
Generation 22250: test Loss = 0.00379
 45%|     | 22299/50002 [4:34:47<4:52:28,  1.58it/s]Generation 22300: train Loss = 0.00468
 45%|     | 22300/50002 [4:34:56<22:51:21,  2.97s/it]Generation 22300: test Loss = 0.00431
 45%|     | 22349/50002 [4:35:27<4:54:27,  1.57it/s]Generation 22350: train Loss = 0.00453
 45%|     | 22350/50002 [4:35:35<22:44:09,  2.96s/it]Generation 22350: test Loss = 0.00468
 45%|     | 22399/50002 [4:36:06<4:55:09,  1.56it/s]Generation 22400: train Loss = 0.00583
 45%|     | 22400/50002 [4:36:15<22:42:33,  2.96s/it]Generation 22400: test Loss = 0.00466
 45%|     | 22449/50002 [4:36:46<4:52:36,  1.57it/s]Generation 22450: train Loss = 0.00532
 45%|     | 22450/50002 [4:36:55<22:47:17,  2.98s/it]Generation 22450: test Loss = 0.00601
 45%|     | 22499/50002 [4:37:26<4:52:04,  1.57it/s]Generation 22500: train Loss = 0.00486
Generation 22500: test Loss = 0.00463
训练集上一个批次数据的前10个数据
 [[ 0.61924684]
 [ 0.53138077]
 [ 0.53138077]
 [ 0.58995813]
 [ 0.51464432]
 [ 0.51882845]
 [ 0.46443516]
 [ 0.51046026]
 [ 0.40167364]
 [ 0.51882845]]
测试集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.38075313]
 [ 0.54811716]
 [ 0.41422594]
 [ 0.58995813]
 [ 0.45606694]
 [ 0.48953974]
 [ 0.55230123]
 [ 0.46861926]
 [ 0.54393303]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]]
 45%|     | 22500/50002 [4:37:36<26:30:25,  3.47s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]
 [ 0.48159575]]
 45%|     | 22549/50002 [4:38:07<4:54:03,  1.56it/s]Generation 22550: train Loss = 0.00572
Generation 22550: test Loss = 0.00637
 45%|     | 22599/50002 [4:38:47<4:51:42,  1.57it/s]Generation 22600: train Loss = 0.00501
Generation 22600: test Loss = 0.00385
 45%|     | 22649/50002 [4:39:27<4:50:37,  1.57it/s]Generation 22650: train Loss = 0.00525
Generation 22650: test Loss = 0.00449
 45%|     | 22699/50002 [4:40:06<4:49:32,  1.57it/s]Generation 22700: train Loss = 0.00775
 45%|     | 22700/50002 [4:40:15<22:38:51,  2.99s/it]Generation 22700: test Loss = 0.00640
 45%|     | 22749/50002 [4:40:46<4:51:06,  1.56it/s]Generation 22750: train Loss = 0.00497
Generation 22750: test Loss = 0.00568
 46%|     | 22799/50002 [4:41:26<4:49:47,  1.56it/s]Generation 22800: train Loss = 0.00564
 46%|     | 22800/50002 [4:41:34<22:34:48,  2.99s/it]Generation 22800: test Loss = 0.00459
 46%|     | 22849/50002 [4:42:06<4:47:36,  1.57it/s]Generation 22850: train Loss = 0.00516
 46%|     | 22850/50002 [4:42:14<22:50:15,  3.03s/it]Generation 22850: test Loss = 0.00540
 46%|     | 22899/50002 [4:42:46<4:49:24,  1.56it/s]Generation 22900: train Loss = 0.00498
Generation 22900: test Loss = 0.00411
 46%|     | 22949/50002 [4:43:25<4:45:57,  1.58it/s]Generation 22950: train Loss = 0.00391
Generation 22950: test Loss = 0.00479
 46%|     | 22999/50002 [4:44:05<4:44:57,  1.58it/s]Generation 23000: train Loss = 0.00475
Generation 23000: test Loss = 0.00403
训练集上一个批次数据的前10个数据
 [[ 0.29707113]
 [ 0.53556484]
 [ 0.48535565]
 [ 0.49372384]
 [ 0.56485355]
 [ 0.32217574]
 [ 0.63598329]
 [ 0.56066948]
 [ 0.51882845]
 [ 0.59832639]]
测试集上一个批次数据的前10个数据
 [[ 0.49790794]
 [ 0.48117155]
 [ 0.51464432]
 [ 0.56066948]
 [ 0.51882845]
 [ 0.47698745]
 [ 0.48117155]
 [ 0.42677826]
 [ 0.60669458]
 [ 0.56903768]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]
 [ 0.48680541]]
 46%|     | 23049/50002 [4:44:46<4:47:29,  1.56it/s]Generation 23050: train Loss = 0.00627
Generation 23050: test Loss = 0.00412
 46%|     | 23099/50002 [4:45:26<4:46:01,  1.57it/s]Generation 23100: train Loss = 0.00629
 46%|     | 23100/50002 [4:45:35<22:48:53,  3.05s/it]Generation 23100: test Loss = 0.00456
 46%|     | 23149/50002 [4:46:06<4:47:00,  1.56it/s]Generation 23150: train Loss = 0.00542
Generation 23150: test Loss = 0.00462
 46%|     | 23199/50002 [4:46:46<4:46:39,  1.56it/s]Generation 23200: train Loss = 0.00425
 46%|     | 23200/50002 [4:46:55<22:34:31,  3.03s/it]Generation 23200: test Loss = 0.00450
 46%|     | 23249/50002 [4:47:26<4:45:44,  1.56it/s]Generation 23250: train Loss = 0.00432
Generation 23250: test Loss = 0.00439
 47%|     | 23299/50002 [4:48:06<4:42:52,  1.57it/s]Generation 23300: train Loss = 0.00415
 47%|     | 23300/50002 [4:48:15<22:33:49,  3.04s/it]Generation 23300: test Loss = 0.00427
 47%|     | 23349/50002 [4:48:46<4:41:47,  1.58it/s]Generation 23350: train Loss = 0.00518
Generation 23350: test Loss = 0.00458
 47%|     | 23399/50002 [4:49:26<4:41:13,  1.58it/s]Generation 23400: train Loss = 0.00435
Generation 23400: test Loss = 0.00519
 47%|     | 23449/50002 [4:50:06<4:40:33,  1.58it/s]Generation 23450: train Loss = 0.00671
Generation 23450: test Loss = 0.00536
 47%|     | 23499/50002 [4:50:46<4:41:29,  1.57it/s]Generation 23500: train Loss = 0.00467
Generation 23500: test Loss = 0.00537
训练集上一个批次数据的前10个数据
 [[ 0.54393303]
 [ 0.57740587]
 [ 0.41841003]
 [ 0.48953974]
 [ 0.40585774]
 [ 0.46861926]
 [ 0.58158994]
 [ 0.53556484]
 [ 0.48535565]
 [ 0.48953974]]
测试集上一个批次数据的前10个数据
 [[ 0.42259413]
 [ 0.41841003]
 [ 0.53974897]
 [ 0.44769874]
 [ 0.56485355]
 [ 0.42259413]
 [ 0.51046026]
 [ 0.53556484]
 [ 0.46025103]
 [ 0.61506277]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]
 [ 0.48127469]]
 47%|     | 23549/50002 [4:51:27<4:41:05,  1.57it/s]Generation 23550: train Loss = 0.00603
Generation 23550: test Loss = 0.00422
 47%|     | 23599/50002 [4:52:07<4:40:01,  1.57it/s]Generation 23600: train Loss = 0.00470
Generation 23600: test Loss = 0.00602
 47%|     | 23649/50002 [4:52:47<4:40:22,  1.57it/s]Generation 23650: train Loss = 0.00370
 47%|     | 23650/50002 [4:52:56<22:29:16,  3.07s/it]Generation 23650: test Loss = 0.00359
 47%|     | 23699/50002 [4:53:27<4:40:06,  1.57it/s]Generation 23700: train Loss = 0.00560
 47%|     | 23700/50002 [4:53:36<22:20:44,  3.06s/it]Generation 23700: test Loss = 0.00523
 47%|     | 23749/50002 [4:54:07<4:37:42,  1.58it/s]Generation 23750: train Loss = 0.00544
Generation 23750: test Loss = 0.00409
 48%|     | 23799/50002 [4:54:47<4:39:34,  1.56it/s]Generation 23800: train Loss = 0.00463
Generation 23800: test Loss = 0.00422
 48%|     | 23849/50002 [4:55:27<4:35:10,  1.58it/s]Generation 23850: train Loss = 0.00503
 48%|     | 23850/50002 [4:55:36<22:20:58,  3.08s/it]Generation 23850: test Loss = 0.00342
 48%|     | 23899/50002 [4:56:07<4:38:50,  1.56it/s]Generation 23900: train Loss = 0.00494
Generation 23900: test Loss = 0.00632
 48%|     | 23949/50002 [4:56:47<4:40:12,  1.55it/s]Generation 23950: train Loss = 0.00463
Generation 23950: test Loss = 0.00448
 48%|     | 23999/50002 [4:57:27<4:36:15,  1.57it/s]Generation 24000: train Loss = 0.00418
Generation 24000: test Loss = 0.00556
训练集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.54811716]
 [ 0.47280335]
 [ 0.58995813]
 [ 0.52301258]
 [ 0.56903768]
 [ 0.43514645]
 [ 0.42259413]
 [ 0.49790794]
 [ 0.56066948]]
测试集上一个批次数据的前10个数据
 [[ 0.51882845]
 [ 0.40167364]
 [ 0.65690374]
 [ 0.48117155]
 [ 0.63179916]
 [ 0.51882845]
 [ 0.56903768]
 [ 0.46025103]
 [ 0.54393303]
 [ 0.43514645]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]]
测试集上一个批次数据中通过inference后的前10个输出结果
 48%|     | 24000/50002 [4:57:38<26:10:48,  3.62s/it] [[ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]
 [ 0.46619418]]
 48%|     | 24049/50002 [4:58:09<4:34:28,  1.58it/s]Generation 24050: train Loss = 0.00564
Generation 24050: test Loss = 0.00384
 48%|     | 24099/50002 [4:58:49<4:34:38,  1.57it/s]Generation 24100: train Loss = 0.00549
 48%|     | 24100/50002 [4:58:58<22:19:44,  3.10s/it]Generation 24100: test Loss = 0.00470
 48%|     | 24149/50002 [4:59:29<4:32:38,  1.58it/s]Generation 24150: train Loss = 0.00588
 48%|     | 24150/50002 [4:59:38<22:24:12,  3.12s/it]Generation 24150: test Loss = 0.00401
 48%|     | 24199/50002 [5:00:09<4:35:17,  1.56it/s]Generation 24200: train Loss = 0.00478
Generation 24200: test Loss = 0.00440
 48%|     | 24249/50002 [5:00:50<4:33:24,  1.57it/s]Generation 24250: train Loss = 0.00548
 48%|     | 24250/50002 [5:00:59<22:16:15,  3.11s/it]Generation 24250: test Loss = 0.00492
 49%|     | 24299/50002 [5:01:30<4:33:26,  1.57it/s]Generation 24300: train Loss = 0.00543
Generation 24300: test Loss = 0.00309
 49%|     | 24349/50002 [5:02:10<4:33:24,  1.56it/s]Generation 24350: train Loss = 0.00369
Generation 24350: test Loss = 0.00509
 49%|     | 24399/50002 [5:02:50<4:32:19,  1.57it/s]Generation 24400: train Loss = 0.00455
Generation 24400: test Loss = 0.00625
 49%|     | 24449/50002 [5:03:31<4:31:04,  1.57it/s]Generation 24450: train Loss = 0.00502
 49%|     | 24450/50002 [5:03:40<22:07:44,  3.12s/it]Generation 24450: test Loss = 0.00429
 49%|     | 24499/50002 [5:04:11<4:30:47,  1.57it/s]Generation 24500: train Loss = 0.00581
Generation 24500: test Loss = 0.00469
训练集上一个批次数据的前10个数据
 [[ 0.57322174]
 [ 0.41841003]
 [ 0.55230123]
 [ 0.51464432]
 [ 0.50627613]
 [ 0.42259413]
 [ 0.50627613]
 [ 0.50627613]
 [ 0.48953974]
 [ 0.58577406]]
测试集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.38075313]
 [ 0.48953974]
 [ 0.47698745]
 [ 0.51046026]
 [ 0.51046026]
 [ 0.44769874]
 [ 0.46025103]
 [ 0.47698745]
 [ 0.46025103]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]
 [ 0.47255936]]
 49%|     | 24549/50002 [5:04:53<4:30:34,  1.57it/s]Generation 24550: train Loss = 0.00489
Generation 24550: test Loss = 0.00493
 49%|     | 24599/50002 [5:05:33<4:32:02,  1.56it/s]Generation 24600: train Loss = 0.00662
Generation 24600: test Loss = 0.00368
 49%|     | 24649/50002 [5:06:13<4:30:56,  1.56it/s]Generation 24650: train Loss = 0.00584
Generation 24650: test Loss = 0.00449
 49%|     | 24699/50002 [5:06:54<4:28:09,  1.57it/s]Generation 24700: train Loss = 0.00440
 49%|     | 24700/50002 [5:07:03<22:04:26,  3.14s/it]Generation 24700: test Loss = 0.00382
 49%|     | 24749/50002 [5:07:34<4:26:17,  1.58it/s]Generation 24750: train Loss = 0.00520
 49%|     | 24750/50002 [5:07:43<22:02:51,  3.14s/it]Generation 24750: test Loss = 0.00363
 50%|     | 24799/50002 [5:08:14<4:25:15,  1.58it/s]Generation 24800: train Loss = 0.00573
Generation 24800: test Loss = 0.00387
 50%|     | 24849/50002 [5:08:54<4:27:55,  1.56it/s]Generation 24850: train Loss = 0.00468
 50%|     | 24850/50002 [5:09:03<22:03:26,  3.16s/it]Generation 24850: test Loss = 0.00475
 50%|     | 24899/50002 [5:09:35<4:27:22,  1.56it/s]Generation 24900: train Loss = 0.00518
Generation 24900: test Loss = 0.00479
 50%|     | 24949/50002 [5:10:15<4:26:57,  1.56it/s]Generation 24950: train Loss = 0.00425
Generation 24950: test Loss = 0.00436
 50%|     | 24999/50002 [5:10:55<4:26:20,  1.56it/s]Generation 25000: train Loss = 0.00469
Generation 25000: test Loss = 0.00469
训练集上一个批次数据的前10个数据
 [[ 0.39748955]
 [ 0.40585774]
 [ 0.49372384]
 [ 0.49372384]
 [ 0.52719665]
 [ 0.49372384]
 [ 0.48535565]
 [ 0.43096235]
 [ 0.58577406]
 [ 0.50209206]]
测试集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.44351465]
 [ 0.58158994]
 [ 0.40585774]
 [ 0.47698745]
 [ 0.50209206]
 [ 0.38912135]
 [ 0.52301258]
 [ 0.49372384]
 [ 0.48117155]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]]
 50%|     | 25000/50002 [5:11:06<25:40:12,  3.70s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]
 [ 0.48831686]]
 50%|     | 25049/50002 [5:11:37<4:26:23,  1.56it/s]Generation 25050: train Loss = 0.00514
 50%|     | 25050/50002 [5:11:46<22:22:34,  3.23s/it]Generation 25050: test Loss = 0.00461
 50%|     | 25099/50002 [5:12:18<4:23:46,  1.57it/s]Generation 25100: train Loss = 0.00460
Generation 25100: test Loss = 0.00367
 50%|     | 25149/50002 [5:12:58<4:25:11,  1.56it/s]Generation 25150: train Loss = 0.00401
Generation 25150: test Loss = 0.00447
 50%|     | 25199/50002 [5:13:39<4:22:54,  1.57it/s]Generation 25200: train Loss = 0.00407
 50%|     | 25200/50002 [5:13:48<22:18:59,  3.24s/it]Generation 25200: test Loss = 0.00403
 50%|     | 25249/50002 [5:14:19<4:21:34,  1.58it/s]Generation 25250: train Loss = 0.00593
 50%|     | 25250/50002 [5:14:28<21:52:31,  3.18s/it]Generation 25250: test Loss = 0.00456
 51%|     | 25299/50002 [5:14:59<4:21:50,  1.57it/s]Generation 25300: train Loss = 0.00617
Generation 25300: test Loss = 0.00517
 51%|     | 25349/50002 [5:15:40<4:21:51,  1.57it/s]Generation 25350: train Loss = 0.00472
Generation 25350: test Loss = 0.00620
 51%|     | 25399/50002 [5:16:21<4:22:26,  1.56it/s]Generation 25400: train Loss = 0.00566
Generation 25400: test Loss = 0.00430
 51%|     | 25449/50002 [5:17:01<4:20:10,  1.57it/s]Generation 25450: train Loss = 0.00541
 51%|     | 25450/50002 [5:17:10<21:50:05,  3.20s/it]Generation 25450: test Loss = 0.00548
 51%|     | 25499/50002 [5:17:42<4:19:27,  1.57it/s]Generation 25500: train Loss = 0.00662
Generation 25500: test Loss = 0.00451
训练集上一个批次数据的前10个数据
 [[ 0.40585774]
 [ 0.37656903]
 [ 0.62343097]
 [ 0.38493723]
 [ 0.53138077]
 [ 0.53974897]
 [ 0.47280335]
 [ 0.51046026]
 [ 0.37238494]
 [ 0.61924684]]
测试集上一个批次数据的前10个数据
 [[ 0.57740587]
 [ 0.41841003]
 [ 0.47280335]
 [ 0.45606694]
 [ 0.53138077]
 [ 0.48953974]
 [ 0.48117155]
 [ 0.55648535]
 [ 0.53138077]
 [ 0.59414226]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]
 [ 0.48758203]]
 51%|     | 25549/50002 [5:18:24<4:18:43,  1.58it/s]Generation 25550: train Loss = 0.00603
Generation 25550: test Loss = 0.00596
 51%|     | 25599/50002 [5:19:04<4:21:00,  1.56it/s]Generation 25600: train Loss = 0.00542
 51%|     | 25600/50002 [5:19:14<21:57:08,  3.24s/it]Generation 25600: test Loss = 0.00394
 51%|    | 25649/50002 [5:19:45<4:19:58,  1.56it/s]Generation 25650: train Loss = 0.00659
Generation 25650: test Loss = 0.00598
 51%|    | 25699/50002 [5:20:26<4:16:55,  1.58it/s]Generation 25700: train Loss = 0.00433
Generation 25700: test Loss = 0.00414
 51%|    | 25749/50002 [5:21:06<4:15:32,  1.58it/s]Generation 25750: train Loss = 0.00477
 51%|    | 25750/50002 [5:21:15<21:36:51,  3.21s/it]Generation 25750: test Loss = 0.00337
 52%|    | 25799/50002 [5:21:47<4:16:47,  1.57it/s]Generation 25800: train Loss = 0.00482
 52%|    | 25800/50002 [5:21:56<21:41:06,  3.23s/it]Generation 25800: test Loss = 0.00484
 52%|    | 25849/50002 [5:22:27<4:18:00,  1.56it/s]Generation 25850: train Loss = 0.00480
Generation 25850: test Loss = 0.00479
 52%|    | 25899/50002 [5:23:08<4:15:12,  1.57it/s]Generation 25900: train Loss = 0.00579
 52%|    | 25900/50002 [5:23:17<21:41:00,  3.24s/it]Generation 25900: test Loss = 0.00475
 52%|    | 25949/50002 [5:23:48<4:14:29,  1.58it/s]Generation 25950: train Loss = 0.00472
 52%|    | 25950/50002 [5:23:58<21:38:10,  3.24s/it]Generation 25950: test Loss = 0.00377
 52%|    | 25999/50002 [5:24:29<4:15:04,  1.57it/s]Generation 26000: train Loss = 0.00416
Generation 26000: test Loss = 0.00372
训练集上一个批次数据的前10个数据
 [[ 0.38493723]
 [ 0.55230123]
 [ 0.50627613]
 [ 0.41841003]
 [ 0.46443516]
 [ 0.46443516]
 [ 0.51046026]
 [ 0.46861926]
 [ 0.48953974]
 [ 0.34309623]]
测试集上一个批次数据的前10个数据
 [[ 0.51882845]
 [ 0.53974897]
 [ 0.52719665]
 [ 0.45188284]
 [ 0.57322174]
 [ 0.43514645]
 [ 0.33472803]
 [ 0.51046026]
 [ 0.46443516]
 [ 0.36820084]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]]
 52%|    | 26000/50002 [5:24:40<26:06:18,  3.92s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]
 [ 0.51131594]]
 52%|    | 26049/50002 [5:25:11<4:14:29,  1.57it/s]Generation 26050: train Loss = 0.00634
 52%|    | 26050/50002 [5:25:21<21:55:58,  3.30s/it]Generation 26050: test Loss = 0.00427
 52%|    | 26099/50002 [5:25:52<4:13:12,  1.57it/s]Generation 26100: train Loss = 0.00380
Generation 26100: test Loss = 0.00479
 52%|    | 26149/50002 [5:26:33<4:12:52,  1.57it/s]Generation 26150: train Loss = 0.00496
 52%|    | 26150/50002 [5:26:42<21:50:05,  3.30s/it]Generation 26150: test Loss = 0.00447
 52%|    | 26199/50002 [5:27:14<4:15:38,  1.55it/s]Generation 26200: train Loss = 0.00496
Generation 26200: test Loss = 0.00411
 52%|    | 26249/50002 [5:27:54<4:12:51,  1.57it/s]Generation 26250: train Loss = 0.00445
Generation 26250: test Loss = 0.00711
 53%|    | 26299/50002 [5:28:35<4:11:35,  1.57it/s]Generation 26300: train Loss = 0.00536
 53%|    | 26300/50002 [5:28:44<21:36:30,  3.28s/it]Generation 26300: test Loss = 0.00608
 53%|    | 26349/50002 [5:29:16<4:12:34,  1.56it/s]Generation 26350: train Loss = 0.00438
Generation 26350: test Loss = 0.00446
 53%|    | 26399/50002 [5:29:56<4:11:26,  1.56it/s]Generation 26400: train Loss = 0.00507
 53%|    | 26400/50002 [5:30:06<22:03:01,  3.36s/it]Generation 26400: test Loss = 0.00500
 53%|    | 26449/50002 [5:30:38<4:12:37,  1.55it/s]Generation 26450: train Loss = 0.00688
 53%|    | 26450/50002 [5:30:47<21:31:59,  3.29s/it]Generation 26450: test Loss = 0.00539
 53%|    | 26499/50002 [5:31:18<4:11:57,  1.55it/s]Generation 26500: train Loss = 0.00576
Generation 26500: test Loss = 0.00511
训练集上一个批次数据的前10个数据
 [[ 0.61924684]
 [ 0.47698745]
 [ 0.57322174]
 [ 0.42259413]
 [ 0.43933055]
 [ 0.54393303]
 [ 0.52719665]
 [ 0.51882845]
 [ 0.46443516]
 [ 0.45188284]]
测试集上一个批次数据的前10个数据
 [[ 0.53138077]
 [ 0.49372384]
 [ 0.43096235]
 [ 0.44351465]
 [ 0.51046026]
 [ 0.52301258]
 [ 0.58995813]
 [ 0.45188284]
 [ 0.47280335]
 [ 0.52301258]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 [ 0.49638161]
 53%|    | 26500/50002 [5:31:31<27:27:13,  4.21s/it]
 53%|    | 26549/50002 [5:32:02<4:07:17,  1.58it/s]Generation 26550: train Loss = 0.00525
Generation 26550: test Loss = 0.00550
 53%|    | 26599/50002 [5:32:43<4:09:10,  1.57it/s]Generation 26600: train Loss = 0.00496
 53%|    | 26600/50002 [5:32:52<21:35:16,  3.32s/it]Generation 26600: test Loss = 0.00430
 53%|    | 26649/50002 [5:33:24<4:08:51,  1.56it/s]Generation 26650: train Loss = 0.00507
 53%|    | 26650/50002 [5:33:33<21:23:31,  3.30s/it]Generation 26650: test Loss = 0.00562
 53%|    | 26699/50002 [5:34:04<4:10:21,  1.55it/s]Generation 26700: train Loss = 0.00481
Generation 26700: test Loss = 0.00479
 53%|    | 26749/50002 [5:34:45<4:06:20,  1.57it/s]Generation 26750: train Loss = 0.00497
 53%|    | 26750/50002 [5:34:55<21:20:39,  3.30s/it]Generation 26750: test Loss = 0.00381
 54%|    | 26799/50002 [5:35:26<4:05:48,  1.57it/s]Generation 26800: train Loss = 0.00548
Generation 26800: test Loss = 0.00482
 54%|    | 26849/50002 [5:36:07<4:05:54,  1.57it/s]Generation 26850: train Loss = 0.00478
Generation 26850: test Loss = 0.00531
 54%|    | 26899/50002 [5:36:47<4:04:25,  1.58it/s]Generation 26900: train Loss = 0.00424
 54%|    | 26900/50002 [5:36:57<21:17:34,  3.32s/it]Generation 26900: test Loss = 0.00526
 54%|    | 26949/50002 [5:37:28<4:05:55,  1.56it/s]Generation 26950: train Loss = 0.00576
Generation 26950: test Loss = 0.00314
 54%|    | 26999/50002 [5:38:09<4:04:13,  1.57it/s]Generation 27000: train Loss = 0.00430
Generation 27000: test Loss = 0.00419
训练集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.53974897]
 [ 0.44351465]
 [ 0.53138077]
 [ 0.54811716]
 [ 0.49790794]
 [ 0.53556484]
 [ 0.39748955]
 [ 0.53556484]
 [ 0.50627613]]
测试集上一个批次数据的前10个数据
 [[ 0.44351465]
 [ 0.60251045]
 [ 0.45606694]
 [ 0.52719665]
 [ 0.50209206]
 [ 0.54393303]
 [ 0.51464432]
 [ 0.45606694]
 [ 0.48117155]
 [ 0.46025103]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]]
 54%|    | 27000/50002 [5:38:20<24:17:45,  3.80s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]
 [ 0.50191742]]
 54%|    | 27049/50002 [5:38:52<4:06:29,  1.55it/s]Generation 27050: train Loss = 0.00468
 54%|    | 27050/50002 [5:39:01<21:31:33,  3.38s/it]Generation 27050: test Loss = 0.00530
 54%|    | 27099/50002 [5:39:33<4:04:10,  1.56it/s]Generation 27100: train Loss = 0.00527
Generation 27100: test Loss = 0.00494
 54%|    | 27149/50002 [5:40:13<4:03:58,  1.56it/s]Generation 27150: train Loss = 0.00560
 54%|    | 27150/50002 [5:40:23<21:12:25,  3.34s/it]Generation 27150: test Loss = 0.00482
 54%|    | 27199/50002 [5:40:54<4:00:50,  1.58it/s]Generation 27200: train Loss = 0.00434
 54%|    | 27200/50002 [5:41:04<21:09:36,  3.34s/it]Generation 27200: test Loss = 0.00503
 54%|    | 27249/50002 [5:41:35<4:01:57,  1.57it/s]Generation 27250: train Loss = 0.00503
 54%|    | 27250/50002 [5:41:45<21:20:24,  3.38s/it]Generation 27250: test Loss = 0.00358
 55%|    | 27299/50002 [5:42:16<4:00:46,  1.57it/s]Generation 27300: train Loss = 0.00444
 55%|    | 27300/50002 [5:42:26<21:11:49,  3.36s/it]Generation 27300: test Loss = 0.00512
 55%|    | 27349/50002 [5:42:57<4:01:01,  1.57it/s]Generation 27350: train Loss = 0.00548
Generation 27350: test Loss = 0.00490
 55%|    | 27399/50002 [5:43:38<3:59:33,  1.57it/s]Generation 27400: train Loss = 0.00508
Generation 27400: test Loss = 0.00500
 55%|    | 27449/50002 [5:44:19<3:59:54,  1.57it/s]Generation 27450: train Loss = 0.00378
Generation 27450: test Loss = 0.00495
 55%|    | 27499/50002 [5:45:00<3:58:38,  1.57it/s]Generation 27500: train Loss = 0.00708
Generation 27500: test Loss = 0.00456
训练集上一个批次数据的前10个数据
 [[ 0.44769874]
 [ 0.32635984]
 [ 0.46861926]
 [ 0.45188284]
 [ 0.47280335]
 [ 0.49372384]
 [ 0.52301258]
 [ 0.46443516]
 [ 0.44769874]
 [ 0.49372384]]
测试集上一个批次数据的前10个数据
 [[ 0.59414226]
 [ 0.53556484]
 [ 0.44351465]
 [ 0.52301258]
 [ 0.51464432]
 [ 0.33472803]
 [ 0.41841003]
 [ 0.52301258]
 [ 0.46443516]
 [ 0.51882845]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]
 [ 0.48669484]]
 55%|    | 27549/50002 [5:45:43<3:59:55,  1.56it/s]Generation 27550: train Loss = 0.00555
 55%|    | 27550/50002 [5:45:53<21:21:53,  3.43s/it]Generation 27550: test Loss = 0.00498
 55%|    | 27599/50002 [5:46:24<3:58:09,  1.57it/s]Generation 27600: train Loss = 0.00445
Generation 27600: test Loss = 0.00398
 55%|    | 27649/50002 [5:47:05<3:57:32,  1.57it/s]Generation 27650: train Loss = 0.00417
 55%|    | 27650/50002 [5:47:15<21:03:02,  3.39s/it]Generation 27650: test Loss = 0.00462
 55%|    | 27699/50002 [5:47:47<3:56:50,  1.57it/s]Generation 27700: train Loss = 0.00654
 55%|    | 27700/50002 [5:47:56<20:58:20,  3.39s/it]Generation 27700: test Loss = 0.00490
 55%|    | 27749/50002 [5:48:28<3:55:38,  1.57it/s]Generation 27750: train Loss = 0.00570
 55%|    | 27750/50002 [5:48:37<20:56:47,  3.39s/it]Generation 27750: test Loss = 0.00296
 56%|    | 27799/50002 [5:49:09<3:56:53,  1.56it/s]Generation 27800: train Loss = 0.00670
 56%|    | 27800/50002 [5:49:19<20:55:12,  3.39s/it]Generation 27800: test Loss = 0.00553
 56%|    | 27849/50002 [5:49:50<3:56:42,  1.56it/s]Generation 27850: train Loss = 0.00677
Generation 27850: test Loss = 0.00461
 56%|    | 27899/50002 [5:50:31<3:54:52,  1.57it/s]Generation 27900: train Loss = 0.00593
 56%|    | 27900/50002 [5:50:41<20:57:31,  3.41s/it]Generation 27900: test Loss = 0.00586
 56%|    | 27949/50002 [5:51:12<3:54:44,  1.57it/s]Generation 27950: train Loss = 0.00530
Generation 27950: test Loss = 0.00496
 56%|    | 27999/50002 [5:51:53<3:54:52,  1.56it/s]Generation 28000: train Loss = 0.00573
Generation 28000: test Loss = 0.00417
训练集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.55230123]
 [ 0.56066948]
 [ 0.52719665]
 [ 0.41004184]
 [ 0.43933055]
 [ 0.39330545]
 [ 0.51464432]
 [ 0.47280335]
 [ 0.57322174]]
测试集上一个批次数据的前10个数据
 [[ 0.52719665]
 [ 0.53556484]
 [ 0.39748955]
 [ 0.44351465]
 [ 0.50627613]
 [ 0.49790794]
 [ 0.55230123]
 [ 0.56066948]
 [ 0.50627613]
 [ 0.51046026]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]
 [ 0.49495274]]
 56%|    | 28049/50002 [5:52:36<3:52:51,  1.57it/s]Generation 28050: train Loss = 0.00649
 56%|    | 28050/50002 [5:52:46<21:07:34,  3.46s/it]Generation 28050: test Loss = 0.00520
 56%|    | 28099/50002 [5:53:17<3:53:33,  1.56it/s]Generation 28100: train Loss = 0.00557
 56%|    | 28100/50002 [5:53:27<20:51:51,  3.43s/it]Generation 28100: test Loss = 0.00404
 56%|    | 28149/50002 [5:53:58<3:54:27,  1.55it/s]Generation 28150: train Loss = 0.00471
 56%|    | 28150/50002 [5:54:08<20:51:42,  3.44s/it]Generation 28150: test Loss = 0.00437
 56%|    | 28199/50002 [5:54:40<3:51:11,  1.57it/s]Generation 28200: train Loss = 0.00433
 56%|    | 28200/50002 [5:54:50<20:45:13,  3.43s/it]Generation 28200: test Loss = 0.00457
 56%|    | 28249/50002 [5:55:21<3:51:21,  1.57it/s]Generation 28250: train Loss = 0.00446
Generation 28250: test Loss = 0.00470
 57%|    | 28299/50002 [5:56:02<3:49:50,  1.57it/s]Generation 28300: train Loss = 0.00733
 57%|    | 28300/50002 [5:56:12<20:46:05,  3.45s/it]Generation 28300: test Loss = 0.00420
 57%|    | 28349/50002 [5:56:43<3:49:35,  1.57it/s]Generation 28350: train Loss = 0.00498
Generation 28350: test Loss = 0.00437
 57%|    | 28399/50002 [5:57:25<3:50:30,  1.56it/s]Generation 28400: train Loss = 0.00469
Generation 28400: test Loss = 0.00516
 57%|    | 28449/50002 [5:58:06<3:49:11,  1.57it/s]Generation 28450: train Loss = 0.00519
 57%|    | 28450/50002 [5:58:16<20:38:08,  3.45s/it]Generation 28450: test Loss = 0.00347
 57%|    | 28499/50002 [5:58:47<3:48:28,  1.57it/s]Generation 28500: train Loss = 0.00481
Generation 28500: test Loss = 0.00480
训练集上一个批次数据的前10个数据
 [[ 0.48953974]
 [ 0.41004184]
 [ 0.41422594]
 [ 0.46443516]
 [ 0.32635984]
 [ 0.54811716]
 [ 0.51464432]
 [ 0.51046026]
 [ 0.49790794]
 [ 0.42677826]]
测试集上一个批次数据的前10个数据
 [[ 0.48117155]
 [ 0.47698745]
 [ 0.52301258]
 [ 0.51046026]
 [ 0.50627613]
 [ 0.66945606]
 [ 0.50209206]
 [ 0.43096235]
 [ 0.58158994]
 [ 0.51464432]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]]
 57%|    | 28500/50002 [5:58:59<23:28:10,  3.93s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]
 [ 0.47812766]]
 57%|    | 28549/50002 [5:59:30<3:46:36,  1.58it/s]Generation 28550: train Loss = 0.00707
 57%|    | 28550/50002 [5:59:40<20:59:49,  3.52s/it]Generation 28550: test Loss = 0.00557
 57%|    | 28599/50002 [6:00:11<3:48:59,  1.56it/s]Generation 28600: train Loss = 0.00540
 57%|    | 28600/50002 [6:00:21<20:52:14,  3.51s/it]Generation 28600: test Loss = 0.00517
 57%|    | 28649/50002 [6:00:53<3:47:23,  1.57it/s]Generation 28650: train Loss = 0.00470
 57%|    | 28650/50002 [6:01:03<20:31:53,  3.46s/it]Generation 28650: test Loss = 0.00413
 57%|    | 28699/50002 [6:01:34<3:47:10,  1.56it/s]Generation 28700: train Loss = 0.00530
Generation 28700: test Loss = 0.00444
 57%|    | 28749/50002 [6:02:15<3:44:08,  1.58it/s]Generation 28750: train Loss = 0.00504
Generation 28750: test Loss = 0.00431
 58%|    | 28799/50002 [6:02:57<3:44:43,  1.57it/s]Generation 28800: train Loss = 0.00449
Generation 28800: test Loss = 0.00457
 58%|    | 28849/50002 [6:03:38<3:45:35,  1.56it/s]Generation 28850: train Loss = 0.00510
 58%|    | 28850/50002 [6:03:48<20:33:47,  3.50s/it]Generation 28850: test Loss = 0.00459
 58%|    | 28899/50002 [6:04:20<3:44:58,  1.56it/s]Generation 28900: train Loss = 0.00530
Generation 28900: test Loss = 0.00578
 58%|    | 28949/50002 [6:05:01<3:46:15,  1.55it/s]Generation 28950: train Loss = 0.00491
Generation 28950: test Loss = 0.00419
 58%|    | 28999/50002 [6:05:42<3:45:06,  1.56it/s]Generation 29000: train Loss = 0.00619
Generation 29000: test Loss = 0.00518
训练集上一个批次数据的前10个数据
 [[ 0.33054394]
 [ 0.47698745]
 [ 0.40167364]
 [ 0.38075313]
 [ 0.48535565]
 [ 0.47698745]
 [ 0.41841003]
 [ 0.54811716]
 [ 0.54811716]
 [ 0.43933055]]
测试集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.46861926]
 [ 0.49372384]
 [ 0.52301258]
 [ 0.46861926]
 [ 0.48117155]
 [ 0.58995813]
 [ 0.47698745]
 [ 0.51046026]
 [ 0.58158994]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]]
 58%|    | 29000/50002 [6:05:54<23:26:19,  4.02s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]
 [ 0.49021292]]
 58%|    | 29049/50002 [6:06:25<3:44:17,  1.56it/s]Generation 29050: train Loss = 0.00490
 58%|    | 29050/50002 [6:06:36<20:42:21,  3.56s/it]Generation 29050: test Loss = 0.00456
 58%|    | 29099/50002 [6:07:07<3:42:33,  1.57it/s]Generation 29100: train Loss = 0.00374
 58%|    | 29100/50002 [6:07:17<20:28:45,  3.53s/it]Generation 29100: test Loss = 0.00457
 58%|    | 29149/50002 [6:07:49<3:42:35,  1.56it/s]Generation 29150: train Loss = 0.00561
 58%|    | 29150/50002 [6:07:59<20:14:48,  3.50s/it]Generation 29150: test Loss = 0.00345
 58%|    | 29199/50002 [6:08:30<3:41:37,  1.56it/s]Generation 29200: train Loss = 0.00433
Generation 29200: test Loss = 0.00450
 58%|    | 29249/50002 [6:09:12<3:40:53,  1.57it/s]Generation 29250: train Loss = 0.00643
Generation 29250: test Loss = 0.00471
 59%|    | 29299/50002 [6:09:53<3:40:55,  1.56it/s]Generation 29300: train Loss = 0.00637
Generation 29300: test Loss = 0.00356
 59%|    | 29349/50002 [6:10:35<3:40:52,  1.56it/s]Generation 29350: train Loss = 0.00457
Generation 29350: test Loss = 0.00478
 59%|    | 29399/50002 [6:11:16<3:39:40,  1.56it/s]Generation 29400: train Loss = 0.00589
 59%|    | 29400/50002 [6:11:26<20:08:07,  3.52s/it]Generation 29400: test Loss = 0.00410
 59%|    | 29449/50002 [6:11:58<3:40:13,  1.56it/s]Generation 29450: train Loss = 0.00426
Generation 29450: test Loss = 0.00390
 59%|    | 29499/50002 [6:12:39<3:38:40,  1.56it/s]Generation 29500: train Loss = 0.00436
Generation 29500: test Loss = 0.00564
训练集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.49790794]
 [ 0.52719665]
 [ 0.49790794]
 [ 0.34309623]
 [ 0.55230123]
 [ 0.46861926]
 [ 0.43514645]
 [ 0.49790794]
 [ 0.37656903]]
测试集上一个批次数据的前10个数据
 [[ 0.54811716]
 [ 0.41004184]
 [ 0.44351465]
 [ 0.44769874]
 [ 0.51464432]
 [ 0.53974897]
 [ 0.51046026]
 [ 0.43514645]
 [ 0.49372384]
 [ 0.41004184]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 59%|    | 29500/50002 [6:12:51<23:11:19,  4.07s/it] [ 0.46313825]
 [ 0.46313825]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]
 [ 0.46313825]]
 59%|    | 29549/50002 [6:13:22<3:37:35,  1.57it/s]Generation 29550: train Loss = 0.00379
 59%|    | 29550/50002 [6:13:33<20:18:09,  3.57s/it]Generation 29550: test Loss = 0.00531
 59%|    | 29599/50002 [6:14:04<3:36:13,  1.57it/s]Generation 29600: train Loss = 0.00552
 59%|    | 29600/50002 [6:14:14<20:14:35,  3.57s/it]Generation 29600: test Loss = 0.00460
 59%|    | 29649/50002 [6:14:46<3:36:46,  1.56it/s]Generation 29650: train Loss = 0.00533
Generation 29650: test Loss = 0.00435
 59%|    | 29699/50002 [6:15:28<3:36:40,  1.56it/s]Generation 29700: train Loss = 0.00561
 59%|    | 29700/50002 [6:15:38<20:06:31,  3.57s/it]Generation 29700: test Loss = 0.00452
 59%|    | 29749/50002 [6:16:09<3:34:36,  1.57it/s]Generation 29750: train Loss = 0.00457
Generation 29750: test Loss = 0.00418
 60%|    | 29799/50002 [6:16:51<3:33:41,  1.58it/s]Generation 29800: train Loss = 0.00438
 60%|    | 29800/50002 [6:17:01<19:56:05,  3.55s/it]Generation 29800: test Loss = 0.00484
 60%|    | 29849/50002 [6:17:33<3:35:09,  1.56it/s]Generation 29850: train Loss = 0.00483
 60%|    | 29850/50002 [6:17:43<20:08:42,  3.60s/it]Generation 29850: test Loss = 0.00508
 60%|    | 29899/50002 [6:18:14<3:34:16,  1.56it/s]Generation 29900: train Loss = 0.00462
 60%|    | 29900/50002 [6:18:25<19:52:53,  3.56s/it]Generation 29900: test Loss = 0.00468
 60%|    | 29949/50002 [6:18:56<3:31:51,  1.58it/s]Generation 29950: train Loss = 0.00424
Generation 29950: test Loss = 0.00550
 60%|    | 29999/50002 [6:19:38<3:33:35,  1.56it/s]Generation 30000: train Loss = 0.00699
Generation 30000: test Loss = 0.00364
训练集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.48953974]
 [ 0.54393303]
 [ 0.50209206]
 [ 0.52301258]
 [ 0.53974897]
 [ 0.53556484]
 [ 0.51464432]
 [ 0.50627613]
 [ 0.41841003]]
测试集上一个批次数据的前10个数据
 [[ 0.52301258]
 [ 0.56485355]
 [ 0.53138077]
 [ 0.53974897]
 [ 0.40585774]
 [ 0.56066948]
 [ 0.54393303]
 [ 0.60669458]
 [ 0.56903768]
 [ 0.38493723]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]
 [ 0.49091342]]
 60%|    | 30049/50002 [6:21:38<3:32:28,  1.57it/s]Generation 30050: train Loss = 0.00452
Generation 30050: test Loss = 0.00492
 60%|    | 30099/50002 [6:22:22<3:30:04,  1.58it/s]Generation 30100: train Loss = 0.00463
Generation 30100: test Loss = 0.00350
 60%|    | 30149/50002 [6:23:04<3:30:58,  1.57it/s]Generation 30150: train Loss = 0.00422
 60%|    | 30150/50002 [6:23:15<20:19:29,  3.69s/it]Generation 30150: test Loss = 0.00583
 60%|    | 30199/50002 [6:23:46<3:29:39,  1.57it/s]Generation 30200: train Loss = 0.00472
Generation 30200: test Loss = 0.00369
 60%|    | 30249/50002 [6:24:28<3:29:34,  1.57it/s]Generation 30250: train Loss = 0.00516
Generation 30250: test Loss = 0.00535
 61%|    | 30299/50002 [6:25:10<3:30:41,  1.56it/s]Generation 30300: train Loss = 0.00401
Generation 30300: test Loss = 0.00497
 61%|    | 30349/50002 [6:25:52<3:28:04,  1.57it/s]Generation 30350: train Loss = 0.00471
 61%|    | 30350/50002 [6:26:03<20:12:48,  3.70s/it]Generation 30350: test Loss = 0.00387
 61%|    | 30399/50002 [6:26:34<3:29:13,  1.56it/s]Generation 30400: train Loss = 0.00561
Generation 30400: test Loss = 0.00437
 61%|    | 30449/50002 [6:27:16<3:28:43,  1.56it/s]Generation 30450: train Loss = 0.00496
 61%|    | 30450/50002 [6:27:28<21:04:21,  3.88s/it]Generation 30450: test Loss = 0.00465
 61%|    | 30499/50002 [6:27:59<3:26:12,  1.58it/s]Generation 30500: train Loss = 0.00617
Generation 30500: test Loss = 0.00455
训练集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.48953974]
 [ 0.42259413]
 [ 0.43933055]
 [ 0.35983264]
 [ 0.45606694]
 [ 0.45606694]
 [ 0.49790794]
 [ 0.48117155]
 [ 0.46443516]]
测试集上一个批次数据的前10个数据
 [[ 0.53138077]
 [ 0.57322174]
 [ 0.48953974]
 [ 0.53974897]
 [ 0.53974897]
 [ 0.47698745]
 [ 0.52719665]
 [ 0.56066948]
 [ 0.63598329]
 [ 0.49790794]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]]
测试集上一个批次数据中通过inference后的前10个输出结果
 61%|    | 30500/50002 [6:28:12<23:30:34,  4.34s/it] [[ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]
 [ 0.49879485]]
 61%|    | 30549/50002 [6:28:43<3:27:20,  1.56it/s]Generation 30550: train Loss = 0.00444
 61%|    | 30550/50002 [6:28:54<20:02:56,  3.71s/it]Generation 30550: test Loss = 0.00405
 61%|    | 30599/50002 [6:29:25<3:26:51,  1.56it/s]Generation 30600: train Loss = 0.00487
 61%|    | 30600/50002 [6:29:37<21:09:37,  3.93s/it]Generation 30600: test Loss = 0.00511
 61%|   | 30649/50002 [6:30:07<3:28:26,  1.55it/s]Generation 30650: train Loss = 0.00514
Generation 30650: test Loss = 0.00539
 61%|   | 30699/50002 [6:30:50<3:25:17,  1.57it/s]Generation 30700: train Loss = 0.00480
 61%|   | 30700/50002 [6:31:01<20:09:56,  3.76s/it]Generation 30700: test Loss = 0.00484
 61%|   | 30749/50002 [6:31:32<3:25:53,  1.56it/s]Generation 30750: train Loss = 0.00497
 61%|   | 30750/50002 [6:31:43<20:00:04,  3.74s/it]Generation 30750: test Loss = 0.00505
 62%|   | 30799/50002 [6:32:14<3:23:13,  1.57it/s]Generation 30800: train Loss = 0.00544
Generation 30800: test Loss = 0.00347
 62%|   | 30849/50002 [6:32:56<3:24:12,  1.56it/s]Generation 30850: train Loss = 0.00532
Generation 30850: test Loss = 0.00396
 62%|   | 30899/50002 [6:33:38<3:23:40,  1.56it/s]Generation 30900: train Loss = 0.00532
 62%|   | 30900/50002 [6:33:49<19:47:18,  3.73s/it]Generation 30900: test Loss = 0.00336
 62%|   | 30949/50002 [6:34:20<3:21:19,  1.58it/s]Generation 30950: train Loss = 0.00425
Generation 30950: test Loss = 0.00391
 62%|   | 30999/50002 [6:35:02<3:20:23,  1.58it/s]Generation 31000: train Loss = 0.00468
Generation 31000: test Loss = 0.00518
训练集上一个批次数据的前10个数据
 [[ 0.64016736]
 [ 0.48117155]
 [ 0.56066948]
 [ 0.48953974]
 [ 0.17573223]
 [ 0.48535565]
 [ 0.58577406]
 [ 0.54393303]
 [ 0.49372384]
 [ 0.53138077]]
测试集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.66108787]
 [ 0.54811716]
 [ 0.49790794]
 [ 0.49790794]
 [ 0.55230123]
 [ 0.58995813]
 [ 0.45606694]
 [ 0.37656903]
 [ 0.51046026]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]
 [ 0.48058322]]
 62%|   | 31049/50002 [6:35:46<3:22:06,  1.56it/s]Generation 31050: train Loss = 0.00517
Generation 31050: test Loss = 0.00422
 62%|   | 31099/50002 [6:36:28<3:20:53,  1.57it/s]Generation 31100: train Loss = 0.00534
Generation 31100: test Loss = 0.00310
 62%|   | 31149/50002 [6:37:10<3:19:59,  1.57it/s]Generation 31150: train Loss = 0.00479
 62%|   | 31150/50002 [6:37:21<19:19:17,  3.69s/it]Generation 31150: test Loss = 0.00492
 62%|   | 31199/50002 [6:37:52<3:21:01,  1.56it/s]Generation 31200: train Loss = 0.00555
 62%|   | 31200/50002 [6:38:03<19:21:42,  3.71s/it]Generation 31200: test Loss = 0.00391
 62%|   | 31249/50002 [6:38:34<3:18:16,  1.58it/s]Generation 31250: train Loss = 0.00508
 62%|   | 31250/50002 [6:38:45<19:21:27,  3.72s/it]Generation 31250: test Loss = 0.00476
 63%|   | 31299/50002 [6:39:16<3:18:04,  1.57it/s]Generation 31300: train Loss = 0.00458
 63%|   | 31300/50002 [6:39:27<19:17:08,  3.71s/it]Generation 31300: test Loss = 0.00476
 63%|   | 31349/50002 [6:39:58<3:18:47,  1.56it/s]Generation 31350: train Loss = 0.00543
Generation 31350: test Loss = 0.00437
 63%|   | 31399/50002 [6:40:40<3:17:36,  1.57it/s]Generation 31400: train Loss = 0.00604
 63%|   | 31400/50002 [6:40:51<19:04:06,  3.69s/it]Generation 31400: test Loss = 0.00389
 63%|   | 31449/50002 [6:41:22<3:17:38,  1.56it/s]Generation 31450: train Loss = 0.00581
 63%|   | 31450/50002 [6:41:33<19:01:24,  3.69s/it]Generation 31450: test Loss = 0.00462
 63%|   | 31499/50002 [6:42:05<3:15:57,  1.57it/s]Generation 31500: train Loss = 0.00463
Generation 31500: test Loss = 0.00333
训练集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.49790794]
 [ 0.48117155]
 [ 0.51046026]
 [ 0.44769874]
 [ 0.55230123]
 [ 0.54393303]
 [ 0.46025103]
 [ 0.49372384]
 [ 0.43933055]]
测试集上一个批次数据的前10个数据
 [[ 0.56066948]
 [ 0.61924684]
 [ 0.47698745]
 [ 0.60669458]
 [ 0.43514645]
 [ 0.51882845]
 [ 0.48535565]
 [ 0.38075313]
 [ 0.55230123]
 [ 0.39748955]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]]
测试集上一个批次数据中通过inference后的前10个输出结果
 63%|   | 31500/50002 [6:42:17<21:48:06,  4.24s/it] [[ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]
 [ 0.48995978]]
 63%|   | 31549/50002 [6:42:48<3:14:37,  1.58it/s]Generation 31550: train Loss = 0.00513
 63%|   | 31550/50002 [6:42:59<19:18:24,  3.77s/it]Generation 31550: test Loss = 0.00414
 63%|   | 31599/50002 [6:43:30<3:15:24,  1.57it/s]Generation 31600: train Loss = 0.00468
 63%|   | 31600/50002 [6:43:41<19:03:14,  3.73s/it]Generation 31600: test Loss = 0.00360
 63%|   | 31649/50002 [6:44:13<3:14:26,  1.57it/s]Generation 31650: train Loss = 0.00503
Generation 31650: test Loss = 0.00516
 63%|   | 31699/50002 [6:44:55<3:16:57,  1.55it/s]Generation 31700: train Loss = 0.00492
 63%|   | 31700/50002 [6:45:06<19:44:36,  3.88s/it]Generation 31700: test Loss = 0.00515
 63%|   | 31749/50002 [6:45:37<3:14:06,  1.57it/s]Generation 31750: train Loss = 0.00389
Generation 31750: test Loss = 0.00496
 64%|   | 31799/50002 [6:46:19<3:13:24,  1.57it/s]Generation 31800: train Loss = 0.00490
Generation 31800: test Loss = 0.00452
 64%|   | 31849/50002 [6:47:02<3:12:51,  1.57it/s]Generation 31850: train Loss = 0.00555
 64%|   | 31850/50002 [6:47:13<19:28:54,  3.86s/it]Generation 31850: test Loss = 0.00415
 64%|   | 31899/50002 [6:47:44<3:13:48,  1.56it/s]Generation 31900: train Loss = 0.00424
 64%|   | 31900/50002 [6:47:55<19:23:54,  3.86s/it]Generation 31900: test Loss = 0.00353
 64%|   | 31949/50002 [6:48:26<3:11:04,  1.57it/s]Generation 31950: train Loss = 0.00580
Generation 31950: test Loss = 0.00515
 64%|   | 31999/50002 [6:49:09<3:10:24,  1.58it/s]Generation 32000: train Loss = 0.00397
Generation 32000: test Loss = 0.00556
训练集上一个批次数据的前10个数据
 [[ 0.45606694]
 [ 0.45188284]
 [ 0.53974897]
 [ 0.63598329]
 [ 0.45188284]
 [ 0.48535565]
 [ 0.32635984]
 [ 0.43514645]
 [ 0.56066948]
 [ 0.44769874]]
测试集上一个批次数据的前10个数据
 [[ 0.53138077]
 [ 0.52719665]
 [ 0.53556484]
 [ 0.46443516]
 [ 0.56066948]
 [ 0.49372384]
 [ 0.46025103]
 [ 0.48117155]
 [ 0.57740587]
 [ 0.42677826]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]
 [ 0.50813043]]
 64%|   | 32049/50002 [6:49:53<3:09:20,  1.58it/s]Generation 32050: train Loss = 0.00415
 64%|   | 32050/50002 [6:50:04<18:54:01,  3.79s/it]Generation 32050: test Loss = 0.00499
 64%|   | 32099/50002 [6:50:35<3:09:56,  1.57it/s]Generation 32100: train Loss = 0.00504
Generation 32100: test Loss = 0.00647
 64%|   | 32149/50002 [6:51:17<3:09:25,  1.57it/s]Generation 32150: train Loss = 0.00472
Generation 32150: test Loss = 0.00445
 64%|   | 32199/50002 [6:52:00<3:09:17,  1.57it/s]Generation 32200: train Loss = 0.00461
Generation 32200: test Loss = 0.00628
 64%|   | 32249/50002 [6:52:42<3:08:47,  1.57it/s]Generation 32250: train Loss = 0.00541
Generation 32250: test Loss = 0.00458
 65%|   | 32299/50002 [6:53:24<3:07:34,  1.57it/s]Generation 32300: train Loss = 0.00398
 65%|   | 32300/50002 [6:53:35<18:34:41,  3.78s/it]Generation 32300: test Loss = 0.00582
 65%|   | 32349/50002 [6:54:07<3:07:45,  1.57it/s]Generation 32350: train Loss = 0.00430
 65%|   | 32350/50002 [6:54:18<18:43:04,  3.82s/it]Generation 32350: test Loss = 0.00520
 65%|   | 32399/50002 [6:54:49<3:06:03,  1.58it/s]Generation 32400: train Loss = 0.00474
 65%|   | 32400/50002 [6:55:00<18:58:20,  3.88s/it]Generation 32400: test Loss = 0.00448
 65%|   | 32449/50002 [6:55:31<3:06:41,  1.57it/s]Generation 32450: train Loss = 0.00515
Generation 32450: test Loss = 0.00483
 65%|   | 32499/50002 [6:56:14<3:07:49,  1.55it/s]Generation 32500: train Loss = 0.00481
Generation 32500: test Loss = 0.00456
训练集上一个批次数据的前10个数据
 [[ 0.57740587]
 [ 0.51046026]
 [ 0.53556484]
 [ 0.48953974]
 [ 0.49372384]
 [ 0.44769874]
 [ 0.29288703]
 [ 0.48953974]
 [ 0.50209206]
 [ 0.46443516]]
测试集上一个批次数据的前10个数据
 [[ 0.51464432]
 [ 0.56066948]
 [ 0.40167364]
 [ 0.51882845]
 [ 0.44769874]
 [ 0.58995813]
 [ 0.45188284]
 [ 0.44769874]
 [ 0.56485355]
 [ 0.32635984]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]
 [ 0.50256968]]
 65%|   | 32549/50002 [6:56:58<3:06:23,  1.56it/s]Generation 32550: train Loss = 0.00492
 65%|   | 32550/50002 [6:57:09<18:47:14,  3.88s/it]Generation 32550: test Loss = 0.00393
 65%|   | 32599/50002 [6:57:41<3:04:12,  1.57it/s]Generation 32600: train Loss = 0.00536
Generation 32600: test Loss = 0.00464
 65%|   | 32649/50002 [6:58:23<3:04:29,  1.57it/s]Generation 32650: train Loss = 0.00473
Generation 32650: test Loss = 0.00484
 65%|   | 32699/50002 [6:59:06<3:05:07,  1.56it/s]Generation 32700: train Loss = 0.00439
 65%|   | 32700/50002 [6:59:17<18:39:08,  3.88s/it]Generation 32700: test Loss = 0.00361
 65%|   | 32749/50002 [6:59:48<3:04:06,  1.56it/s]Generation 32750: train Loss = 0.00474
Generation 32750: test Loss = 0.00473
 66%|   | 32799/50002 [7:00:31<3:03:09,  1.57it/s]Generation 32800: train Loss = 0.00492
 66%|   | 32800/50002 [7:00:43<18:36:04,  3.89s/it]Generation 32800: test Loss = 0.00668
 66%|   | 32849/50002 [7:01:14<3:02:45,  1.56it/s]Generation 32850: train Loss = 0.00524
Generation 32850: test Loss = 0.00451
 66%|   | 32899/50002 [7:01:56<3:01:26,  1.57it/s]Generation 32900: train Loss = 0.00579
Generation 32900: test Loss = 0.00298
 66%|   | 32949/50002 [7:02:39<3:03:11,  1.55it/s]Generation 32950: train Loss = 0.00447
Generation 32950: test Loss = 0.00512
 66%|   | 32999/50002 [7:03:21<2:59:38,  1.58it/s]Generation 33000: train Loss = 0.00426
Generation 33000: test Loss = 0.00524
训练集上一个批次数据的前10个数据
 [[ 0.69456065]
 [ 0.64435148]
 [ 0.43933055]
 [ 0.52301258]
 [ 0.51046026]
 [ 0.52719665]
 [ 0.53556484]
 [ 0.45188284]
 [ 0.51464432]
 [ 0.40167364]]
测试集上一个批次数据的前10个数据
 [[ 0.46025103]
 [ 0.51882845]
 [ 0.48953974]
 [ 0.39330545]
 [ 0.53556484]
 [ 0.54811716]
 [ 0.53974897]
 [ 0.42677826]
 [ 0.36820084]
 [ 0.48953974]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]]
 66%|   | 33000/50002 [7:03:35<21:28:06,  4.55s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]
 [ 0.47052062]]
 66%|   | 33049/50002 [7:04:06<2:59:45,  1.57it/s]Generation 33050: train Loss = 0.00565
Generation 33050: test Loss = 0.00346
 66%|   | 33099/50002 [7:04:49<3:01:18,  1.55it/s]Generation 33100: train Loss = 0.00474
Generation 33100: test Loss = 0.00470
 66%|   | 33149/50002 [7:05:32<3:00:49,  1.55it/s]Generation 33150: train Loss = 0.00437
 66%|   | 33150/50002 [7:05:43<18:32:46,  3.96s/it]Generation 33150: test Loss = 0.00483
 66%|   | 33199/50002 [7:06:14<2:58:09,  1.57it/s]Generation 33200: train Loss = 0.00532
 66%|   | 33200/50002 [7:06:26<18:08:18,  3.89s/it]Generation 33200: test Loss = 0.00396
 66%|   | 33249/50002 [7:06:57<2:58:16,  1.57it/s]Generation 33250: train Loss = 0.00471
 66%|   | 33250/50002 [7:07:09<18:22:31,  3.95s/it]Generation 33250: test Loss = 0.00395
 67%|   | 33299/50002 [7:07:39<2:56:54,  1.57it/s]Generation 33300: train Loss = 0.00635
 67%|   | 33300/50002 [7:07:51<18:12:07,  3.92s/it]Generation 33300: test Loss = 0.00715
 67%|   | 33349/50002 [7:08:22<2:57:39,  1.56it/s]Generation 33350: train Loss = 0.00571
Generation 33350: test Loss = 0.00349
 67%|   | 33399/50002 [7:09:05<2:57:03,  1.56it/s]Generation 33400: train Loss = 0.00396
Generation 33400: test Loss = 0.00663
 67%|   | 33449/50002 [7:09:47<2:55:44,  1.57it/s]Generation 33450: train Loss = 0.00580
Generation 33450: test Loss = 0.00381
 67%|   | 33499/50002 [7:10:30<2:55:33,  1.57it/s]Generation 33500: train Loss = 0.00535
Generation 33500: test Loss = 0.00524
训练集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.51464432]
 [ 0.46443516]
 [ 0.52301258]
 [ 0.48535565]
 [ 0.46861926]
 [ 0.52301258]
 [ 0.43933055]
 [ 0.41422594]
 [ 0.51046026]]
测试集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.39748955]
 [ 0.52719665]
 [ 0.56903768]
 [ 0.43933055]
 [ 0.38912135]
 [ 0.52719665]
 [ 0.46861926]
 [ 0.33472803]
 [ 0.53138077]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]
 [ 0.51652795]]
 67%|   | 33549/50002 [7:11:15<2:55:20,  1.56it/s]Generation 33550: train Loss = 0.00522
 67%|   | 33550/50002 [7:11:27<18:09:23,  3.97s/it]Generation 33550: test Loss = 0.00295
 67%|   | 33599/50002 [7:11:58<2:55:19,  1.56it/s]Generation 33600: train Loss = 0.00516
 67%|   | 33600/50002 [7:12:09<18:00:02,  3.95s/it]Generation 33600: test Loss = 0.00452
 67%|   | 33649/50002 [7:12:40<2:54:44,  1.56it/s]Generation 33650: train Loss = 0.00565
Generation 33650: test Loss = 0.00402
 67%|   | 33699/50002 [7:13:23<2:53:38,  1.56it/s]Generation 33700: train Loss = 0.00596
 67%|   | 33700/50002 [7:13:35<17:58:06,  3.97s/it]Generation 33700: test Loss = 0.00474
 67%|   | 33749/50002 [7:14:06<2:51:54,  1.58it/s]Generation 33750: train Loss = 0.00428
Generation 33750: test Loss = 0.00459
 68%|   | 33799/50002 [7:14:49<2:53:42,  1.55it/s]Generation 33800: train Loss = 0.00527
 68%|   | 33800/50002 [7:15:00<17:48:29,  3.96s/it]Generation 33800: test Loss = 0.00608
 68%|   | 33849/50002 [7:15:31<2:52:49,  1.56it/s]Generation 33850: train Loss = 0.00590
 68%|   | 33850/50002 [7:15:43<17:57:34,  4.00s/it]Generation 33850: test Loss = 0.00465
 68%|   | 33899/50002 [7:16:14<2:51:18,  1.57it/s]Generation 33900: train Loss = 0.00486
 68%|   | 33900/50002 [7:16:26<17:32:09,  3.92s/it]Generation 33900: test Loss = 0.00487
 68%|   | 33949/50002 [7:16:57<2:50:47,  1.57it/s]Generation 33950: train Loss = 0.00442
 68%|   | 33950/50002 [7:17:09<17:32:40,  3.93s/it]Generation 33950: test Loss = 0.00461
 68%|   | 33999/50002 [7:17:40<2:49:14,  1.58it/s]Generation 34000: train Loss = 0.00495
Generation 34000: test Loss = 0.00680
训练集上一个批次数据的前10个数据
 [[ 0.42259413]
 [ 0.44351465]
 [ 0.46861926]
 [ 0.58995813]
 [ 0.45188284]
 [ 0.44351465]
 [ 0.55230123]
 [ 0.53974897]
 [ 0.47280335]
 [ 0.54811716]]
测试集上一个批次数据的前10个数据
 [[ 0.39748955]
 [ 0.49372384]
 [ 0.48535565]
 [ 0.42259413]
 [ 0.35983264]
 [ 0.61087865]
 [ 0.54811716]
 [ 0.52301258]
 [ 0.63179916]
 [ 0.51882845]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]
 [ 0.46192995]]
 68%|   | 34049/50002 [7:18:25<2:49:53,  1.56it/s]Generation 34050: train Loss = 0.00566
 68%|   | 34050/50002 [7:18:37<17:38:41,  3.98s/it]Generation 34050: test Loss = 0.00502
 68%|   | 34099/50002 [7:19:08<2:48:01,  1.58it/s]Generation 34100: train Loss = 0.00499
Generation 34100: test Loss = 0.00577
 68%|   | 34149/50002 [7:19:51<2:48:07,  1.57it/s]Generation 34150: train Loss = 0.00431
 68%|   | 34150/50002 [7:20:03<17:45:11,  4.03s/it]Generation 34150: test Loss = 0.00418
 68%|   | 34199/50002 [7:20:34<2:48:18,  1.56it/s]Generation 34200: train Loss = 0.00489
Generation 34200: test Loss = 0.00359
 68%|   | 34249/50002 [7:21:17<2:49:04,  1.55it/s]Generation 34250: train Loss = 0.00441
Generation 34250: test Loss = 0.00459
 69%|   | 34299/50002 [7:22:00<2:47:24,  1.56it/s]Generation 34300: train Loss = 0.00491
 69%|   | 34300/50002 [7:22:12<17:22:13,  3.98s/it]Generation 34300: test Loss = 0.00329
 69%|   | 34349/50002 [7:22:43<2:47:31,  1.56it/s]Generation 34350: train Loss = 0.00461
Generation 34350: test Loss = 0.00392
 69%|   | 34399/50002 [7:23:25<2:45:38,  1.57it/s]Generation 34400: train Loss = 0.00508
Generation 34400: test Loss = 0.00451
 69%|   | 34449/50002 [7:24:08<2:45:48,  1.56it/s]Generation 34450: train Loss = 0.00684
 69%|   | 34450/50002 [7:24:20<17:21:59,  4.02s/it]Generation 34450: test Loss = 0.00522
 69%|   | 34499/50002 [7:24:51<2:44:33,  1.57it/s]Generation 34500: train Loss = 0.00500
Generation 34500: test Loss = 0.00456
训练集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.31799164]
 [ 0.43096235]
 [ 0.65690374]
 [ 0.64016736]
 [ 0.46443516]
 [ 0.42259413]
 [ 0.56903768]
 [ 0.40167364]
 [ 0.56485355]]
测试集上一个批次数据的前10个数据
 [[ 0.56485355]
 [ 0.53556484]
 [ 0.63598329]
 [ 0.52719665]
 [ 0.46861926]
 [ 0.55230123]
 [ 0.42677826]
 [ 0.51464432]
 [ 0.45188284]
 [ 0.54393303]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]]
 69%|   | 34500/50002 [7:25:05<19:26:31,  4.51s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]
 [ 0.51541382]]
 69%|   | 34549/50002 [7:25:36<2:44:29,  1.57it/s]Generation 34550: train Loss = 0.00398
Generation 34550: test Loss = 0.00407
 69%|   | 34599/50002 [7:26:19<2:43:10,  1.57it/s]Generation 34600: train Loss = 0.00438
 69%|   | 34600/50002 [7:26:31<17:24:27,  4.07s/it]Generation 34600: test Loss = 0.00428
 69%|   | 34649/50002 [7:27:02<2:42:40,  1.57it/s]Generation 34650: train Loss = 0.00394
Generation 34650: test Loss = 0.00530
 69%|   | 34699/50002 [7:27:45<2:42:00,  1.57it/s]Generation 34700: train Loss = 0.00466
Generation 34700: test Loss = 0.00407
 69%|   | 34749/50002 [7:28:28<2:43:15,  1.56it/s]Generation 34750: train Loss = 0.00432
 69%|   | 34750/50002 [7:28:40<17:08:17,  4.05s/it]Generation 34750: test Loss = 0.00499
 70%|   | 34799/50002 [7:29:11<2:40:12,  1.58it/s]Generation 34800: train Loss = 0.00515
Generation 34800: test Loss = 0.00485
 70%|   | 34849/50002 [7:29:54<2:41:36,  1.56it/s]Generation 34850: train Loss = 0.00482
 70%|   | 34850/50002 [7:30:07<17:30:45,  4.16s/it]Generation 34850: test Loss = 0.00506
 70%|   | 34899/50002 [7:30:38<2:40:38,  1.57it/s]Generation 34900: train Loss = 0.00467
Generation 34900: test Loss = 0.00413
 70%|   | 34949/50002 [7:31:21<2:40:37,  1.56it/s]Generation 34950: train Loss = 0.00654
 70%|   | 34950/50002 [7:31:33<17:00:20,  4.07s/it]Generation 34950: test Loss = 0.00499
 70%|   | 34999/50002 [7:32:04<2:40:01,  1.56it/s]Generation 35000: train Loss = 0.00405
Generation 35000: test Loss = 0.00447
训练集上一个批次数据的前10个数据
 [[ 0.54393303]
 [ 0.53556484]
 [ 0.50209206]
 [ 0.47698745]
 [ 0.57740587]
 [ 0.53974897]
 [ 0.55648535]
 [ 0.52301258]
 [ 0.46025103]
 [ 0.63598329]]
测试集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.46025103]
 [ 0.57740587]
 [ 0.46443516]
 [ 0.44351465]
 [ 0.48535565]
 [ 0.59414226]
 [ 0.64016736]
 [ 0.59414226]
 [ 0.61087865]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]
 [ 0.48391849]]
 70%|   | 35049/50002 [7:32:50<2:40:12,  1.56it/s]Generation 35050: train Loss = 0.00392
 70%|   | 35050/50002 [7:33:02<17:09:12,  4.13s/it]Generation 35050: test Loss = 0.00398
 70%|   | 35099/50002 [7:33:33<2:39:02,  1.56it/s]Generation 35100: train Loss = 0.00553
Generation 35100: test Loss = 0.00499
 70%|   | 35149/50002 [7:34:16<2:39:25,  1.55it/s]Generation 35150: train Loss = 0.00381
 70%|   | 35150/50002 [7:34:28<16:54:24,  4.10s/it]Generation 35150: test Loss = 0.00476
 70%|   | 35199/50002 [7:34:59<2:38:00,  1.56it/s]Generation 35200: train Loss = 0.00520
Generation 35200: test Loss = 0.00545
 70%|   | 35249/50002 [7:35:43<2:37:04,  1.57it/s]Generation 35250: train Loss = 0.00488
 70%|   | 35250/50002 [7:35:54<16:34:00,  4.04s/it]Generation 35250: test Loss = 0.00467
 71%|   | 35299/50002 [7:36:26<2:36:07,  1.57it/s]Generation 35300: train Loss = 0.00569
Generation 35300: test Loss = 0.00393
 71%|   | 35349/50002 [7:37:09<2:36:57,  1.56it/s]Generation 35350: train Loss = 0.00400
 71%|   | 35350/50002 [7:37:21<16:42:49,  4.11s/it]Generation 35350: test Loss = 0.00487
 71%|   | 35399/50002 [7:37:52<2:35:55,  1.56it/s]Generation 35400: train Loss = 0.00394
 71%|   | 35400/50002 [7:38:04<16:35:37,  4.09s/it]Generation 35400: test Loss = 0.00399
 71%|   | 35449/50002 [7:38:35<2:34:11,  1.57it/s]Generation 35450: train Loss = 0.00411
 71%|   | 35450/50002 [7:38:48<16:34:47,  4.10s/it]Generation 35450: test Loss = 0.00418
 71%|   | 35499/50002 [7:39:19<2:33:52,  1.57it/s]Generation 35500: train Loss = 0.00487
Generation 35500: test Loss = 0.00421
训练集上一个批次数据的前10个数据
 [[ 0.48117155]
 [ 0.47698745]
 [ 0.49372384]
 [ 0.38075313]
 [ 0.41841003]
 [ 0.42677826]
 [ 0.52719665]
 [ 0.51046026]
 [ 0.50627613]
 [ 0.51882845]]
测试集上一个批次数据的前10个数据
 [[ 0.46443516]
 [ 0.48535565]
 [ 0.51046026]
 [ 0.48953974]
 [ 0.41841003]
 [ 0.56485355]
 [ 0.51464432]
 [ 0.40585774]
 [ 0.55230123]
 [ 0.52301258]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]]
 71%|   | 35500/50002 [7:39:33<18:49:45,  4.67s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]
 [ 0.4987781]]
 71%|   | 35549/50002 [7:40:04<2:34:10,  1.56it/s]Generation 35550: train Loss = 0.00299
 71%|   | 35550/50002 [7:40:16<16:27:32,  4.10s/it]Generation 35550: test Loss = 0.00520
 71%|   | 35599/50002 [7:40:47<2:34:08,  1.56it/s]Generation 35600: train Loss = 0.00529
Generation 35600: test Loss = 0.00431
 71%|  | 35649/50002 [7:41:30<2:33:13,  1.56it/s]Generation 35650: train Loss = 0.00449
 71%|  | 35650/50002 [7:41:43<16:25:16,  4.12s/it]Generation 35650: test Loss = 0.00390
 71%|  | 35699/50002 [7:42:14<2:32:54,  1.56it/s]Generation 35700: train Loss = 0.00444
 71%|  | 35700/50002 [7:42:26<16:45:28,  4.22s/it]Generation 35700: test Loss = 0.00345
 71%|  | 35749/50002 [7:42:57<2:32:04,  1.56it/s]Generation 35750: train Loss = 0.00505
Generation 35750: test Loss = 0.00571
 72%|  | 35799/50002 [7:43:41<2:31:29,  1.56it/s]Generation 35800: train Loss = 0.00596
 72%|  | 35800/50002 [7:43:53<16:22:39,  4.15s/it]Generation 35800: test Loss = 0.00311
 72%|  | 35849/50002 [7:44:24<2:30:14,  1.57it/s]Generation 35850: train Loss = 0.00378
 72%|  | 35850/50002 [7:44:37<16:30:51,  4.20s/it]Generation 35850: test Loss = 0.00438
 72%|  | 35899/50002 [7:45:08<2:30:47,  1.56it/s]Generation 35900: train Loss = 0.00494
 72%|  | 35900/50002 [7:45:21<16:53:27,  4.31s/it]Generation 35900: test Loss = 0.00346
 72%|  | 35949/50002 [7:45:52<2:29:11,  1.57it/s]Generation 35950: train Loss = 0.00591
 72%|  | 35950/50002 [7:46:04<16:32:39,  4.24s/it]Generation 35950: test Loss = 0.00421
 72%|  | 35999/50002 [7:46:35<2:29:43,  1.56it/s]Generation 36000: train Loss = 0.00490
Generation 36000: test Loss = 0.00519
训练集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.56066948]
 [ 0.43514645]
 [ 0.56903768]
 [ 0.46025103]
 [ 0.44769874]
 [ 0.62343097]
 [ 0.48117155]
 [ 0.49372384]
 [ 0.58995813]]
测试集上一个批次数据的前10个数据
 [[ 0.42677826]
 [ 0.48535565]
 [ 0.48117155]
 [ 0.56066948]
 [ 0.46443516]
 [ 0.54393303]
 [ 0.53556484]
 [ 0.64016736]
 [ 0.53556484]
 [ 0.46861926]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]]
 72%|  | 36000/50002 [7:46:50<18:55:21,  4.87s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]
 [ 0.48060173]]
 72%|  | 36049/50002 [7:47:21<2:29:07,  1.56it/s]Generation 36050: train Loss = 0.00496
 72%|  | 36050/50002 [7:47:34<16:39:21,  4.30s/it]Generation 36050: test Loss = 0.00480
 72%|  | 36099/50002 [7:48:05<2:29:08,  1.55it/s]Generation 36100: train Loss = 0.00450
 72%|  | 36100/50002 [7:48:18<16:27:28,  4.26s/it]Generation 36100: test Loss = 0.00513
 72%|  | 36149/50002 [7:48:49<2:27:21,  1.57it/s]Generation 36150: train Loss = 0.00455
Generation 36150: test Loss = 0.00393
 72%|  | 36199/50002 [7:50:19<2:26:37,  1.57it/s]Generation 36200: train Loss = 0.00512
 72%|  | 36200/50002 [7:50:32<16:43:05,  4.36s/it]Generation 36200: test Loss = 0.00449
 72%|  | 36249/50002 [7:51:03<2:26:36,  1.56it/s]Generation 36250: train Loss = 0.00466
 72%|  | 36250/50002 [7:51:16<15:56:50,  4.17s/it]Generation 36250: test Loss = 0.00562
 73%|  | 36299/50002 [7:51:47<2:25:05,  1.57it/s]Generation 36300: train Loss = 0.00557
 73%|  | 36300/50002 [7:51:59<15:48:23,  4.15s/it]Generation 36300: test Loss = 0.00495
 73%|  | 36349/50002 [7:52:30<2:25:42,  1.56it/s]Generation 36350: train Loss = 0.00660
Generation 36350: test Loss = 0.00416
 73%|  | 36399/50002 [7:53:14<2:24:31,  1.57it/s]Generation 36400: train Loss = 0.00541
Generation 36400: test Loss = 0.00485
 73%|  | 36449/50002 [7:53:58<2:24:15,  1.57it/s]Generation 36450: train Loss = 0.00479
Generation 36450: test Loss = 0.00491
 73%|  | 36499/50002 [7:54:42<2:24:36,  1.56it/s]Generation 36500: train Loss = 0.00497
Generation 36500: test Loss = 0.00427
训练集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.46025103]
 [ 0.45188284]
 [ 0.38493723]
 [ 0.47280335]
 [ 0.60251045]
 [ 0.49790794]
 [ 0.46861926]
 [ 0.48117155]
 [ 0.53974897]]
测试集上一个批次数据的前10个数据
 [[ 0.49372384]
 [ 0.53556484]
 [ 0.38075313]
 [ 0.38912135]
 [ 0.44769874]
 [ 0.41422594]
 [ 0.43514645]
 [ 0.48117155]
 [ 0.53138077]
 [ 0.54811716]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]
 [ 0.49300396]]
 73%|  | 36549/50002 [7:55:27<2:23:04,  1.57it/s]Generation 36550: train Loss = 0.00581
Generation 36550: test Loss = 0.00503
 73%|  | 36599/50002 [7:56:11<2:22:47,  1.56it/s]Generation 36600: train Loss = 0.00556
 73%|  | 36600/50002 [7:56:24<15:39:45,  4.21s/it]Generation 36600: test Loss = 0.00623
 73%|  | 36649/50002 [7:56:55<2:21:56,  1.57it/s]Generation 36650: train Loss = 0.00443
 73%|  | 36650/50002 [7:57:08<15:32:53,  4.19s/it]Generation 36650: test Loss = 0.00515
 73%|  | 36699/50002 [7:57:39<2:21:01,  1.57it/s]Generation 36700: train Loss = 0.00466
 73%|  | 36700/50002 [7:57:52<15:55:06,  4.31s/it]Generation 36700: test Loss = 0.00488
 73%|  | 36749/50002 [7:58:23<2:20:21,  1.57it/s]Generation 36750: train Loss = 0.00475
Generation 36750: test Loss = 0.00450
 74%|  | 36799/50002 [7:59:07<2:20:54,  1.56it/s]Generation 36800: train Loss = 0.00484
Generation 36800: test Loss = 0.00371
 74%|  | 36849/50002 [7:59:51<2:22:03,  1.54it/s]Generation 36850: train Loss = 0.00421
Generation 36850: test Loss = 0.00376
 74%|  | 36899/50002 [8:00:34<2:18:53,  1.57it/s]Generation 36900: train Loss = 0.00551
 74%|  | 36900/50002 [8:00:47<15:21:18,  4.22s/it]Generation 36900: test Loss = 0.00462
 74%|  | 36949/50002 [8:01:18<2:18:54,  1.57it/s]Generation 36950: train Loss = 0.00530
Generation 36950: test Loss = 0.00545
 74%|  | 36999/50002 [8:02:02<2:18:05,  1.57it/s]Generation 37000: train Loss = 0.00503
Generation 37000: test Loss = 0.00469
训练集上一个批次数据的前10个数据
 [[ 0.55648535]
 [ 0.51464432]
 [ 0.48117155]
 [ 0.38912135]
 [ 0.61087865]
 [ 0.50209206]
 [ 0.53138077]
 [ 0.56485355]
 [ 0.46025103]
 [ 0.41004184]]
测试集上一个批次数据的前10个数据
 [[ 0.49790794]
 [ 0.57740587]
 [ 0.54393303]
 [ 0.62343097]
 [ 0.51464432]
 [ 0.48117155]
 [ 0.38075313]
 [ 0.52719665]
 [ 0.43096235]
 [ 0.49790794]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]]
 74%|  | 37000/50002 [8:02:17<17:36:40,  4.88s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]
 [ 0.4864755]]
 74%|  | 37049/50002 [8:02:48<2:16:52,  1.58it/s]Generation 37050: train Loss = 0.00603
 74%|  | 37050/50002 [8:03:00<15:27:39,  4.30s/it]Generation 37050: test Loss = 0.00541
 74%|  | 37099/50002 [8:03:32<2:17:39,  1.56it/s]Generation 37100: train Loss = 0.00530
 74%|  | 37100/50002 [8:03:44<15:13:53,  4.25s/it]Generation 37100: test Loss = 0.00410
 74%|  | 37149/50002 [8:04:16<2:17:13,  1.56it/s]Generation 37150: train Loss = 0.00527
 74%|  | 37150/50002 [8:04:29<15:18:27,  4.29s/it]Generation 37150: test Loss = 0.00462
 74%|  | 37199/50002 [8:05:00<2:16:45,  1.56it/s]Generation 37200: train Loss = 0.00417
Generation 37200: test Loss = 0.00540
 74%|  | 37249/50002 [8:05:44<2:16:09,  1.56it/s]Generation 37250: train Loss = 0.00622
Generation 37250: test Loss = 0.00493
 75%|  | 37299/50002 [8:06:28<2:15:16,  1.57it/s]Generation 37300: train Loss = 0.00506
 75%|  | 37300/50002 [8:06:40<14:58:34,  4.24s/it]Generation 37300: test Loss = 0.00404
 75%|  | 37349/50002 [8:07:11<2:13:45,  1.58it/s]Generation 37350: train Loss = 0.00499
Generation 37350: test Loss = 0.00474
 75%|  | 37399/50002 [8:07:55<2:14:42,  1.56it/s]Generation 37400: train Loss = 0.00536
Generation 37400: test Loss = 0.00408
 75%|  | 37449/50002 [8:08:39<2:13:02,  1.57it/s]Generation 37450: train Loss = 0.00587
Generation 37450: test Loss = 0.00504
 75%|  | 37499/50002 [8:09:23<2:12:49,  1.57it/s]Generation 37500: train Loss = 0.00510
Generation 37500: test Loss = 0.00363
训练集上一个批次数据的前10个数据
 [[ 0.55648535]
 [ 0.43096235]
 [ 0.42677826]
 [ 0.51464432]
 [ 0.30962342]
 [ 0.43096235]
 [ 0.38493723]
 [ 0.55230123]
 [ 0.51046026]
 [ 0.47698745]]
测试集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.52301258]
 [ 0.51882845]
 [ 0.54811716]
 [ 0.70711297]
 [ 0.50627613]
 [ 0.49790794]
 [ 0.54393303]
 [ 0.45606694]
 [ 0.48117155]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]]
 75%|  | 37500/50002 [8:09:38<16:43:22,  4.82s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]
 [ 0.49855974]]
 75%|  | 37549/50002 [8:10:09<2:11:26,  1.58it/s]Generation 37550: train Loss = 0.00565
Generation 37550: test Loss = 0.00338
 75%|  | 37599/50002 [8:10:53<2:13:47,  1.55it/s]Generation 37600: train Loss = 0.00528
 75%|  | 37600/50002 [8:11:06<14:53:04,  4.32s/it]Generation 37600: test Loss = 0.00408
 75%|  | 37649/50002 [8:11:37<2:12:38,  1.55it/s]Generation 37650: train Loss = 0.00469
 75%|  | 37650/50002 [8:11:50<14:50:00,  4.32s/it]Generation 37650: test Loss = 0.00485
 75%|  | 37699/50002 [8:12:21<2:11:54,  1.55it/s]Generation 37700: train Loss = 0.00430
 75%|  | 37700/50002 [8:12:55<35:59:51, 10.53s/it]Generation 37700: test Loss = 0.00473
 75%|  | 37749/50002 [8:13:25<2:10:54,  1.56it/s]Generation 37750: train Loss = 0.00461
 75%|  | 37750/50002 [8:13:39<14:50:58,  4.36s/it]Generation 37750: test Loss = 0.00467
 76%|  | 37799/50002 [8:14:10<2:09:36,  1.57it/s]Generation 37800: train Loss = 0.00534
Generation 37800: test Loss = 0.00490
 76%|  | 37849/50002 [8:14:54<2:08:46,  1.57it/s]Generation 37850: train Loss = 0.00426
 76%|  | 37850/50002 [8:15:07<14:57:11,  4.43s/it]Generation 37850: test Loss = 0.00311
 76%|  | 37899/50002 [8:15:38<2:09:22,  1.56it/s]Generation 37900: train Loss = 0.00436
Generation 37900: test Loss = 0.00406
 76%|  | 37949/50002 [8:16:23<2:09:29,  1.55it/s]Generation 37950: train Loss = 0.00455
 76%|  | 37950/50002 [8:16:36<14:47:16,  4.42s/it]Generation 37950: test Loss = 0.00384
 76%|  | 37999/50002 [8:17:07<2:08:56,  1.55it/s]Generation 38000: train Loss = 0.00671
Generation 38000: test Loss = 0.00472
训练集上一个批次数据的前10个数据
 [[ 0.54393303]
 [ 0.56903768]
 [ 0.53556484]
 [ 0.56485355]
 [ 0.41004184]
 [ 0.38075313]
 [ 0.44769874]
 [ 0.48117155]
 [ 0.54393303]
 [ 0.46861926]]
测试集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.54811716]
 [ 0.37238494]
 [ 0.58995813]
 [ 0.54811716]
 [ 0.51046026]
 [ 0.45188284]
 [ 0.51464432]
 [ 0.53556484]
 [ 0.43933055]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]]
 76%|  | 38000/50002 [8:17:22<17:01:26,  5.11s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]
 [ 0.47199014]]
 76%|  | 38049/50002 [8:17:54<2:09:14,  1.54it/s]Generation 38050: train Loss = 0.00512
Generation 38050: test Loss = 0.00507
 76%|  | 38099/50002 [8:18:38<2:07:56,  1.55it/s]Generation 38100: train Loss = 0.00430
 76%|  | 38100/50002 [8:18:51<14:36:17,  4.42s/it]Generation 38100: test Loss = 0.00366
 76%|  | 38149/50002 [8:19:22<2:05:51,  1.57it/s]Generation 38150: train Loss = 0.00498
 76%|  | 38150/50002 [8:19:36<14:24:06,  4.37s/it]Generation 38150: test Loss = 0.00406
 76%|  | 38199/50002 [8:20:07<2:05:18,  1.57it/s]Generation 38200: train Loss = 0.00413
Generation 38200: test Loss = 0.00476
 76%|  | 38249/50002 [8:20:51<2:05:15,  1.56it/s]Generation 38250: train Loss = 0.00590
Generation 38250: test Loss = 0.00466
 77%|  | 38299/50002 [8:21:35<2:05:06,  1.56it/s]Generation 38300: train Loss = 0.00459
Generation 38300: test Loss = 0.00377
 77%|  | 38349/50002 [8:22:20<2:04:25,  1.56it/s]Generation 38350: train Loss = 0.00671
Generation 38350: test Loss = 0.00371
 77%|  | 38399/50002 [8:23:04<2:04:05,  1.56it/s]Generation 38400: train Loss = 0.00405
Generation 38400: test Loss = 0.00433
 77%|  | 38449/50002 [8:23:48<2:02:20,  1.57it/s]Generation 38450: train Loss = 0.00635
 77%|  | 38450/50002 [8:24:02<14:07:25,  4.40s/it]Generation 38450: test Loss = 0.00584
 77%|  | 38499/50002 [8:24:33<2:02:08,  1.57it/s]Generation 38500: train Loss = 0.00489
Generation 38500: test Loss = 0.00433
训练集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.41841003]
 [ 0.48117155]
 [ 0.54393303]
 [ 0.43933055]
 [ 0.55648535]
 [ 0.42259413]
 [ 0.63598329]
 [ 0.40167364]
 [ 0.43096235]]
测试集上一个批次数据的前10个数据
 [[ 0.53138077]
 [ 0.42259413]
 [ 0.49372384]
 [ 0.47280335]
 [ 0.65690374]
 [ 0.40585774]
 [ 0.53138077]
 [ 0.38912135]
 [ 0.53556484]
 [ 0.54811716]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]]
 77%|  | 38500/50002 [8:24:48<16:08:53,  5.05s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]
 [ 0.49904156]]
 77%|  | 38549/50002 [8:25:19<2:03:25,  1.55it/s]Generation 38550: train Loss = 0.00576
 77%|  | 38550/50002 [8:25:32<14:09:38,  4.45s/it]Generation 38550: test Loss = 0.00311
 77%|  | 38599/50002 [8:26:04<2:01:36,  1.56it/s]Generation 38600: train Loss = 0.00513
Generation 38600: test Loss = 0.00437
 77%|  | 38649/50002 [8:26:48<2:00:45,  1.57it/s]Generation 38650: train Loss = 0.00484
Generation 38650: test Loss = 0.00428
 77%|  | 38699/50002 [8:27:33<2:00:00,  1.57it/s]Generation 38700: train Loss = 0.00524
Generation 38700: test Loss = 0.00393
 77%|  | 38749/50002 [8:28:17<2:00:06,  1.56it/s]Generation 38750: train Loss = 0.00393
 77%|  | 38750/50002 [8:28:31<14:03:39,  4.50s/it]Generation 38750: test Loss = 0.00447
 78%|  | 38799/50002 [8:29:02<1:59:11,  1.57it/s]Generation 38800: train Loss = 0.00528
 78%|  | 38800/50002 [8:29:15<13:56:08,  4.48s/it]Generation 38800: test Loss = 0.00345
 78%|  | 38849/50002 [8:29:46<1:58:38,  1.57it/s]Generation 38850: train Loss = 0.00452
Generation 38850: test Loss = 0.00383
 78%|  | 38899/50002 [8:30:31<1:57:09,  1.58it/s]Generation 38900: train Loss = 0.00531
Generation 38900: test Loss = 0.00418
 78%|  | 38949/50002 [8:31:15<1:57:29,  1.57it/s]Generation 38950: train Loss = 0.00480
 78%|  | 38950/50002 [8:31:29<13:54:22,  4.53s/it]Generation 38950: test Loss = 0.00308
 78%|  | 38999/50002 [8:32:00<1:57:26,  1.56it/s]Generation 39000: train Loss = 0.00620
Generation 39000: test Loss = 0.00375
训练集上一个批次数据的前10个数据
 [[ 0.38493723]
 [ 0.48535565]
 [ 0.42677826]
 [ 0.53138077]
 [ 0.50627613]
 [ 0.51464432]
 [ 0.46025103]
 [ 0.47698745]
 [ 0.47698745]
 [ 0.51464432]]
测试集上一个批次数据的前10个数据
 [[ 0.48535565]
 [ 0.46443516]
 [ 0.51882845]
 [ 0.41422594]
 [ 0.42677826]
 [ 0.53556484]
 [ 0.54393303]
 [ 0.51464432]
 [ 0.54393303]
 [ 0.43514645]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]]
测试集上一个批次数据中通过inference后的前10个输出结果
 78%|  | 39000/50002 [8:32:15<15:55:34,  5.21s/it] [[ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]
 [ 0.49016935]]
 78%|  | 39049/50002 [8:32:47<1:56:20,  1.57it/s]Generation 39050: train Loss = 0.00535
Generation 39050: test Loss = 0.00466
 78%|  | 39099/50002 [8:33:31<1:56:45,  1.56it/s]Generation 39100: train Loss = 0.00442
 78%|  | 39100/50002 [8:33:45<13:38:32,  4.50s/it]Generation 39100: test Loss = 0.00528
 78%|  | 39149/50002 [8:34:16<1:56:59,  1.55it/s]Generation 39150: train Loss = 0.00445
Generation 39150: test Loss = 0.00498
 78%|  | 39199/50002 [8:35:00<1:55:23,  1.56it/s]Generation 39200: train Loss = 0.00347
 78%|  | 39200/50002 [8:35:14<13:39:15,  4.55s/it]Generation 39200: test Loss = 0.00465
 78%|  | 39249/50002 [8:35:45<1:54:21,  1.57it/s]Generation 39250: train Loss = 0.00566
 78%|  | 39250/50002 [8:35:58<13:26:42,  4.50s/it]Generation 39250: test Loss = 0.00421
 79%|  | 39299/50002 [8:36:29<1:54:04,  1.56it/s]Generation 39300: train Loss = 0.00804
Generation 39300: test Loss = 0.00446
 79%|  | 39349/50002 [8:37:14<1:52:44,  1.57it/s]Generation 39350: train Loss = 0.00422
Generation 39350: test Loss = 0.00454
 79%|  | 39399/50002 [8:37:59<1:52:24,  1.57it/s]Generation 39400: train Loss = 0.00532
 79%|  | 39400/50002 [8:38:12<13:11:04,  4.48s/it]Generation 39400: test Loss = 0.00299
 79%|  | 39449/50002 [8:38:43<1:52:06,  1.57it/s]Generation 39450: train Loss = 0.00504
 79%|  | 39450/50002 [8:38:57<13:35:32,  4.64s/it]Generation 39450: test Loss = 0.00575
 79%|  | 39499/50002 [8:39:28<1:50:59,  1.58it/s]Generation 39500: train Loss = 0.00392
Generation 39500: test Loss = 0.00418
训练集上一个批次数据的前10个数据
 [[ 0.42259413]
 [ 0.39330545]
 [ 0.46443516]
 [ 0.54811716]
 [ 0.51046026]
 [ 0.52301258]
 [ 0.37656903]
 [ 0.39330545]
 [ 0.40585774]
 [ 0.37238494]]
测试集上一个批次数据的前10个数据
 [[ 0.57740587]
 [ 0.51046026]
 [ 0.54393303]
 [ 0.53556484]
 [ 0.44351465]
 [ 0.71548116]
 [ 0.42677826]
 [ 0.54393303]
 [ 0.54811716]
 [ 0.48953974]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48600197]
 79%|  | 39500/50002 [8:39:44<15:21:13,  5.26s/it] [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]
 [ 0.48600197]]
 79%|  | 39549/50002 [8:40:15<1:52:24,  1.55it/s]Generation 39550: train Loss = 0.00675
Generation 39550: test Loss = 0.00411
 79%|  | 39599/50002 [8:41:00<1:51:34,  1.55it/s]Generation 39600: train Loss = 0.00635
 79%|  | 39600/50002 [8:41:14<13:01:56,  4.51s/it]Generation 39600: test Loss = 0.00424
 79%|  | 39649/50002 [8:41:45<1:49:51,  1.57it/s]Generation 39650: train Loss = 0.00590
 79%|  | 39650/50002 [8:41:59<13:11:05,  4.59s/it]Generation 39650: test Loss = 0.00296
 79%|  | 39699/50002 [8:42:30<1:50:15,  1.56it/s]Generation 39700: train Loss = 0.00478
Generation 39700: test Loss = 0.00453
 79%|  | 39749/50002 [8:43:14<1:49:44,  1.56it/s]Generation 39750: train Loss = 0.00444
 79%|  | 39750/50002 [8:43:28<12:55:17,  4.54s/it]Generation 39750: test Loss = 0.00405
 80%|  | 39799/50002 [8:43:59<1:47:53,  1.58it/s]Generation 39800: train Loss = 0.00387
 80%|  | 39800/50002 [8:44:13<12:55:23,  4.56s/it]Generation 39800: test Loss = 0.00478
 80%|  | 39849/50002 [8:44:44<1:48:55,  1.55it/s]Generation 39850: train Loss = 0.00608
 80%|  | 39850/50002 [8:44:58<13:10:55,  4.67s/it]Generation 39850: test Loss = 0.00370
 80%|  | 39899/50002 [8:45:29<1:48:55,  1.55it/s]Generation 39900: train Loss = 0.00544
 80%|  | 39900/50002 [8:45:43<13:16:52,  4.73s/it]Generation 39900: test Loss = 0.00408
 80%|  | 39949/50002 [8:46:14<1:47:48,  1.55it/s]Generation 39950: train Loss = 0.00576
Generation 39950: test Loss = 0.00560
 80%|  | 39999/50002 [8:46:59<1:45:55,  1.57it/s]Generation 40000: train Loss = 0.00340
Generation 40000: test Loss = 0.00483
训练集上一个批次数据的前10个数据
 [[ 0.57322174]
 [ 0.42677826]
 [ 0.50627613]
 [ 0.63179916]
 [ 0.55230123]
 [ 0.59832639]
 [ 0.53556484]
 [ 0.46861926]
 [ 0.55230123]
 [ 0.49790794]]
测试集上一个批次数据的前10个数据
 [[ 0.59832639]
 [ 0.53974897]
 [ 0.52301258]
 [ 0.50209206]
 [ 0.53138077]
 [ 0.46861926]
 [ 0.49372384]
 [ 0.48953974]
 [ 0.54393303]
 [ 0.56903768]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]]
测试集上一个批次数据中通过inference后的前10个输出结果
 80%|  | 40000/50002 [8:47:15<14:46:06,  5.32s/it] [[ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]
 [ 0.49498302]]
 80%|  | 40049/50002 [8:50:27<1:46:50,  1.55it/s]Generation 40050: train Loss = 0.00614
 80%|  | 40050/50002 [8:51:27<51:17:01, 18.55s/it]Generation 40050: test Loss = 0.00474
 80%|  | 40099/50002 [8:51:58<1:44:32,  1.58it/s]Generation 40100: train Loss = 0.00383
 80%|  | 40100/50002 [8:52:12<13:04:10,  4.75s/it]Generation 40100: test Loss = 0.00444
 80%|  | 40149/50002 [8:52:43<1:45:13,  1.56it/s]Generation 40150: train Loss = 0.00579
 80%|  | 40150/50002 [8:52:57<12:39:30,  4.63s/it]Generation 40150: test Loss = 0.00520
 80%|  | 40199/50002 [8:53:28<1:43:36,  1.58it/s]Generation 40200: train Loss = 0.00752
 80%|  | 40200/50002 [8:53:42<12:33:21,  4.61s/it]Generation 40200: test Loss = 0.00461
 80%|  | 40249/50002 [8:54:13<1:42:34,  1.58it/s]Generation 40250: train Loss = 0.00468
 80%|  | 40250/50002 [8:54:27<12:46:42,  4.72s/it]Generation 40250: test Loss = 0.00573
 81%|  | 40299/50002 [8:54:58<1:43:06,  1.57it/s]Generation 40300: train Loss = 0.00410
Generation 40300: test Loss = 0.00543
 81%|  | 40349/50002 [8:55:43<1:42:34,  1.57it/s]Generation 40350: train Loss = 0.00634
 81%|  | 40350/50002 [8:55:57<12:24:29,  4.63s/it]Generation 40350: test Loss = 0.00496
 81%|  | 40399/50002 [8:56:28<1:42:11,  1.57it/s]Generation 40400: train Loss = 0.00551
Generation 40400: test Loss = 0.00556
 81%|  | 40449/50002 [8:57:13<1:41:12,  1.57it/s]Generation 40450: train Loss = 0.00499
 81%|  | 40450/50002 [8:57:27<12:13:34,  4.61s/it]Generation 40450: test Loss = 0.00474
 81%|  | 40499/50002 [8:57:58<1:41:07,  1.57it/s]Generation 40500: train Loss = 0.00473
Generation 40500: test Loss = 0.00496
训练集上一个批次数据的前10个数据
 [[ 0.48953974]
 [ 0.43096235]
 [ 0.41422594]
 [ 0.50209206]
 [ 0.49790794]
 [ 0.49372384]
 [ 0.34309623]
 [ 0.51464432]
 [ 0.40585774]
 [ 0.51882845]]
测试集上一个批次数据的前10个数据
 [[ 0.52719665]
 [ 0.57322174]
 [ 0.32635984]
 [ 0.48535565]
 [ 0.65271968]
 [ 0.53138077]
 [ 0.53556484]
 [ 0.53556484]
 [ 0.54811716]
 [ 0.57740587]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]]
 81%|  | 40500/50002 [8:58:15<14:31:51,  5.51s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]
 [ 0.50538069]]
 81%|  | 40549/50002 [8:58:46<1:40:24,  1.57it/s]Generation 40550: train Loss = 0.00455
Generation 40550: test Loss = 0.00338
 81%|  | 40599/50002 [8:59:31<1:39:06,  1.58it/s]Generation 40600: train Loss = 0.00424
 81%|  | 40600/50002 [9:01:40<102:37:48, 39.30s/it]Generation 40600: test Loss = 0.00415
 81%| | 40649/50002 [9:02:11<1:40:30,  1.55it/s]Generation 40650: train Loss = 0.00556
Generation 40650: test Loss = 0.00337
 81%| | 40699/50002 [9:02:57<1:37:49,  1.58it/s]Generation 40700: train Loss = 0.00449
 81%| | 40700/50002 [9:03:10<11:53:08,  4.60s/it]Generation 40700: test Loss = 0.00487
 81%| | 40749/50002 [9:03:42<1:38:42,  1.56it/s]Generation 40750: train Loss = 0.00625
Generation 40750: test Loss = 0.00424
 82%| | 40799/50002 [9:04:27<1:37:43,  1.57it/s]Generation 40800: train Loss = 0.00467
Generation 40800: test Loss = 0.00415
 82%| | 40849/50002 [9:05:12<1:37:27,  1.57it/s]Generation 40850: train Loss = 0.00510
 82%| | 40850/50002 [9:05:25<11:35:19,  4.56s/it]Generation 40850: test Loss = 0.00446
 82%| | 40899/50002 [9:05:57<1:37:55,  1.55it/s]Generation 40900: train Loss = 0.00484
Generation 40900: test Loss = 0.00550
 82%| | 40949/50002 [9:06:42<1:36:27,  1.56it/s]Generation 40950: train Loss = 0.00602
 82%| | 40950/50002 [9:07:03<17:17:10,  6.87s/it]Generation 40950: test Loss = 0.00543
 82%| | 40999/50002 [9:07:34<1:35:34,  1.57it/s]Generation 41000: train Loss = 0.00553
Generation 41000: test Loss = 0.00378
训练集上一个批次数据的前10个数据
 [[ 0.58158994]
 [ 0.52301258]
 [ 0.45188284]
 [ 0.51046026]
 [ 0.49372384]
 [ 0.38493723]
 [ 0.55230123]
 [ 0.40167364]
 [ 0.47280335]
 [ 0.56485355]]
测试集上一个批次数据的前10个数据
 [[ 0.40167364]
 [ 0.53556484]
 [ 0.48117155]
 [ 0.55230123]
 [ 0.51464432]
 [ 0.48535565]
 [ 0.52301258]
 [ 0.30543932]
 [ 0.55230123]
 [ 0.45188284]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]]
 82%| | 41000/50002 [9:07:50<12:50:14,  5.13s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]
 [ 0.50060415]]
 82%| | 41049/50002 [9:08:21<1:35:52,  1.56it/s]Generation 41050: train Loss = 0.00559
Generation 41050: test Loss = 0.00417
 82%| | 41099/50002 [9:09:06<1:34:07,  1.58it/s]Generation 41100: train Loss = 0.00493
 82%| | 41100/50002 [9:09:20<11:17:57,  4.57s/it]Generation 41100: test Loss = 0.00362
 82%| | 41149/50002 [9:09:51<1:34:14,  1.57it/s]Generation 41150: train Loss = 0.00582
Generation 41150: test Loss = 0.00544
 82%| | 41199/50002 [9:10:36<1:33:04,  1.58it/s]Generation 41200: train Loss = 0.00520
Generation 41200: test Loss = 0.00428
 82%| | 41249/50002 [9:11:22<1:33:06,  1.57it/s]Generation 41250: train Loss = 0.00489
 82%| | 41250/50002 [9:11:35<11:06:14,  4.57s/it]Generation 41250: test Loss = 0.00720
 83%| | 41299/50002 [9:12:07<1:32:50,  1.56it/s]Generation 41300: train Loss = 0.00432
Generation 41300: test Loss = 0.00418
 83%| | 41349/50002 [9:12:52<1:32:05,  1.57it/s]Generation 41350: train Loss = 0.00534
 83%| | 41350/50002 [9:13:05<11:01:22,  4.59s/it]Generation 41350: test Loss = 0.00505
 83%| | 41399/50002 [9:13:37<1:31:40,  1.56it/s]Generation 41400: train Loss = 0.00464
 83%| | 41400/50002 [9:13:50<10:56:57,  4.58s/it]Generation 41400: test Loss = 0.00411
 83%| | 41449/50002 [9:14:22<1:30:49,  1.57it/s]Generation 41450: train Loss = 0.00645
 83%| | 41450/50002 [9:14:36<10:56:15,  4.60s/it]Generation 41450: test Loss = 0.00364
 83%| | 41499/50002 [9:15:07<1:29:57,  1.58it/s]Generation 41500: train Loss = 0.00488
Generation 41500: test Loss = 0.00505
训练集上一个批次数据的前10个数据
 [[ 0.41841003]
 [ 0.43933055]
 [ 0.35146442]
 [ 0.53974897]
 [ 0.60251045]
 [ 0.50627613]
 [ 0.44351465]
 [ 0.47698745]
 [ 0.50209206]
 [ 0.55648535]]
测试集上一个批次数据的前10个数据
 [[ 0.46861926]
 [ 0.53138077]
 [ 0.46861926]
 [ 0.47280335]
 [ 0.45188284]
 [ 0.52719665]
 [ 0.43514645]
 [ 0.52301258]
 [ 0.40167364]
 [ 0.49372384]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]]
测试集上一个批次数据中通过inference后的前10个输出结果
 83%| | 41500/50002 [9:15:23<12:17:12,  5.20s/it] [[ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]
 [ 0.49486929]]
 83%| | 41549/50002 [9:15:54<1:30:11,  1.56it/s]Generation 41550: train Loss = 0.00479
Generation 41550: test Loss = 0.00504
 83%| | 41599/50002 [9:16:39<1:29:19,  1.57it/s]Generation 41600: train Loss = 0.00469
 83%| | 41600/50002 [9:16:53<10:48:05,  4.63s/it]Generation 41600: test Loss = 0.00665
 83%| | 41649/50002 [9:17:24<1:28:57,  1.57it/s]Generation 41650: train Loss = 0.00524
 83%| | 41650/50002 [9:17:38<10:39:47,  4.60s/it]Generation 41650: test Loss = 0.00471
 83%| | 41699/50002 [9:18:10<1:28:29,  1.56it/s]Generation 41700: train Loss = 0.00500
Generation 41700: test Loss = 0.00407
 83%| | 41749/50002 [9:18:55<1:27:07,  1.58it/s]Generation 41750: train Loss = 0.00565
 83%| | 41750/50002 [9:19:09<10:34:09,  4.61s/it]Generation 41750: test Loss = 0.00444
 84%| | 41799/50002 [9:19:40<1:27:06,  1.57it/s]Generation 41800: train Loss = 0.00537
Generation 41800: test Loss = 0.00419
 84%| | 41849/50002 [9:20:25<1:26:56,  1.56it/s]Generation 41850: train Loss = 0.00507
 84%| | 41850/50002 [9:20:39<10:27:43,  4.62s/it]Generation 41850: test Loss = 0.00439
 84%| | 41899/50002 [9:21:10<1:26:18,  1.56it/s]Generation 41900: train Loss = 0.00474
Generation 41900: test Loss = 0.00347
 84%| | 41949/50002 [9:21:55<1:25:57,  1.56it/s]Generation 41950: train Loss = 0.00422
 84%| | 41950/50002 [9:22:09<10:20:43,  4.63s/it]Generation 41950: test Loss = 0.00580
 84%| | 41999/50002 [9:22:40<1:25:15,  1.56it/s]Generation 42000: train Loss = 0.00494
Generation 42000: test Loss = 0.00625
训练集上一个批次数据的前10个数据
 [[ 0.52301258]
 [ 0.52719665]
 [ 0.62761503]
 [ 0.54811716]
 [ 0.46025103]
 [ 0.49372384]
 [ 0.53138077]
 [ 0.42259413]
 [ 0.47280335]
 [ 0.37656903]]
测试集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.54811716]
 [ 0.49790794]
 [ 0.46025103]
 [ 0.55230123]
 [ 0.53138077]
 [ 0.51464432]
 [ 0.58995813]
 [ 0.47280335]
 [ 0.31380752]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]
 [ 0.47103849]]
 84%| | 42049/50002 [9:23:28<1:24:25,  1.57it/s]Generation 42050: train Loss = 0.00521
Generation 42050: test Loss = 0.00438
 84%| | 42099/50002 [9:24:13<1:24:21,  1.56it/s]Generation 42100: train Loss = 0.00455
Generation 42100: test Loss = 0.00422
 84%| | 42149/50002 [9:24:58<1:23:17,  1.57it/s]Generation 42150: train Loss = 0.00463
Generation 42150: test Loss = 0.00377
 84%| | 42199/50002 [9:25:44<1:22:56,  1.57it/s]Generation 42200: train Loss = 0.00488
Generation 42200: test Loss = 0.00385
 84%| | 42249/50002 [9:26:29<1:23:21,  1.55it/s]Generation 42250: train Loss = 0.00533
 84%| | 42250/50002 [9:26:43<9:59:13,  4.64s/it]Generation 42250: test Loss = 0.00438
 85%| | 42299/50002 [9:27:14<1:21:48,  1.57it/s]Generation 42300: train Loss = 0.00462
Generation 42300: test Loss = 0.00411
 85%| | 42349/50002 [9:27:59<1:21:21,  1.57it/s]Generation 42350: train Loss = 0.00374
Generation 42350: test Loss = 0.00384
 85%| | 42399/50002 [9:28:45<1:21:07,  1.56it/s]Generation 42400: train Loss = 0.00472
 85%| | 42400/50002 [9:28:59<9:47:11,  4.63s/it]Generation 42400: test Loss = 0.00424
 85%| | 42449/50002 [9:29:30<1:20:27,  1.56it/s]Generation 42450: train Loss = 0.00531
 85%| | 42450/50002 [9:29:44<9:45:35,  4.65s/it]Generation 42450: test Loss = 0.00477
 85%| | 42499/50002 [9:30:15<1:20:02,  1.56it/s]Generation 42500: train Loss = 0.00634
Generation 42500: test Loss = 0.00484
训练集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.53556484]
 [ 0.53556484]
 [ 0.47698745]
 [ 0.48953974]
 [ 0.48953974]
 [ 0.60669458]
 [ 0.39748955]
 [ 0.53138077]
 [ 0.36401674]]
测试集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.49372384]
 [ 0.57322174]
 [ 0.48117155]
 [ 0.44769874]
 [ 0.38912135]
 [ 0.45606694]
 [ 0.43933055]
 [ 0.55648535]
 [ 0.50209206]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]]
 85%| | 42500/50002 [9:30:31<10:56:14,  5.25s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]
 [ 0.47881618]]
 85%| | 42549/50002 [9:31:02<1:19:30,  1.56it/s]Generation 42550: train Loss = 0.00590
Generation 42550: test Loss = 0.00487
 85%| | 42599/50002 [9:31:48<1:19:08,  1.56it/s]Generation 42600: train Loss = 0.00588
 85%| | 42600/50002 [9:32:02<9:37:37,  4.68s/it]Generation 42600: test Loss = 0.00524
 85%| | 42649/50002 [9:32:33<1:18:08,  1.57it/s]Generation 42650: train Loss = 0.00464
 85%| | 42650/50002 [9:32:48<9:38:34,  4.72s/it]Generation 42650: test Loss = 0.00428
 85%| | 42699/50002 [9:33:19<1:17:40,  1.57it/s]Generation 42700: train Loss = 0.00586
 85%| | 42700/50002 [9:33:33<9:30:41,  4.69s/it]Generation 42700: test Loss = 0.00511
 85%| | 42749/50002 [9:34:04<1:16:42,  1.58it/s]Generation 42750: train Loss = 0.00557
Generation 42750: test Loss = 0.00544
 86%| | 42799/50002 [9:34:50<1:16:49,  1.56it/s]Generation 42800: train Loss = 0.00424
 86%| | 42800/50002 [9:35:04<9:24:08,  4.70s/it]Generation 42800: test Loss = 0.00390
 86%| | 42849/50002 [9:35:35<1:16:02,  1.57it/s]Generation 42850: train Loss = 0.00507
 86%| | 42850/50002 [9:35:49<9:18:22,  4.68s/it]Generation 42850: test Loss = 0.00403
 86%| | 42899/50002 [9:36:20<1:15:15,  1.57it/s]Generation 42900: train Loss = 0.00503
 86%| | 42900/50002 [9:36:35<9:28:10,  4.80s/it]Generation 42900: test Loss = 0.00430
 86%| | 42949/50002 [9:37:06<1:14:39,  1.57it/s]Generation 42950: train Loss = 0.00549
 86%| | 42950/50002 [9:37:20<9:14:12,  4.72s/it]Generation 42950: test Loss = 0.00342
 86%| | 42999/50002 [9:37:51<1:14:01,  1.58it/s]Generation 43000: train Loss = 0.00566
Generation 43000: test Loss = 0.00326
训练集上一个批次数据的前10个数据
 [[ 0.41004184]
 [ 0.49372384]
 [ 0.57740587]
 [ 0.51046026]
 [ 0.43514645]
 [ 0.55648535]
 [ 0.50627613]
 [ 0.53974897]
 [ 0.52719665]
 [ 0.53556484]]
测试集上一个批次数据的前10个数据
 [[ 0.58158994]
 [ 0.50209206]
 [ 0.40167364]
 [ 0.53138077]
 [ 0.50209206]
 [ 0.52719665]
 [ 0.41422594]
 [ 0.51046026]
 [ 0.55230123]
 [ 0.51882845]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]
 [ 0.49119669]]
 86%| | 43049/50002 [9:38:39<1:13:57,  1.57it/s]Generation 43050: train Loss = 0.00448
Generation 43050: test Loss = 0.00499
 86%| | 43099/50002 [9:39:24<1:13:27,  1.57it/s]Generation 43100: train Loss = 0.00529
Generation 43100: test Loss = 0.00434
 86%| | 43149/50002 [9:40:10<1:13:27,  1.55it/s]Generation 43150: train Loss = 0.00526
Generation 43150: test Loss = 0.00429
 86%| | 43199/50002 [9:40:55<1:13:07,  1.55it/s]Generation 43200: train Loss = 0.00650
 86%| | 43200/50002 [9:41:10<8:53:44,  4.71s/it]Generation 43200: test Loss = 0.00511
 86%| | 43249/50002 [9:41:41<1:12:45,  1.55it/s]Generation 43250: train Loss = 0.00629
Generation 43250: test Loss = 0.00499
 87%| | 43299/50002 [9:42:26<1:11:34,  1.56it/s]Generation 43300: train Loss = 0.00481
Generation 43300: test Loss = 0.00436
 87%| | 43349/50002 [9:43:12<1:10:48,  1.57it/s]Generation 43350: train Loss = 0.00492
Generation 43350: test Loss = 0.00456
 87%| | 43399/50002 [9:43:57<1:09:53,  1.57it/s]Generation 43400: train Loss = 0.00489
Generation 43400: test Loss = 0.00592
 87%| | 43449/50002 [9:44:43<1:10:08,  1.56it/s]Generation 43450: train Loss = 0.00502
Generation 43450: test Loss = 0.00336
 87%| | 43499/50002 [9:45:29<1:09:24,  1.56it/s]Generation 43500: train Loss = 0.00440
Generation 43500: test Loss = 0.00391
训练集上一个批次数据的前10个数据
 [[ 0.50627613]
 [ 0.51882845]
 [ 0.50627613]
 [ 0.51882845]
 [ 0.54393303]
 [ 0.51464432]
 [ 0.58995813]
 [ 0.64435148]
 [ 0.38493723]
 [ 0.55230123]]
测试集上一个批次数据的前10个数据
 [[ 0.51046026]
 [ 0.53138077]
 [ 0.43096235]
 [ 0.44351465]
 [ 0.40167364]
 [ 0.42677826]
 [ 0.41422594]
 [ 0.57740587]
 [ 0.38493723]
 [ 0.38493723]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]
 [ 0.48333979]]
 87%| | 43549/50002 [9:46:17<1:09:07,  1.56it/s]Generation 43550: train Loss = 0.00423
Generation 43550: test Loss = 0.00425
 87%| | 43599/50002 [9:47:03<1:07:32,  1.58it/s]Generation 43600: train Loss = 0.00563
Generation 43600: test Loss = 0.00360
 87%| | 43649/50002 [9:47:49<1:08:06,  1.55it/s]Generation 43650: train Loss = 0.00607
Generation 43650: test Loss = 0.00483
 87%| | 43699/50002 [9:48:35<1:06:49,  1.57it/s]Generation 43700: train Loss = 0.00532
Generation 43700: test Loss = 0.00423
 87%| | 43749/50002 [9:49:20<1:06:31,  1.57it/s]Generation 43750: train Loss = 0.00592
 87%| | 43750/50002 [9:49:35<8:32:05,  4.91s/it]Generation 43750: test Loss = 0.00494
 88%| | 43799/50002 [9:50:06<1:06:09,  1.56it/s]Generation 43800: train Loss = 0.00595
 88%| | 43800/50002 [9:50:21<8:17:26,  4.81s/it]Generation 43800: test Loss = 0.00496
 88%| | 43849/50002 [9:50:52<1:05:05,  1.58it/s]Generation 43850: train Loss = 0.00602
Generation 43850: test Loss = 0.00488
 88%| | 43899/50002 [9:51:38<1:05:20,  1.56it/s]Generation 43900: train Loss = 0.00485
 88%| | 43900/50002 [9:51:52<8:13:25,  4.85s/it]Generation 43900: test Loss = 0.00489
 88%| | 43949/50002 [9:52:23<1:04:44,  1.56it/s]Generation 43950: train Loss = 0.00569
 88%| | 43950/50002 [9:52:38<8:04:35,  4.80s/it]Generation 43950: test Loss = 0.00397
 88%| | 43999/50002 [9:53:09<1:03:43,  1.57it/s]Generation 44000: train Loss = 0.00507
Generation 44000: test Loss = 0.00470
训练集上一个批次数据的前10个数据
 [[ 0.39330545]
 [ 0.53974897]
 [ 0.55648535]
 [ 0.51882845]
 [ 0.40585774]
 [ 0.41841003]
 [ 0.45188284]
 [ 0.61506277]
 [ 0.48953974]
 [ 0.45606694]]
测试集上一个批次数据的前10个数据
 [[ 0.53556484]
 [ 0.43096235]
 [ 0.57322174]
 [ 0.38075313]
 [ 0.46861926]
 [ 0.53138077]
 [ 0.38075313]
 [ 0.63598329]
 [ 0.49372384]
 [ 0.46861926]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]]
测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]
 [ 0.48240426]]
 88%| | 44049/50002 [9:53:57<1:03:42,  1.56it/s]Generation 44050: train Loss = 0.00541
Generation 44050: test Loss = 0.00395
 88%| | 44099/50002 [9:54:43<1:02:28,  1.57it/s]Generation 44100: train Loss = 0.00528
 88%| | 44100/50002 [9:54:58<7:59:02,  4.87s/it]Generation 44100: test Loss = 0.00592
 88%| | 44149/50002 [9:55:29<1:02:45,  1.55it/s]Generation 44150: train Loss = 0.00509
 88%| | 44150/50002 [9:55:43<7:55:06,  4.87s/it]Generation 44150: test Loss = 0.00453
 88%| | 44199/50002 [9:56:15<1:02:19,  1.55it/s]Generation 44200: train Loss = 0.00453
 88%| | 44200/50002 [9:56:29<7:53:22,  4.90s/it]Generation 44200: test Loss = 0.00478
 88%| | 44249/50002 [9:57:00<1:01:18,  1.56it/s]Generation 44250: train Loss = 0.00411
Generation 44250: test Loss = 0.00412
 89%| | 44299/50002 [9:57:46<1:00:42,  1.57it/s]Generation 44300: train Loss = 0.00590
Generation 44300: test Loss = 0.00533
 89%| | 44349/50002 [9:58:32<1:00:17,  1.56it/s]Generation 44350: train Loss = 0.00512
 89%| | 44350/50002 [9:58:48<7:50:06,  4.99s/it]Generation 44350: test Loss = 0.00457
 89%| | 44399/50002 [9:59:18<59:10,  1.58it/s]  Generation 44400: train Loss = 0.00424
Generation 44400: test Loss = 0.00405
 89%| | 44449/50002 [10:00:05<59:51,  1.55it/s]Generation 44450: train Loss = 0.00469
Generation 44450: test Loss = 0.00402
 89%| | 44499/50002 [10:00:52<59:03,  1.55it/s]Generation 44500: train Loss = 0.00491
Generation 44500: test Loss = 0.00449
训练集上一个批次数据的前10个数据
 [[ 0.51464432]
 [ 0.51464432]
 [ 0.45606694]
 [ 0.51464432]
 [ 0.60669458]
 [ 0.46861926]
 [ 0.49372384]
 [ 0.43096235]
 [ 0.52301258]
 [ 0.51046026]]
测试集上一个批次数据的前10个数据
 [[ 0.52301258]
 [ 0.59414226]
 [ 0.54811716]
 [ 0.55648535]
 [ 0.45188284]
 [ 0.49790794]
 [ 0.50627613]
 [ 0.41841003]
 [ 0.30543932]
 [ 0.23849373]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]]
 89%| | 44500/50002 [10:01:09<8:34:38,  5.61s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]
 [ 0.50874096]]
 89%| | 44549/50002 [10:01:40<58:16,  1.56it/s]Generation 44550: train Loss = 0.00454
 89%| | 44550/50002 [10:01:55<7:30:34,  4.96s/it]Generation 44550: test Loss = 0.00457
 89%| | 44599/50002 [10:02:26<57:27,  1.57it/s]Generation 44600: train Loss = 0.00370
 89%| | 44600/50002 [10:02:41<7:25:49,  4.95s/it]Generation 44600: test Loss = 0.00356
 89%| | 44649/50002 [10:03:12<57:07,  1.56it/s]Generation 44650: train Loss = 0.00444
Generation 44650: test Loss = 0.00534
 89%| | 44699/50002 [10:03:58<55:54,  1.58it/s]Generation 44700: train Loss = 0.00614
Generation 44700: test Loss = 0.00366
 89%| | 44749/50002 [10:04:44<56:08,  1.56it/s]Generation 44750: train Loss = 0.00529
Generation 44750: test Loss = 0.00490
 90%| | 44799/50002 [10:05:30<55:21,  1.57it/s]Generation 44800: train Loss = 0.00514
 90%| | 44800/50002 [10:05:45<7:06:53,  4.92s/it]Generation 44800: test Loss = 0.00435
 90%| | 44849/50002 [10:06:16<55:12,  1.56it/s]Generation 44850: train Loss = 0.00500
Generation 44850: test Loss = 0.00381
 90%| | 44899/50002 [10:07:02<54:02,  1.57it/s]Generation 44900: train Loss = 0.00482
 90%| | 44900/50002 [10:07:17<7:01:42,  4.96s/it]Generation 44900: test Loss = 0.00429
 90%| | 44949/50002 [10:07:48<54:11,  1.55it/s]Generation 44950: train Loss = 0.00585
Generation 44950: test Loss = 0.00565
 90%| | 44999/50002 [10:08:34<53:36,  1.56it/s]Generation 45000: train Loss = 0.00516
Generation 45000: test Loss = 0.00570
训练集上一个批次数据的前10个数据
 [[ 0.40585774]
 [ 0.54393303]
 [ 0.48953974]
 [ 0.46443516]
 [ 0.54811716]
 [ 0.35564855]
 [ 0.44769874]
 [ 0.41004184]
 [ 0.50627613]
 [ 0.35146442]]
测试集上一个批次数据的前10个数据
 [[ 0.47280335]
 [ 0.58577406]
 [ 0.44351465]
 [ 0.48953974]
 [ 0.47698745]
 [ 0.61506277]
 [ 0.55230123]
 [ 0.49372384]
 [ 0.51046026]
 [ 0.34728032]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]]
 90%| | 45000/50002 [10:08:52<7:45:51,  5.59s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]
 [ 0.47566074]]
 90%| | 45049/50002 [10:09:23<52:46,  1.56it/s]Generation 45050: train Loss = 0.00541
Generation 45050: test Loss = 0.00488
 90%| | 45099/50002 [10:10:09<52:11,  1.57it/s]Generation 45100: train Loss = 0.00573
 90%| | 45100/50002 [10:10:24<6:42:18,  4.92s/it]Generation 45100: test Loss = 0.00487
 90%| | 45149/50002 [10:10:55<51:24,  1.57it/s]Generation 45150: train Loss = 0.00476
Generation 45150: test Loss = 0.00427
 90%| | 45199/50002 [10:11:41<51:43,  1.55it/s]Generation 45200: train Loss = 0.00483
Generation 45200: test Loss = 0.00322
 90%| | 45249/50002 [10:12:27<50:50,  1.56it/s]Generation 45250: train Loss = 0.00405
 90%| | 45250/50002 [10:12:42<6:30:54,  4.94s/it]Generation 45250: test Loss = 0.00421
 91%| | 45299/50002 [10:13:13<49:45,  1.58it/s]Generation 45300: train Loss = 0.00499
Generation 45300: test Loss = 0.00453
 91%| | 45349/50002 [10:13:59<49:23,  1.57it/s]Generation 45350: train Loss = 0.00650
 91%| | 45350/50002 [10:14:14<6:19:30,  4.89s/it]Generation 45350: test Loss = 0.00512
 91%| | 45399/50002 [10:14:45<49:07,  1.56it/s]Generation 45400: train Loss = 0.00369
Generation 45400: test Loss = 0.00487
 91%| | 45449/50002 [10:15:32<48:45,  1.56it/s]Generation 45450: train Loss = 0.00472
Generation 45450: test Loss = 0.00418
 91%| | 45499/50002 [10:16:19<48:50,  1.54it/s]Generation 45500: train Loss = 0.00556
Generation 45500: test Loss = 0.00487
训练集上一个批次数据的前10个数据
 [[ 0.43933055]
 [ 0.53138077]
 [ 0.48535565]
 [ 0.53138077]
 [ 0.50627613]
 [ 0.39330545]
 [ 0.43514645]
 [ 0.61087865]
 [ 0.54811716]
 [ 0.40585774]]
测试集上一个批次数据的前10个数据
 [[ 0.56066948]
 [ 0.53556484]
 [ 0.48953974]
 [ 0.56485355]
 [ 0.50209206]
 [ 0.50209206]
 [ 0.38075313]
 [ 0.58577406]
 [ 0.41422594]
 [ 0.44769874]]
训练集上一个批次数据通过inference的前10个输出结果
 [[ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]]
 91%| | 45500/50002 [10:16:42<9:17:43,  7.43s/it]测试集上一个批次数据中通过inference后的前10个输出结果
 [[ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]
 [ 0.47294423]]
 91%| | 45549/50002 [10:17:14<48:13,  1.54it/s]Generation 45550: train Loss = 0.00451

Process finished with exit code -1
